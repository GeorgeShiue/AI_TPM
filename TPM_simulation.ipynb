{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e77eec5f",
   "metadata": {},
   "source": [
    "# API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93efbf78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf3564e",
   "metadata": {},
   "source": [
    "# Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a680ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "附件四、報告格式 \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "即時海洋觀測平台開發暨AI影像數據應用服\n",
      "務主題式研發計畫 \n",
      " \n",
      "期末報告\n",
      "{'producer': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creator': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creationdate': '2025-07-26T01:23:18+08:00',\n",
      " 'author': 'Annie',\n",
      " 'moddate': '2025-07-26T01:23:18+08:00',\n",
      " 'source': './docs/期末報告_0407.pdf',\n",
      " 'total_pages': 20,\n",
      " 'page': 0,\n",
      " 'page_label': '1'}\n",
      "1 \n",
      " \n",
      "即時海洋觀測平台開發暨 AI 影像數據應用服務主題式研發\n",
      "計畫 \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "期末報告 \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "計畫主持人：林家瑜 助理教授     \n",
      "研究機構  ：國立中央大\n",
      "{'producer': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creator': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creationdate': '2025-07-26T01:23:18+08:00',\n",
      " 'author': 'Annie',\n",
      " 'moddate': '2025-07-26T01:23:18+08:00',\n",
      " 'source': './docs/期末報告_0407.pdf',\n",
      " 'total_pages': 20,\n",
      " 'page': 1,\n",
      " 'page_label': '2'}\n",
      "2 \n",
      " \n",
      "計畫摘要 \n",
      "    本研究致力於開發即時海洋觀測平台，並應用 AI 影像數據分析來提升遠距離船\n",
      "隻辨識的準確性與效率。現行船舶識別技術主要依賴人眼辨識，然而在 3 公里以上距\n",
      "離，由於海面反\n",
      "{'producer': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creator': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creationdate': '2025-07-26T01:23:18+08:00',\n",
      " 'author': 'Annie',\n",
      " 'moddate': '2025-07-26T01:23:18+08:00',\n",
      " 'source': './docs/期末報告_0407.pdf',\n",
      " 'total_pages': 20,\n",
      " 'page': 2,\n",
      " 'page_label': '3'}\n",
      "3 \n",
      " \n",
      "目錄 \n",
      "計畫摘要 ......................................................................................\n",
      "{'producer': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creator': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creationdate': '2025-07-26T01:23:18+08:00',\n",
      " 'author': 'Annie',\n",
      " 'moddate': '2025-07-26T01:23:18+08:00',\n",
      " 'source': './docs/期末報告_0407.pdf',\n",
      " 'total_pages': 20,\n",
      " 'page': 3,\n",
      " 'page_label': '4'}\n",
      "4 \n",
      " \n",
      "一、 計畫動機與目的 \n",
      "1. 動機 \n",
      "在海洋環境中，對於船隻的及時且準確的辨識是保障航行安全和有效執\n",
      "行海上作業的關鍵。但目前大部分的船隻都是人工辨識，而人眼無法同時看\n",
      "超過 10 艘船隻進\n",
      "{'producer': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creator': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creationdate': '2025-07-26T01:23:18+08:00',\n",
      " 'author': 'Annie',\n",
      " 'moddate': '2025-07-26T01:23:18+08:00',\n",
      " 'source': './docs/期末報告_0407.pdf',\n",
      " 'total_pages': 20,\n",
      " 'page': 4,\n",
      " 'page_label': '5'}\n",
      "5 \n",
      " \n",
      "二、 文獻探討 \n",
      "現在有一些研究採用物件辨識模型進行船隻辨識，在 Automatic Ship \n",
      "Object Detection Model Based on YOLOv4 with Tr\n",
      "{'producer': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creator': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creationdate': '2025-07-26T01:23:18+08:00',\n",
      " 'author': 'Annie',\n",
      " 'moddate': '2025-07-26T01:23:18+08:00',\n",
      " 'source': './docs/期末報告_0407.pdf',\n",
      " 'total_pages': 20,\n",
      " 'page': 5,\n",
      " 'page_label': '6'}\n",
      "6 \n",
      " \n",
      "YOLOv8 的基礎上，額外加入了較大尺寸的兩個輸入 (320×320和160×\n",
      "160)、一個 Upsampling 層(160×160) 、一個 Fusion 加 C2f 層(160×1\n",
      "{'producer': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creator': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creationdate': '2025-07-26T01:23:18+08:00',\n",
      " 'author': 'Annie',\n",
      " 'moddate': '2025-07-26T01:23:18+08:00',\n",
      " 'source': './docs/期末報告_0407.pdf',\n",
      " 'total_pages': 20,\n",
      " 'page': 6,\n",
      " 'page_label': '7'}\n",
      "7 \n",
      " \n",
      "的寬高比差異來提升回歸精度，而Focal Loss 則用於平衡正負樣本比例，讓\n",
      "模型更關注高質量的預測框。 \n",
      "為了評估模型性能，作者在 SeaShips(7000)資料集上進行實驗，訓練時\n",
      "\n",
      "{'producer': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creator': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creationdate': '2025-07-26T01:23:18+08:00',\n",
      " 'author': 'Annie',\n",
      " 'moddate': '2025-07-26T01:23:18+08:00',\n",
      " 'source': './docs/期末報告_0407.pdf',\n",
      " 'total_pages': 20,\n",
      " 'page': 7,\n",
      " 'page_label': '8'}\n",
      "8 \n",
      " \n",
      "三、 研究方法 \n",
      "1. 資料收集 \n",
      "    資料集使用 Singapore Maritime Dataset 的 Visible On-Shore 資料集[5, 6]加上\n",
      "ABOships-\n",
      "{'producer': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creator': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creationdate': '2025-07-26T01:23:18+08:00',\n",
      " 'author': 'Annie',\n",
      " 'moddate': '2025-07-26T01:23:18+08:00',\n",
      " 'source': './docs/期末報告_0407.pdf',\n",
      " 'total_pages': 20,\n",
      " 'page': 8,\n",
      " 'page_label': '9'}\n",
      "9 \n",
      " \n",
      "    ABOships-PLUS 資料集為網路上的公開資料集，ABOships 資料集的改進版\n",
      "本，包含 9880 張影像，33227 個標註，屬於近港船隻影像資料集，其中含有 3 個\n",
      "船\n",
      "{'producer': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creator': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creationdate': '2025-07-26T01:23:18+08:00',\n",
      " 'author': 'Annie',\n",
      " 'moddate': '2025-07-26T01:23:18+08:00',\n",
      " 'source': './docs/期末報告_0407.pdf',\n",
      " 'total_pages': 20,\n",
      " 'page': 9,\n",
      " 'page_label': '10'}\n",
      "10 \n",
      " \n",
      "2. 資料前處理 \n",
      "    \n",
      " \n",
      "圖一、資料前處理流程圖。 \n",
      "    如圖一所示，首先會將資料集處理成只包含 images 和 labels 資料夾的\n",
      "形式，images 和 labels\n",
      "{'producer': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creator': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creationdate': '2025-07-26T01:23:18+08:00',\n",
      " 'author': 'Annie',\n",
      " 'moddate': '2025-07-26T01:23:18+08:00',\n",
      " 'source': './docs/期末報告_0407.pdf',\n",
      " 'total_pages': 20,\n",
      " 'page': 10,\n",
      " 'page_label': '11'}\n",
      "11 \n",
      " \n",
      " \n",
      "圖二、YOLOv11 架構圖[9] \n",
      " \n",
      "Backbone 如圖二左側所示，主要目的是從輸入影像中提取有用的特徵\n",
      "資訊。在 YOLOv11 中，Backbone 採用了 C3K2 結構\n",
      "{'producer': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creator': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creationdate': '2025-07-26T01:23:18+08:00',\n",
      " 'author': 'Annie',\n",
      " 'moddate': '2025-07-26T01:23:18+08:00',\n",
      " 'source': './docs/期末報告_0407.pdf',\n",
      " 'total_pages': 20,\n",
      " 'page': 11,\n",
      " 'page_label': '12'}\n",
      "12 \n",
      " \n",
      "四、 實驗結果 \n",
      "    我們使用 YOLOv11l 模型，訓練集使用 ABOships-PLUS，測試集使用\n",
      "高雄資料集，實驗環境為 64-bit Windows 11、Intel i5\n",
      "{'producer': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creator': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creationdate': '2025-07-26T01:23:18+08:00',\n",
      " 'author': 'Annie',\n",
      " 'moddate': '2025-07-26T01:23:18+08:00',\n",
      " 'source': './docs/期末報告_0407.pdf',\n",
      " 'total_pages': 20,\n",
      " 'page': 12,\n",
      " 'page_label': '13'}\n",
      "13 \n",
      " \n",
      " \n",
      "圖三、彩色影片 output_005 第一秒影像 \n",
      "    彩色影片 output_005 的第一秒影像如上圖所示，圖中模型成功辨識出所\n",
      "有船隻，1~3 秒內的檢測率都為 1.0。 \n",
      "\n",
      "{'producer': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creator': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creationdate': '2025-07-26T01:23:18+08:00',\n",
      " 'author': 'Annie',\n",
      " 'moddate': '2025-07-26T01:23:18+08:00',\n",
      " 'source': './docs/期末報告_0407.pdf',\n",
      " 'total_pages': 20,\n",
      " 'page': 13,\n",
      " 'page_label': '14'}\n",
      "14 \n",
      " \n",
      " \n",
      "圖五、彩色影片 output_080 第一秒影像 \n",
      "    彩色影片 output_080 的第一秒影像如上圖所示，圖中模型成功辨識出所\n",
      "有船隻，1~3 秒內的檢測率都為 1.0。 \n",
      "\n",
      "{'producer': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creator': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creationdate': '2025-07-26T01:23:18+08:00',\n",
      " 'author': 'Annie',\n",
      " 'moddate': '2025-07-26T01:23:18+08:00',\n",
      " 'source': './docs/期末報告_0407.pdf',\n",
      " 'total_pages': 20,\n",
      " 'page': 14,\n",
      " 'page_label': '15'}\n",
      "15 \n",
      " \n",
      " \n",
      "圖七、黑白影片 output_199 第二秒影像 \n",
      "    彩色影片 output_199 的第二秒影像如上圖所示，圖中模型成功辨識出所\n",
      "有船隻，2~3 秒內的檢測率都為 1.0。 \n",
      "\n",
      "{'producer': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creator': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creationdate': '2025-07-26T01:23:18+08:00',\n",
      " 'author': 'Annie',\n",
      " 'moddate': '2025-07-26T01:23:18+08:00',\n",
      " 'source': './docs/期末報告_0407.pdf',\n",
      " 'total_pages': 20,\n",
      " 'page': 15,\n",
      " 'page_label': '16'}\n",
      "16 \n",
      " \n",
      " \n",
      "圖九、黑白影片 output_276 第一秒影像 \n",
      "    彩色影片 output_276 的第一秒影像如上圖所示，圖中模型成功辨識出所\n",
      "有船隻，1~3 秒內的檢測率都為 1.0。 \n",
      "\n",
      "{'producer': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creator': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creationdate': '2025-07-26T01:23:18+08:00',\n",
      " 'author': 'Annie',\n",
      " 'moddate': '2025-07-26T01:23:18+08:00',\n",
      " 'source': './docs/期末報告_0407.pdf',\n",
      " 'total_pages': 20,\n",
      " 'page': 16,\n",
      " 'page_label': '17'}\n",
      "17 \n",
      " \n",
      "表五、KPI 完成表 \n",
      "項目 達成狀況 \n",
      "1.建立 AI 分析海事觀測演算法邏輯架構 已達成 \n",
      "2.完成演算法建立，並可在本島沿海 3 公里海域內環境進行 已達成 \n",
      "3.演算結果可達以下規\n",
      "{'producer': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creator': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creationdate': '2025-07-26T01:23:18+08:00',\n",
      " 'author': 'Annie',\n",
      " 'moddate': '2025-07-26T01:23:18+08:00',\n",
      " 'source': './docs/期末報告_0407.pdf',\n",
      " 'total_pages': 20,\n",
      " 'page': 17,\n",
      " 'page_label': '18'}\n",
      "18 \n",
      " \n",
      "五、 結論 \n",
      "本計畫目的為設計出可以有效辨識 3 公里遠的船隻，且一次可辨識長度 15\n",
      "公尺的船隻 10 艘以上的模型，根據目前的實驗結果，模型在船隻距離、速度、\n",
      "目標數量以及避碰能力上都\n",
      "{'producer': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creator': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creationdate': '2025-07-26T01:23:18+08:00',\n",
      " 'author': 'Annie',\n",
      " 'moddate': '2025-07-26T01:23:18+08:00',\n",
      " 'source': './docs/期末報告_0407.pdf',\n",
      " 'total_pages': 20,\n",
      " 'page': 18,\n",
      " 'page_label': '19'}\n",
      "19 \n",
      " \n",
      "六、 參考文獻 \n",
      "[1] Sun, Bowen, et al. \"Automatic ship object detection model based on YOLOv4 \n",
      "with t\n",
      "{'producer': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creator': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creationdate': '2025-07-26T01:23:18+08:00',\n",
      " 'author': 'Annie',\n",
      " 'moddate': '2025-07-26T01:23:18+08:00',\n",
      " 'source': './docs/期末報告_0407.pdf',\n",
      " 'total_pages': 20,\n",
      " 'page': 19,\n",
      " 'page_label': '20'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "import pprint\n",
    "\n",
    "file_path = \"./docs/期末報告_0407.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "\n",
    "pages = []\n",
    "async for page in loader.alazy_load():\n",
    "    pages.append(page)\n",
    "\n",
    "for page in pages:\n",
    "    print(page.page_content[:100])  # Print the first 100 characters of each page content\n",
    "    pprint.pp(page.metadata)  # Print the metadata of each page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ae4a850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "附件四、報告格式 \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "即時海洋觀測平台開發暨AI影像數據應用服\n",
      "務主題式研發計畫 \n",
      " \n",
      "期末報告1 \n",
      " \n",
      "即時海洋觀測平台開發暨 AI 影像數據應用服務主題式研發\n",
      "計畫 \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "期末報告 \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "計畫主持人：林家瑜 助理教授     \n",
      "研究機構  ：國立中央大學資訊工程系 \n",
      "執行期間  ：113/05/01-114/04/30（請填寫合作研究計畫執行期間） \n",
      " \n",
      "(以上資料請務必以中文繕打清楚) \n",
      " \n",
      "中華民國 114 年 01 月31 日2 \n",
      " \n",
      "計畫摘要 \n",
      "    本研究致力於開發即時海洋觀測平台，並應用 AI 影像數據分析來提升遠距離船\n",
      "隻辨識的準確性與效率。現行船舶識別技術主要依賴人眼辨識，然而在 3 公里以上距\n",
      "離，由於海面反射、霧氣與光線變化等環境因素的影響，傳統方法的準確率明顯下\n",
      "降。本計畫旨在透過深度學習物件辨識技術，建立一套高效能的「即時遠距離多船隻\n",
      "辨識系統」，能夠在 3 公里外準確偵測船隻，並可同時識別 10 艘以上長度超過 15 公\n",
      "尺的船隻。 \n",
      "    本研究參考 YOLOv5s 與YOLOv8 物件辨識模型，針對海洋環境特性進行改良，\n",
      "並利用多種公開及自建數據集如 Singapore Maritime Dataset、ABOships-PLUS、高雄\n",
      "港實測數據進行模型訓練與驗證。透過影像增強、特徵提取優化與多尺度檢測技術，\n",
      "我們顯著提升了模型在複雜海洋場景中的識別能力。 \n",
      "    目前的實驗結果顯示，我們的系統在新加坡與高雄測試數據集中的部分影像皆展\n",
      "現超過 90%的識別準確度，並成功達成： \n",
      "⚫ 可偵測移動速度超過 15 節的船隻 \n",
      "⚫ 在 5 公里範圍內實現高效識別 \n",
      "⚫ 可即時處理 640×480 解析度影像，幀率≥10FPS \n",
      "⚫ 具備船隻避碰預警功能 \n",
      "    未來將進一步提升船隻辨識與船隻避碰預測的準確度，並擴充模型至夜間與黑白\n",
      "影像辨識，以提升即時監測與應用能力。此技術的發展對於海洋交通安全監控、智慧\n",
      "港口管理與海上救援應用將具備重要價值。 \n",
      " \n",
      "關鍵字：即時海洋觀測、AI 影像辨識、深度學習、YOLOv5、YOLOv8、多尺度檢\n",
      "測、船隻辨識、避碰預警、智慧港口、遠距離監測3 \n",
      " \n",
      "目錄 \n",
      "計畫摘要 ................................\n"
     ]
    }
   ],
   "source": [
    "documents_content = []\n",
    "\n",
    "full_content = \"\".join([page.page_content for page in pages])\n",
    "print(full_content[:1000])  # Print the first 1000 characters of the full\n",
    "\n",
    "documents_content.append(full_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880d9111",
   "metadata": {},
   "source": [
    "# Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30e34857",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_documents_content = \"\\n\".join(f\"===\\n{doc}\\n===\" for doc in documents_content)\n",
    "\n",
    "task_description = f\"\"\"\n",
    "以下是提供你閱讀的計畫文件：\n",
    "{full_documents_content}\n",
    "請根據以上文件內容，模擬一位業務代表會向 TPM 詢問有關 即時辨識 24 海里內船隻平台 的1個問題或轉述的需求。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd98cd2c",
   "metadata": {},
   "source": [
    "# Model Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bf3f9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "\n",
    "model_client = OpenAIChatCompletionClient(\n",
    "    model=\"gpt-4.1-mini\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7173b999",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15a94368",
   "metadata": {},
   "outputs": [],
   "source": [
    "business_agent_system_prompt = f\"\"\"\n",
    "你是一位業務代表，負責把從客戶那裡聽到的需求與想法，轉達給應用專家（Application Agent），以協助釐清並形成具體應用情境。\n",
    "\n",
    "你不熟悉技術，但擅長觀察客戶反應、理解業務痛點。你現在的任務是：\n",
    "\n",
    "---\n",
    "\n",
    "### 模擬任務：\n",
    "\n",
    "閱讀一份「過去專案成果文件」後，請模擬以下情境：\n",
    "\n",
    "1. 想像某新客戶對這類方案表達興趣，說了些初步想法\n",
    "2. 根據你對文件的理解與客戶背景，轉述這些模糊但合理的需求或問題\n",
    "3. 不用完整，也可以帶點想像，語氣自然即可\n",
    "\n",
    "---\n",
    "\n",
    "### 對話引導：\n",
    "\n",
    "- Application Agent 會問你問題，幫你把「想法」變成「使用情境」\n",
    "- 請主動代入你想像的客戶場景（產業、用途、挑戰）\n",
    "\n",
    "---\n",
    "\n",
    "### 語氣建議與注意事項：\n",
    "\n",
    "- 用聊天方式自然表達，不需要規劃完整解法\n",
    "- 禁用技術術語或系統細節（如架構、模型）\n",
    "- 你是需求的「轉述者與觸發者」，不是設計者\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73bf31d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "applicational_agent_system_prompt = f\"\"\"\n",
    "你是一位 Application 專家，負責在業務與技術團隊之間扮演橋樑角色，將模糊需求轉化為具體應用情境，並協助技術團隊理解業務背景。\n",
    "\n",
    "你有兩種互動角色：\n",
    "\n",
    "---\n",
    "\n",
    "## 面對業務代表時：\n",
    "\n",
    "- 協助釐清模糊構想，提出非技術性、情境導向的問題，如：\n",
    "  - 使用者是誰？目的是什麼？\n",
    "  - 使用場景是什麼？他們想解決什麼困擾？\n",
    "  - 他們希望看到什麼成果或回饋？\n",
    "- 引導業務想像實際應用方式，不使用技術術語、不提解法。\n",
    "- 當需求釐清較為完整後，請主動**彙整你對應用情境的初步想像**，內容應根據對話內容合理推測，並包含：\n",
    "  - 使用者可能的行為或工作流程\n",
    "  - 使用時的時機與觸發條件\n",
    "  - 系統如何介入並產生幫助或回饋  \n",
    "- 你的描述應具備情境性與可理解性，不需進入技術細節，重點是幫助業務與技術雙方建立共同的畫面。\n",
    "\n",
    "---\n",
    "\n",
    "## 面對技術人員時：\n",
    "\n",
    "- 當技術人員提出兩種以上的技術組合方案後，你的任務是：\n",
    "  - 根據使用情境判斷各方案的合適性\n",
    "  - 從業務邏輯、使用彈性、現場條件等角度進行分析\n",
    "  - 協助選擇最符合需求的技術方案，並提供選擇理由（如某方案在場域部署較穩定、維運負擔較小等）\n",
    "\n",
    "- 你不負責設計系統或技術架構，但會在需求與使用面協助確認方案的適切性。\n",
    "\n",
    "---\n",
    "\n",
    "## 溝通風格：\n",
    "\n",
    "- 面向業務：使用引導式語氣，協助想像應用場景，並在適當時機主動總結使用情境\n",
    "- 面向技術：結構清楚、實務導向，協助還原問題背景與目標\n",
    "- 你的任務是「釐清需求」與「建立情境」，不是「設計系統」或「技術決策」\n",
    "\n",
    "---\n",
    "\n",
    "## 對話終止條件：\n",
    "\n",
    "- 當你和業務來回溝通完並確認好使用情境，請在最後一段輸出 \"TERMINATE\"。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fb8160b",
   "metadata": {},
   "outputs": [],
   "source": [
    "technical_agent_system_prompt = f\"\"\"\n",
    "你是一位 TPM（Technical Program Manager），根據 Application Agent 提供的應用情境，負責提出可行技術解法，並在選定方案後協助規劃交付內容，支援專案落地。\n",
    "\n",
    "---\n",
    "\n",
    "你的任務分為兩個階段，請依下列順序執行：\n",
    "\n",
    "---\n",
    "\n",
    "### 第一階段：提出技術組合建議\n",
    "\n",
    "請根據應用情境，提出**至少兩種可行的技術解法組合**，每種方案請說明：\n",
    "\n",
    "- 適用條件（何種情境下適合）\n",
    "- 核心模組與系統層級流程（無需進入程式實作）\n",
    "- 擴展性與彈性（能否因應未來變化）\n",
    "- 潛在風險與限制（如資料來源、即時性、資安、維運等）\n",
    "\n",
    "若有資訊尚不明確，請根據合理假設補足，並註記「待補充」。\n",
    "\n",
    "此階段僅負責輸出可行技術選項，**請等待 Application Agent 回覆並選擇方案後再進入第二階段**。\n",
    "\n",
    "---\n",
    "\n",
    "### 第二階段：任務拆解與交付建議（在方案確定後啟動）\n",
    "\n",
    "當 Application Agent 明確選定其中一種技術方案後，請依此方案進行交付規劃，內容包括：\n",
    "\n",
    "- 任務步驟拆解與依賴關係\n",
    "- 建議所需人力角色（如前端、後端、資料、資安）\n",
    "- 潛在風險與備案建議\n",
    "- 可推估的驗收標準與里程碑（如有）\n",
    "\n",
    "---\n",
    "\n",
    "### 溝通準則：\n",
    "\n",
    "- 所有情境皆視為已完成需求釐清，**不需回到業務層面或重新定義需求**\n",
    "- 請避免程式實作細節，聚焦在系統架構與交付可行性\n",
    "- 使用清楚的分段與條列，方便技術團隊與 PM 理解與實施\n",
    "\n",
    "---\n",
    "\n",
    "### 對話終止條件：\n",
    "- 當你完成任務拆解與交付建議時，請在最後一段輸出 \"TERMINATE\"。\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19cb2043",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "\n",
    "business_agent = AssistantAgent(\n",
    "    name=\"Business\",\n",
    "    model_client=model_client,\n",
    "    system_message=business_agent_system_prompt,\n",
    ")\n",
    "\n",
    "applicational_agent = AssistantAgent(\n",
    "    name=\"ApplicationAgent\",\n",
    "    model_client=model_client,\n",
    "    system_message=applicational_agent_system_prompt,\n",
    ")\n",
    "\n",
    "technical_agent = AssistantAgent(\n",
    "    name=\"TechnicalAgent\",\n",
    "    model_client=model_client,\n",
    "    system_message=technical_agent_system_prompt,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599ee9f7",
   "metadata": {},
   "source": [
    "# Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffbf15cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.conditions import MaxMessageTermination, TextMentionTermination\n",
    "\n",
    "termination1 = TextMentionTermination(\"TERMINATE\", [applicational_agent.name])\n",
    "termination2 = TextMentionTermination(\"TERMINATE\", [technical_agent.name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f0b5441",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "\n",
    "team1 = RoundRobinGroupChat(\n",
    "    participants=[business_agent, applicational_agent],\n",
    "    termination_condition=termination1,   \n",
    "    max_turns=20\n",
    ")\n",
    "\n",
    "team2 = RoundRobinGroupChat(\n",
    "    participants=[technical_agent, applicational_agent],\n",
    "    termination_condition=termination2,\n",
    "    max_turns=20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35458427",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b224b2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from io import StringIO\n",
    "from contextlib import contextmanager\n",
    "\n",
    "class TeeOutput:\n",
    "    \"\"\"同時寫入檔案和控制台的類別\"\"\"\n",
    "    def __init__(self, file_handle, console_handle):\n",
    "        self.file = file_handle\n",
    "        self.console = console_handle\n",
    "    \n",
    "    def write(self, text):\n",
    "        self.file.write(text)\n",
    "        self.console.write(text)\n",
    "        self.file.flush()  # 確保立即寫入\n",
    "    \n",
    "    def flush(self):\n",
    "        self.file.flush()\n",
    "        self.console.flush()\n",
    "\n",
    "@contextmanager\n",
    "def capture_print_to_file(filename, mode='w', show_console=True):\n",
    "    \"\"\"捕獲指定程式碼塊中的所有 print 輸出到檔案\n",
    "    \n",
    "    Args:\n",
    "        filename: 輸出檔案名稱\n",
    "        mode: 檔案開啟模式 ('w' 或 'a')\n",
    "        show_console: 是否同時在控制台顯示輸出\n",
    "    \"\"\"\n",
    "    \n",
    "    # 保存原始的 stdout\n",
    "    original_stdout = sys.stdout\n",
    "    \n",
    "    try:\n",
    "        if show_console:\n",
    "            # 同時顯示在控制台和保存到檔案\n",
    "            with open(filename, mode, encoding='utf-8') as f:\n",
    "                tee = TeeOutput(f, original_stdout)\n",
    "                sys.stdout = tee\n",
    "                yield\n",
    "        else:\n",
    "            # 只保存到檔案，不顯示在控制台\n",
    "            string_buffer = StringIO()\n",
    "            sys.stdout = string_buffer\n",
    "            yield\n",
    "            \n",
    "            # 取得捕獲的內容並寫入檔案\n",
    "            captured_output = string_buffer.getvalue()\n",
    "            with open(filename, mode, encoding='utf-8') as f:\n",
    "                f.write(captured_output)\n",
    "            string_buffer.close()\n",
    "    finally:\n",
    "        # 恢復原始 stdout\n",
    "        sys.stdout = original_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7916167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with capture_print_to_file(\"business_agent_output.txt\"):\n",
    "#     result = await business_agent.run(task=task_description)\n",
    "#     print(result.messages[-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fcf950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "\n",
      "以下是提供你閱讀的計畫文件：\n",
      "===\n",
      "附件四、報告格式 \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "即時海洋觀測平台開發暨AI影像數據應用服\n",
      "務主題式研發計畫 \n",
      " \n",
      "期末報告1 \n",
      " \n",
      "即時海洋觀測平台開發暨 AI 影像數據應用服務主題式研發\n",
      "計畫 \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "期末報告 \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "計畫主持人：林家瑜 助理教授     \n",
      "研究機構  ：國立中央大學資訊工程系 \n",
      "執行期間  ：113/05/01-114/04/30（請填寫合作研究計畫執行期間） \n",
      " \n",
      "(以上資料請務必以中文繕打清楚) \n",
      " \n",
      "中華民國 114 年 01 月31 日2 \n",
      " \n",
      "計畫摘要 \n",
      "    本研究致力於開發即時海洋觀測平台，並應用 AI 影像數據分析來提升遠距離船\n",
      "隻辨識的準確性與效率。現行船舶識別技術主要依賴人眼辨識，然而在 3 公里以上距\n",
      "離，由於海面反射、霧氣與光線變化等環境因素的影響，傳統方法的準確率明顯下\n",
      "降。本計畫旨在透過深度學習物件辨識技術，建立一套高效能的「即時遠距離多船隻\n",
      "辨識系統」，能夠在 3 公里外準確偵測船隻，並可同時識別 10 艘以上長度超過 15 公\n",
      "尺的船隻。 \n",
      "    本研究參考 YOLOv5s 與YOLOv8 物件辨識模型，針對海洋環境特性進行改良，\n",
      "並利用多種公開及自建數據集如 Singapore Maritime Dataset、ABOships-PLUS、高雄\n",
      "港實測數據進行模型訓練與驗證。透過影像增強、特徵提取優化與多尺度檢測技術，\n",
      "我們顯著提升了模型在複雜海洋場景中的識別能力。 \n",
      "    目前的實驗結果顯示，我們的系統在新加坡與高雄測試數據集中的部分影像皆展\n",
      "現超過 90%的識別準確度，並成功達成： \n",
      "⚫ 可偵測移動速度超過 15 節的船隻 \n",
      "⚫ 在 5 公里範圍內實現高效識別 \n",
      "⚫ 可即時處理 640×480 解析度影像，幀率≥10FPS \n",
      "⚫ 具備船隻避碰預警功能 \n",
      "    未來將進一步提升船隻辨識與船隻避碰預測的準確度，並擴充模型至夜間與黑白\n",
      "影像辨識，以提升即時監測與應用能力。此技術的發展對於海洋交通安全監控、智慧\n",
      "港口管理與海上救援應用將具備重要價值。 \n",
      " \n",
      "關鍵字：即時海洋觀測、AI 影像辨識、深度學習、YOLOv5、YOLOv8、多尺度檢\n",
      "測、船隻辨識、避碰預警、智慧港口、遠距離監測3 \n",
      " \n",
      "目錄 \n",
      "計畫摘要 ....................................................................................................................... 2 \n",
      "一、計畫動機與目的 ................................................................................................... 4 \n",
      "1. 動機 ..................................................................................................................... 4 \n",
      "2. 目的 ..................................................................................................................... 4 \n",
      "二、文獻探討 ............................................................................................................... 5 \n",
      "三、研究方法 ............................................................................................................... 8 \n",
      "1. 資料收集 ............................................................................................................. 8 \n",
      "2. 資料前處理 ....................................................................................................... 10 \n",
      "3. 船隻辨識模型 ................................................................................................... 10 \n",
      "四、實驗結果 ............................................................................................................. 12 \n",
      "五、結論 ..................................................................................................................... 18 \n",
      "六、參考文獻 ............................................................................................................. 194 \n",
      " \n",
      "一、 計畫動機與目的 \n",
      "1. 動機 \n",
      "在海洋環境中，對於船隻的及時且準確的辨識是保障航行安全和有效執\n",
      "行海上作業的關鍵。但目前大部分的船隻都是人工辨識，而人眼無法同時看\n",
      "超過 10 艘船隻進行辨識，因此需要 AI 輔助。現有的 AI 對距離近且較大的\n",
      "船或是俯視角的衛星雷達成像的船有不錯的辨識能力，但若是在第一人稱且\n",
      "距離超過 3 公里的情況下，可能會受到環境條件如海面反射、霧氣、光線變\n",
      "化等的影響，導致偵測的準確度降低，且現有開放資料集大多是較大的船隻\n",
      "，3 公里以上的船隻資料集較少，不利於訓練模型。 \n",
      "2. 目的 \n",
      "基於上述的問題，本計畫欲設計一套「即時遠距離多船隻辨識系統」 ，\n",
      "此系統可以有效辨識 3 公里遠的船隻，且一次可辨識長度15 公尺的船隻 10\n",
      "艘以上。5 \n",
      " \n",
      "二、 文獻探討 \n",
      "現在有一些研究採用物件辨識模型進行船隻辨識，在 Automatic Ship \n",
      "Object Detection Model Based on YOLOv4 with Transformer Mechanism in \n",
      "Remote Sensing Images 論文中提出了名為 Auto-T-YOLO 的架構[1]，用於解\n",
      "決現有物件偵測模型從輸入中提取特徵未能充分考慮全局特徵，且無法根據\n",
      "輸入的特徵自動調整，導致偵測準確度下降的問題。 \n",
      "    Auto-T-YOLO 的模型架構分為三個部分 ，Preattention, Attention 和\n",
      "Prediction。輸入影像大小為608×608×3，Preattention 和 Attention 的設計\n",
      "模仿了人類視覺系統中從大的全局特徵開始，再逐步轉向局部細節的兩階段\n",
      "注意機制。 \n",
      "    在 Preattention 架構中，輸入的圖像會根據其中是否包含𝑠𝑖𝑧𝑒 > 32×32\n",
      "的物件分為 A 子資料集及 B 子資料集，並在之後的 Attention 架構中根據其\n",
      "所在的子資料集做不同的影像處理。 \n",
      "    Attention 架構主要參考了 YOLOv4 的 Backbone 及 Neck 架構來設計，\n",
      "A 子資料集及 B 子資料集在 Backbone 中的處理流程相同，都是利用一層\n",
      "CBM 進行卷積運算以及五層 CSPDarknet53 進行殘差及卷積運算來提取特\n",
      "徵同時防止梯度消失，由於YOLOv4 的 CBL 架構基於卷積運算，而卷積運\n",
      "算受限於 Kernel 大小，因此無法很好地提取全局特徵，所以 A 子資料集在\n",
      "Neck 中 SPP 架構輸出之後使用了 Transformer 中的 Multi-head Self-Attention\n",
      "架構取代了 CBL，稱為 SPP-MHSA，其中 Multi-head Self-Attention 使用了\n",
      "四個 head。Neck 的後半段與 YOLOv4 相似，使用了 FPN 做 Upsampling、\n",
      "PANet 做 downsampling 以提升多尺度目標檢測的能力。 \n",
      "    Prediction 架構用來對 PANet 輸出做多尺度目標檢測，損失函數使用了\n",
      "CIoU 以及 DIoU-NMS。模型準確度在 SSDD 資料集、近海及遠海場景上分\n",
      "別達到了 96.3%、91.78%以及 98.33%。 \n",
      " 在另一篇論文 A streamlined approach for intelligent ship object detection \n",
      "using EL -YOLO algorithm 中提出了 EL-YOLO 的架構[2]，用於提升目標檢\n",
      "測在具有波浪、反射等複雜海洋環境中對於小物體的檢測精度，其輕量化的\n",
      "網路架構在硬體運算資源有限的智慧船舶、無人船舶等領域也有良好的適應\n",
      "性。 \n",
      "EL-YOLO 的架構基於 YOLOv8 進行改進，輸入影像大小為640×640\n",
      "，包含了Backbone、Neck、Head 三個部分，Backbone 中與 YOLOv8 相同，\n",
      "使用了一層CBS 進行卷積運算和四層CBS 加C2f 進行殘差及卷積運算來提\n",
      "取特徵同時防止梯度消失。 \n",
      "在 Neck 部分，因為傳統的 FPN 和 PAN 架構在面對因反射或波浪等背\n",
      "景干擾因素導致特徵信息不足的目標時，容易在多層卷積過程中丟失信息，\n",
      "導致檢測精度下降，所以作者提出了 SMFN (short multi‑fuse neck )架構，在6 \n",
      " \n",
      "YOLOv8 的基礎上，額外加入了較大尺寸的兩個輸入 (320×320和160×\n",
      "160)、一個 Upsampling 層(160×160) 、一個 Fusion 加 C2f 層(160×160)\n",
      "、一個卷積層(80×80)及一個輸出(160×160)到 FPN 和 PAN 架構中，以\n",
      "捕捉更多的特徵信息，並提高對小型目標的檢測能力。 \n",
      "Head 架構因為 Neck 的 SMFN 架構而多了一個160×160的輸出，相較\n",
      "原本只有三個輸出的 YOLOv8 多了一個。在損失函數的部分，因為傳統的\n",
      "CIoU 在處理特徵信息不足的目標時 往往會過度懲罰， 因此作者提出了\n",
      "AWIoU(adequate wise IoU )，通過動態分配不同權重給不同特徵信息量的目\n",
      "標來調整懲罰，避免目標因受背景干擾而造成模型誤判。 \n",
      "在模型訓練完後，為了使其網路架構輕量化以應用於硬體運算資源有限\n",
      "的智慧船舶 、 無人船舶等領域，作者提出了GDFP(Greedy-driven filter pruning)\n",
      "，首先計算每一層中所有 filter 的 L1 範數以得到其重要性分數，並將分數最\n",
      "低的 filter 刪除，在刪除後對模型重新評估，並重複以上操作直到得到理想\n",
      "的模型，最後重新訓練該模型，以得到將模型輕量化的效果。 \n",
      "此模型在 SeaShips 資料集上的mAP0.5 為 0.988， mAP0.5:0.95 為 0.778\n",
      "，在 ABOships 資料集上的mAP0.5 為 0.672，mAP0.5:0.95 為 0.348。 \n",
      "另一篇論文  YOLOSeaShip: a lightweight model for real -time ship \n",
      "detection [3]中提出了 YOLOSeaShip 的架構，用於解決海洋環境中目標檢測\n",
      "的準確性與硬體資源需求之間的矛盾，特別是在實時性要求較高且硬體運算\n",
      "能力有限的應用場景如邊境監控、智慧海洋交通中。 \n",
      "    YOLOSeaShip 的架構基於 YOLOv7-tiny 進行改進，包含了 Input、\n",
      "Backbone 和 Head 三個主要部分。 \n",
      "Input 架構上採用了 Mosaic 數據增強技術，通過隨機裁剪並拼接多張影\n",
      "像，增加數據的多樣性與小目標樣本數。此外，使用自適應圖片縮放技術來\n",
      "處理不同尺度的目標，並結合K-means 分群方法優化錨框的尺寸設定，避免\n",
      "人工設計過程中的偏差。 \n",
      "Backbone 的部分，YOLOSeaShip 引入了 PConv（Partial Convolution ）\n",
      "架構替代了原本的卷積操作。該架構僅對部分通道進行計算，從而有效減少\n",
      "了參數量並提升計算效率。此外，每層池化操作後 還加入了 PfAAM（\n",
      "Parameter-Free Average Attention Module）。PfAAM 基於空間和通道的平均值\n",
      "計算注意力權重，不增加模型參數的情況下提升了模型對關鍵區域的定位能\n",
      "力。 \n",
      "Head 部分，模型加入了SPPCSPC_tiny 架構，通過多尺度（5×5、9×9 和\n",
      "13×13）最大池化層結合本地與全局特徵，增強對不同大小目標的檢測能力\n",
      "。模型的最終輸出包含三個不同大小的特徵圖，用於處理不同尺度的目標檢\n",
      "測。 \n",
      "在損失函數設計上，作者提出了 Focal EIOU（Focal and Efficient IOU）\n",
      "損失函數，結合了 EIOU 和 Focal Loss 的優點。EIOU 損失通過細化目標框7 \n",
      " \n",
      "的寬高比差異來提升回歸精度，而Focal Loss 則用於平衡正負樣本比例，讓\n",
      "模型更關注高質量的預測框。 \n",
      "為了評估模型性能，作者在 SeaShips(7000)資料集上進行實驗，訓練時\n",
      "採用 Adam 優化器，學習率為 0.001，訓練 300 個 epoch。結果顯示，\n",
      "YOLOSeaShip 的 mAP 達到 0.976，檢測速度達到119.84 FPS，相較YOLOv7-\n",
      "tiny 模型，參數量減少至 4.78M，同時大幅提升了檢測速度和資源效率。 \n",
      "在論文 An Improved YOLO v4 Algorithm-based Object Detection Method \n",
      "for Maritime Vessels[4]中提出了基於改進 YOLOv4 的船舶和泊位檢測方法，\n",
      "用於提升目標檢測在複雜海洋環境下的準確性，特別是對港口泊位的檢測效\n",
      "果進行了優化。該方法通過改良 錨框的生成方式和數據集構建，改善了\n",
      "YOLOv4 在海洋場景中的檢測性能，適用於智能船舶的安全輔助系統。 \n",
      "改進的 YOLOv4 架構包含了 Backbone、Neck 和 Head 三個部分。\n",
      "Backbone 部分採用了 CSPDarknet53 作為特徵提取模塊，通過 ResUnit 組件\n",
      "進行深度卷積操作，增強特徵提取能力。Neck 部分引入了 SPP 層和 PANet\n",
      "層，其中 SPP 層通過多尺度池化操作擴展感受野，而 PANet 則將底層的定\n",
      "位信息與高層的語義信息結合，提高多尺度目標的檢測能力。Head 部分則\n",
      "採用了 YOLOv3 的檢測頭，輸出不同尺度的檢測結果。 \n",
      "針對泊位檢測效果不足的問題，作者採用了 K-means 演算法重新生成\n",
      "錨框。在原始 YOLOv4 模型中，錨框基於 MS COCO 和 VOC 數據集生成，\n",
      "但這些框與船舶與泊位數據集中的物體尺寸不匹配，影響了檢測精度。改進\n",
      "後的 K-means 演算法針對數據集進行分群，生成了9 組適配的錨框，有效提\n",
      "升了檢測效率和準確性。 \n",
      "此外，作者構建了一個包含船舶和泊位的專用數據集，通過智能實驗船\n",
      "上的攝像頭在港口拍攝的實景影像生成，並結合公開數據集如MS COCO 和\n",
      "VOC 補充正樣本數量。最終數據集中包含6634 張標註影像，其中70%用於\n",
      "訓練，30%用於測試。標註信息包括物體類別及邊界框的坐標和尺寸。 \n",
      "實驗結果表明，改進的YOLOv4 模型在 mAP 和 F1-score 方面分別提升\n",
      "了 2.79%和 0.80%，相較於原始YOLOv4 達到了更高的檢測精度與穩定性。\n",
      "具體指標顯示，改進後的YOLOv4 模型在 mAP 上達到 83.98%，F1-score 達\n",
      "到 86.18%，而 YOLOv4_tiny 僅達到 54.45%的 mAP 和 54.82%的 F1-score，\n",
      "說明輕量化模型雖然具有更快的檢測速度，但在檢測準確性上仍有進步空間\n",
      "。8 \n",
      " \n",
      "三、 研究方法 \n",
      "1. 資料收集 \n",
      "    資料集使用 Singapore Maritime Dataset 的 Visible On-Shore 資料集[5, 6]加上\n",
      "ABOships-PLUS[7]以及手動標註公司提供的高雄資料集。 \n",
      "    Visible On-Shore 資料集為網路上的公開資料集，包含 38 部長度小於 33 秒\n",
      "的全彩影片，屬於中、遠港船隻影像資料集，其中含有 7 個船隻類別，此資料集\n",
      "特徵為船隻背景為海面、天空等較乾淨的畫面。 \n",
      " \n",
      "表一、Visible On-Shore 資料集類別 \n",
      "Lable Data   \n",
      "Ferry \n",
      " \n",
      "SailsBoat \n",
      " \n",
      "PatrolBoat \n",
      " \n",
      "MerchantShip \n",
      " \n",
      "FishingBoat \n",
      " \n",
      "Tugboat \n",
      " \n",
      "BargeShip9 \n",
      " \n",
      "    ABOships-PLUS 資料集為網路上的公開資料集，ABOships 資料集的改進版\n",
      "本，包含 9880 張影像，33227 個標註，屬於近港船隻影像資料集，其中含有 3 個\n",
      "船隻類別，此資料集特徵為船隻背景包含陸地建築物等容易誤判的畫面。 \n",
      " \n",
      "表二、ABOships-PLUS 資料集類別 \n",
      "Lable Data   \n",
      "powerboat \n",
      " \n",
      "sailboat \n",
      " \n",
      "ship \n",
      " \n",
      "  \n",
      " \n",
      "    高雄資料集為高雄實地拍攝的非公開資料集，包含 504 部長度小於 10 秒的\n",
      "影片，屬於近、中港船隻影像資料集，其中含有 4 個船隻類別，此資料集特徵為\n",
      "船隻背景包含陸地建築物等容易誤判的畫面。 \n",
      " \n",
      "表三、高雄資料集類別 \n",
      "Lable Data   \n",
      "PatrolBoat \n",
      " \n",
      "Yacht \n",
      " \n",
      "MerchantShip \n",
      " \n",
      "Tugboat10 \n",
      " \n",
      "2. 資料前處理 \n",
      "    \n",
      " \n",
      "圖一、資料前處理流程圖。 \n",
      "    如圖一所示，首先會將資料集處理成只包含 images 和 labels 資料夾的\n",
      "形式，images 和 labels 中的檔案是兩兩對應的，並且labels 內的標註檔格式\n",
      "為 yolo 格式。再來會刪除有問題的標註檔及圖片，例如標註檔為空、包含\n",
      "不存在類別、格式錯誤、圖片模糊或者有破圖情況等。第三步是合併資料集\n",
      "，這步是可選的，主要會將數個資料集合併，並記錄合併後的類別名稱。第\n",
      "四步是篩選類別，這步同樣為可選，主要會將需要的類別保留，不需要的剔\n",
      "除。接著因為同一圖片中可能包含數量不等的不同類別物件，因此在切分訓\n",
      "練集和驗證集時，容易造成不同類別的訓練驗證比例不同的情況，所以第五\n",
      "步會將包含 n 個物件的標註檔拆分成 n 份，每一份只包含1 個原始標註檔的\n",
      "物件，彼此不重複，且與其對應的圖片同樣複製 n 份，以確保每個類別都按\n",
      "照正確比例進行切分，最後一步為按照自訂比例切分訓練集及驗證集。 \n",
      "3. 船隻辨識模型 \n",
      "    我們使用了最新的YOLOv11[8]模型來建置船隻辨識模型 ，YOLOv11 基\n",
      "於 PyTorch 架構開發，可在一次前向傳播中同時定位及辨識物件，具有速度\n",
      "快、所需資源少、開發便利及多尺度檢測等優點。圖二為 YOLOv11 架構圖\n",
      "，首先輸入的圖片為 640x640x3 的 RGB 圖像，接著 YOLOv11 可以根據此\n",
      "架構分為三個部分，Backbone, Neck 以及 Head。11 \n",
      " \n",
      " \n",
      "圖二、YOLOv11 架構圖[9] \n",
      " \n",
      "Backbone 如圖二左側所示，主要目的是從輸入影像中提取有用的特徵\n",
      "資訊。在 YOLOv11 中，Backbone 採用了 C3K2 結構，為升級版的 C3，透\n",
      "過更小的卷積核與路徑切分技術，在保持模型表現的前提下大幅降低了計算\n",
      "成本。每個C3K2 中包含兩條路徑，一條直接進行卷積處理，另一條則經過\n",
      "多個 Bottleneck 區塊進行深度特徵學習，最後進行特徵融合。這種結構不僅\n",
      "有效防止梯度消失問題，也能提升網路的收斂速度與特徵提取效率。 \n",
      "Neck 部分如圖二中間所示，結合了 SPFF(Spatial Pyramid Pooling Fast)\n",
      "架構和多層 C2PSA 區塊。SPFF 架構是 SPP 的高速版本，透過不同尺度的\n",
      "最大池化操作將特徵圖進行多尺度融合，再透過 Concatenation 將資訊彙整\n",
      "，幫助模型更好地識別大小不一的船隻。此外，Neck 中的 C2PSA 架構引入\n",
      "空間注意力機制(Spatial Attention)，能讓模型聚焦在關鍵影像區域，特別是\n",
      "對小型或部分遮蔽的物件表現更佳。這部分的架構延續了FPN 與 PAN 的優\n",
      "點，強化了從深層到淺層、再回到深層的資訊傳遞，進一步提升辨識與定位\n",
      "的能力。 \n",
      "Head 如圖二右側所示，負責進行最後的物件偵測任務。YOLOv11 採用\n",
      "多尺度輸出策略，透過多層輸出特徵圖分別負責不同大小目標的偵測。\n",
      "YOLOv11 會利用不同尺寸與比例的錨框(Anchor Boxes)來涵蓋不同形狀的\n",
      "目標，並透過 Non-Maximum Suppression(NMS)過濾重疊的邊界框，保留最\n",
      "具代表性的偵測結果。12 \n",
      " \n",
      "四、 實驗結果 \n",
      "    我們使用 YOLOv11l 模型，訓練集使用 ABOships-PLUS，測試集使用\n",
      "高雄資料集，實驗環境為 64-bit Windows 11、Intel i5-13400F 2.5GHz CPU、\n",
      "32GB RAM 及 NVIDIA RTX 4070 GPU。除了測試模型在原先新加坡資料集\n",
      "的效果外，實驗還在高雄資料集上針對船隻速度、距離以及避碰能力做檢測\n",
      "，因實際場域在白天時使用的是彩色影像，黑夜時使用的是黑白影像當作模\n",
      "型輸入，所以實驗也同時測試了模型對彩色和黑白影像的辨識能力，檢測方\n",
      "式為當船隻出現的 3 秒內有辨識到至少 1 次則辨識成功，反之辨識失敗，同\n",
      "一部影片中辨識成功的數量與真實船隻的數量比值即為檢測率。實驗時我們\n",
      "同時比較了 1 秒內有辨識到船隻、2 秒內有辨識到船隻的檢測率以更精確地\n",
      "測量模型的辨識能力，以下為檢測效果。 \n",
      " \n",
      "表四、實驗結果檢測率 \n",
      "測試影片 1 秒內檢測率 2 秒內檢測率 3 秒內檢測率 \n",
      "彩色影片 output_005 1.0 1.0 1.0 \n",
      "彩色影片 output_041 1.0 1.0 1.0 \n",
      "彩色影片 output_080 1.0 1.0 1.0 \n",
      "彩色影片 output_097 1.0 1.0 1.0 \n",
      "黑白影片 output_199 0.67 1.0 1.0 \n",
      "黑白影片 output_202 0.67 1.0 1.0 \n",
      "黑白影片 output_276 1.0 1.0 1.0 \n",
      "黑白影片 output_290 0.75 0.75 1.0 \n",
      " \n",
      "    如上表所示，原要求的 3 秒內檢測率全部達標，都為 1.0，2 秒與 1 秒\n",
      "內的檢測率也大部分都是 1.0，其中判錯的情況都是在船隻彼此重疊時或影\n",
      "像較模糊時發生，一般的應用情況幾乎不會有問題。13 \n",
      " \n",
      " \n",
      "圖三、彩色影片 output_005 第一秒影像 \n",
      "    彩色影片 output_005 的第一秒影像如上圖所示，圖中模型成功辨識出所\n",
      "有船隻，1~3 秒內的檢測率都為 1.0。 \n",
      " \n",
      "圖四、彩色影片 output_041 第一秒影像 \n",
      "    彩色影片 output_041 的第一秒影像如上圖所示，圖中模型成功辨識出所\n",
      "有船隻，1~3 秒內的檢測率都為 1.0。14 \n",
      " \n",
      " \n",
      "圖五、彩色影片 output_080 第一秒影像 \n",
      "    彩色影片 output_080 的第一秒影像如上圖所示，圖中模型成功辨識出所\n",
      "有船隻，1~3 秒內的檢測率都為 1.0。 \n",
      " \n",
      "圖六、彩色影片 output_097 第一秒影像 \n",
      "    彩色影片 output_097 的第一秒影像如上圖所示，圖中模型成功辨識出所\n",
      "有船隻，1~3 秒內的檢測率都為 1.0。15 \n",
      " \n",
      " \n",
      "圖七、黑白影片 output_199 第二秒影像 \n",
      "    彩色影片 output_199 的第二秒影像如上圖所示，圖中模型成功辨識出所\n",
      "有船隻，2~3 秒內的檢測率都為 1.0。 \n",
      " \n",
      "圖八、黑白影片 output_202 第二秒影像 \n",
      "    彩色影片 output_202 的第二秒影像如上圖所示，圖中模型成功辨識出所\n",
      "有船隻，2~3 秒內的檢測率都為 1.0。16 \n",
      " \n",
      " \n",
      "圖九、黑白影片 output_276 第一秒影像 \n",
      "    彩色影片 output_276 的第一秒影像如上圖所示，圖中模型成功辨識出所\n",
      "有船隻，1~3 秒內的檢測率都為 1.0。 \n",
      " \n",
      "圖十、黑白影片 output_290 第三秒影像 \n",
      "    彩色影片 output_290 的第三秒影像如上圖所示，圖中模型成功辨識出所\n",
      "有船隻，3 秒內的檢測率都為 1.0。17 \n",
      " \n",
      "表五、KPI 完成表 \n",
      "項目 達成狀況 \n",
      "1.建立 AI 分析海事觀測演算法邏輯架構 已達成 \n",
      "2.完成演算法建立，並可在本島沿海 3 公里海域內環境進行 已達成 \n",
      "3.演算結果可達以下規格標準: \n",
      "通訊傳輸速率>250kbps 以上 已達成 \n",
      "影像解析度> 640x480 已達成 \n",
      "影像幀速率≧ 10FPS 已達成 \n",
      "船隻移動速度≧15 節(30km/hr) 已達成 \n",
      "船隻辨識數量≧ 10 已達成 \n",
      "船隻辨識大小> 15m 已達成 \n",
      "船隻辨識距離≧5km 已達成 \n",
      "船隻避碰距離≧3.7km 已達成 \n",
      "船隻辨識準確度≧90% 已達成 \n",
      " \n",
      "KPI 完成表如上所示，全部項目都已完成。18 \n",
      " \n",
      "五、 結論 \n",
      "本計畫目的為設計出可以有效辨識 3 公里遠的船隻，且一次可辨識長度 15\n",
      "公尺的船隻 10 艘以上的模型，根據目前的實驗結果，模型在船隻距離、速度、\n",
      "目標數量以及避碰能力上都有達到目標，並且模型在彩色及黑白影片上的表現也\n",
      "能夠符合實際應用場域需求。19 \n",
      " \n",
      "六、 參考文獻 \n",
      "[1] Sun, Bowen, et al. \"Automatic ship object detection model based on YOLOv4 \n",
      "with transformer mechanism in remote sensing images.\" Applied Sciences vol. \n",
      "13. No. 4, p. 2488, 2023. \n",
      "[2] Yang, Defu, et al. \"A streamlined approach for intelligent ship object detection \n",
      "using EL-YOLO algorithm.\" Scientific Reports, vol. 14. No.1, p.15254, 2024. \n",
      "[3] Jiang, X., Cai, J., & Wang, B. (2024). YOLOSeaShip: a lightweight model for \n",
      "real-time ship detection. European Journal of Remote Sensing, 57(1). \n",
      "https://doi.org/10.1080/22797254.2024.2307613 \n",
      "[4] He, Guowen & Wang, Wenlong & Shi, Bowen & Liu, Shijie & Xiang, Hui & \n",
      "Wang, Xiaoyuan. (2022). An Improved YOLO v4 Algorithm-based Object \n",
      "Detection Method for Maritime Vessels. International Journal of Science and \n",
      "Engineering Applications. 11. 50-55. 10.7753/IJSEA1104.1001. \n",
      "[5] D. K. Prasad, D. Rajan, L. Rachmawati, E. Rajabaly, and C. Quek, “Video \n",
      "Processing from Electro-optical Sensors for Object Detection and Tracking in \n",
      "Maritime Environment: A Survey,” IEEE Transactions on Intelligent \n",
      "Transportation Systems (IEEE), 18 (8), 1993 - 2016, 2017. \n",
      "[6] D. K. Prasad, “Singapore Maritime Dataset, Visible On-Shore dataset,” Available \n",
      "Online: https://sites.google.com/site/dilipprasad/home/singapore-maritime-\n",
      "dataset \n",
      "[7] Winsten Jesper, Iancu Bogdan, Soloviev Valentin, & Lilius Johan. (2024). \n",
      "ABOships-PLUS [Data set]. Zenodo. https://doi.org/10.5281/zenodo.10469672 \n",
      "[8] Glenn Jocher and Jing Qiu, “Ultralytics YOLO11,” Available Online: \n",
      "https://github.com/ultralytics/ultralytics \n",
      "[9] Medium, “YOLOv11 Architecture Explained: Next-Level Object Detection with \n",
      "Enhanced Speed and Accuracy,” Available Online: https://medium.com/@nikhil-\n",
      "rao-20/yolov11-explained-next-level-object-detection-with-enhanced-speed-and-\n",
      "accuracy-2dbe2d376f71\n",
      "===\n",
      "請根據以上文件內容，模擬一位業務代表會向 TPM 詢問有關 即時辨識 24 海里內船隻平台 的1個問題或轉述的需求。\n",
      "\n",
      "---------- TextMessage (Business) ----------\n",
      "您好TPM，我這邊有個客戶對「即時海洋觀測平台」特別有興趣，他們主要是在做海上航運管理。客戶提到，他們希望這套系統不只是能辨識3公里內的船隻，而是想要擴展到能即時辨識最遠到24海里（約44公里）內的船隻。\n",
      "\n",
      "從文件裡看到目前系統是在3公里甚至5公里內辨識效果很好，但不知道對於這麼遠距離的即時辨識，有哪些挑戰會比較大？或者說，現有技術能否調整或升級來達成這樣的需求？如果能幫他們做到24海里範圍的穩定監控，像是在遠洋船隊調度或安全預警方面會有很大幫助。\n",
      "\n",
      "不曉得您看是不是可以協助我跟技術團隊聊聊，確認這部分的實際可能性或需要新增的功能，讓我跟客戶回報比較有依據？\n",
      "---------- TextMessage (ApplicationAgent) ----------\n",
      "您好，感謝您分享客戶的具體需求，這確實是一個很有意義且應用十分廣泛的目標。先讓我跟您一起想像一下，如果要達成「即時辨識最遠24海里（約44公里）內的船隻」這件事，您覺得使用者在現場的操作場景會是怎樣的？他們會在什麼時候、用什麼方式或裝置看到這些辨識結果？是不是希望系統能夠持續自動偵測並即時發出預警？或者對不同距離的船隻，有沒有分層的巡檢頻率或重點？\n",
      "\n",
      "另外，您覺得客戶最在意的成果是什麼？是辨識的準確率、辨識的數量，還是辨識的反應時間？還是有其他的安全監控或調度決策支持功能？\n",
      "\n",
      "這些使用情境的細節能幫助我們跟技術團隊更清楚了解需求的核心重點，也能對遠距離有所挑戰的部分，例如影像清晰度、傳輸延遲、環境干擾等，做出合理的溝通。\n",
      "\n",
      "您覺得這樣的想像有幫助嗎？或者還有什麼特別想補充的細節？我可以幫您整理好這些資訊，方便接下來跟技術團隊釐清可行性。\n",
      "\n",
      "初步從目前系統的描述來看，現有技術專注於3到5公里內的即時辨識，挑戰會主要在於遠距離影像的解析度與訊號品質，還有環境干擾變數增加。但必須更清楚使用場景與目標才好給出建議。\n",
      "\n",
      "期待您的回覆，讓我們能共同打造客戶期待的應用畫面。\n",
      "---------- TextMessage (Business) ----------\n",
      "謝謝您的提醒，這樣我比較能理解要怎麼幫客戶釐清。就我跟客戶的了解，他們是在運用岸邊的監控中心來管理航運跟船隊調度，主要是在日夜不停地巡檢大範圍海域。\n",
      "\n",
      "他們希望系統能持續自動掃描，並且在發現遠距離進入範圍的船隻時，能即時顯示位置並發出警示，特別關注那些航速較快或路線接近危險區域的船。對他們來說，準確率和辨識反應速度都很重要，因為這關係到後續的調度指令是否能及時發出。\n",
      "\n",
      "他們也有提到，因為24海里的範圍較大，可能會根據距離來分層管理，比如近距離的船隻會頻繁更新、遠距離的則可稍微延長掃描間隔，避免系統過於負擔。\n",
      "\n",
      "另外，夜間和惡劣天氣的辨識能力也是他們很在意的，因為影響視線的因素很多，若能提高黑白影像或低光源下的辨識準確度會是加分項。\n",
      "\n",
      "不知道這些資訊是否能幫助團隊更聚焦於遠距離即時辨識的技術挑戰和優先方向？我可以繼續跟客戶確認更多細節，再同步給您。\n",
      "---------- TextMessage (ApplicationAgent) ----------\n",
      "感謝您分享這麼詳細的使用場景與需求，這讓我對客戶的期待有了更清晰的認識。\n",
      "\n",
      "簡單整理目前的想像畫面：\n",
      "- 使用者是岸邊的監控中心操作人員，負責24小時不間斷監控約24海里（約44公里）範圍內海域的船隻動向。\n",
      "- 系統需要持續自動掃描，並能在船隻進入或快速靠近關鍵區域時，及時在螢幕上標示其位置並發出警示，協助管控及調度決策。\n",
      "- 在距離較近的地方，掃描頻率及更新速度要高，確保船隻動態能即時反映；而遠距離船隻則可以較低頻率掃描，平衡系統負載與效率。\n",
      "- 影像辨識必須涵蓋夜間及低光環境，對黑白影像或雨霧等惡劣天氣需有一定的精準度，避免錯過重要目標。\n",
      "\n",
      "基於這個使用情境，遠距離即時辨識的主要挑戰可能會包含：\n",
      "1. **影像品質與解析度**：遠距離的船隻在影像中尺寸會非常小，光線及水氣環境易降低辨識率。\n",
      "2. **傳輸與處理效率**：解析高解析度影像需要較大頻寬與計算資源，尤其是24海里範圍涵蓋面積廣。\n",
      "3. **環境干擾**：反射、波浪、霧氣等變數更顯著，會影響模型的判斷準確度。\n",
      "4. **多層次巡檢策略**：需針對不同距離船隻設定合理的掃描頻率及預警門檻，避免系統過載且保持監控效能。\n",
      "5. **低光源與夜間辨識**：必須提升模型對黑白或低光影像的準確率，可能需導入專門的影像增強或特殊感測器。\n",
      "\n",
      "接下來，我可以協助將這些情境與挑戰整理後，與技術團隊討論：\n",
      "- 現有的深度學習模型與系統架構能否直接升級支持24海里範圍？\n",
      "- 是否需要新增硬體（如更高倍數光學鏡頭、紅外感測器等）或更強運算資源？\n",
      "- 在多層掃描頻率與預警機制的設計上，技術上如何實現效能/資源的平衡？\n",
      "- 對於夜間及惡劣天氣影像的補強方法是否已有研究或方案？\n",
      "\n",
      "若您方便，我們持續透過您的協助，聽取客戶更多細節，例如：\n",
      "- 客戶目前可用的攝影設備規格？\n",
      "- 是否有嚴格的傳輸延時要求？\n",
      "- 對警示或調度指令的反應時間期望範圍？\n",
      "\n",
      "這些都將有助於技術方案更貼切實務需求與限制。\n",
      "\n",
      "期待您的回饋，我會準備好與技術團隊安排深入對話。  \n",
      "謝謝您！\n",
      "\n",
      "TERMINATE\n"
     ]
    }
   ],
   "source": [
    "# Business to Application interaction\n",
    "\n",
    "from autogen_agentchat.ui import Console\n",
    "\n",
    "with capture_print_to_file(\"log/no_rag/business_to_application_log.txt\"):\n",
    "    await Console(team1.run_stream(task=task_description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31611a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "\n",
      "以下是提供你閱讀的計畫文件：\n",
      "===\n",
      "附件四、報告格式 \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "即時海洋觀測平台開發暨AI影像數據應用服\n",
      "務主題式研發計畫 \n",
      " \n",
      "期末報告1 \n",
      " \n",
      "即時海洋觀測平台開發暨 AI 影像數據應用服務主題式研發\n",
      "計畫 \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "期末報告 \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "計畫主持人：林家瑜 助理教授     \n",
      "研究機構  ：國立中央大學資訊工程系 \n",
      "執行期間  ：113/05/01-114/04/30（請填寫合作研究計畫執行期間） \n",
      " \n",
      "(以上資料請務必以中文繕打清楚) \n",
      " \n",
      "中華民國 114 年 01 月31 日2 \n",
      " \n",
      "計畫摘要 \n",
      "    本研究致力於開發即時海洋觀測平台，並應用 AI 影像數據分析來提升遠距離船\n",
      "隻辨識的準確性與效率。現行船舶識別技術主要依賴人眼辨識，然而在 3 公里以上距\n",
      "離，由於海面反射、霧氣與光線變化等環境因素的影響，傳統方法的準確率明顯下\n",
      "降。本計畫旨在透過深度學習物件辨識技術，建立一套高效能的「即時遠距離多船隻\n",
      "辨識系統」，能夠在 3 公里外準確偵測船隻，並可同時識別 10 艘以上長度超過 15 公\n",
      "尺的船隻。 \n",
      "    本研究參考 YOLOv5s 與YOLOv8 物件辨識模型，針對海洋環境特性進行改良，\n",
      "並利用多種公開及自建數據集如 Singapore Maritime Dataset、ABOships-PLUS、高雄\n",
      "港實測數據進行模型訓練與驗證。透過影像增強、特徵提取優化與多尺度檢測技術，\n",
      "我們顯著提升了模型在複雜海洋場景中的識別能力。 \n",
      "    目前的實驗結果顯示，我們的系統在新加坡與高雄測試數據集中的部分影像皆展\n",
      "現超過 90%的識別準確度，並成功達成： \n",
      "⚫ 可偵測移動速度超過 15 節的船隻 \n",
      "⚫ 在 5 公里範圍內實現高效識別 \n",
      "⚫ 可即時處理 640×480 解析度影像，幀率≥10FPS \n",
      "⚫ 具備船隻避碰預警功能 \n",
      "    未來將進一步提升船隻辨識與船隻避碰預測的準確度，並擴充模型至夜間與黑白\n",
      "影像辨識，以提升即時監測與應用能力。此技術的發展對於海洋交通安全監控、智慧\n",
      "港口管理與海上救援應用將具備重要價值。 \n",
      " \n",
      "關鍵字：即時海洋觀測、AI 影像辨識、深度學習、YOLOv5、YOLOv8、多尺度檢\n",
      "測、船隻辨識、避碰預警、智慧港口、遠距離監測3 \n",
      " \n",
      "目錄 \n",
      "計畫摘要 ....................................................................................................................... 2 \n",
      "一、計畫動機與目的 ................................................................................................... 4 \n",
      "1. 動機 ..................................................................................................................... 4 \n",
      "2. 目的 ..................................................................................................................... 4 \n",
      "二、文獻探討 ............................................................................................................... 5 \n",
      "三、研究方法 ............................................................................................................... 8 \n",
      "1. 資料收集 ............................................................................................................. 8 \n",
      "2. 資料前處理 ....................................................................................................... 10 \n",
      "3. 船隻辨識模型 ................................................................................................... 10 \n",
      "四、實驗結果 ............................................................................................................. 12 \n",
      "五、結論 ..................................................................................................................... 18 \n",
      "六、參考文獻 ............................................................................................................. 194 \n",
      " \n",
      "一、 計畫動機與目的 \n",
      "1. 動機 \n",
      "在海洋環境中，對於船隻的及時且準確的辨識是保障航行安全和有效執\n",
      "行海上作業的關鍵。但目前大部分的船隻都是人工辨識，而人眼無法同時看\n",
      "超過 10 艘船隻進行辨識，因此需要 AI 輔助。現有的 AI 對距離近且較大的\n",
      "船或是俯視角的衛星雷達成像的船有不錯的辨識能力，但若是在第一人稱且\n",
      "距離超過 3 公里的情況下，可能會受到環境條件如海面反射、霧氣、光線變\n",
      "化等的影響，導致偵測的準確度降低，且現有開放資料集大多是較大的船隻\n",
      "，3 公里以上的船隻資料集較少，不利於訓練模型。 \n",
      "2. 目的 \n",
      "基於上述的問題，本計畫欲設計一套「即時遠距離多船隻辨識系統」 ，\n",
      "此系統可以有效辨識 3 公里遠的船隻，且一次可辨識長度15 公尺的船隻 10\n",
      "艘以上。5 \n",
      " \n",
      "二、 文獻探討 \n",
      "現在有一些研究採用物件辨識模型進行船隻辨識，在 Automatic Ship \n",
      "Object Detection Model Based on YOLOv4 with Transformer Mechanism in \n",
      "Remote Sensing Images 論文中提出了名為 Auto-T-YOLO 的架構[1]，用於解\n",
      "決現有物件偵測模型從輸入中提取特徵未能充分考慮全局特徵，且無法根據\n",
      "輸入的特徵自動調整，導致偵測準確度下降的問題。 \n",
      "    Auto-T-YOLO 的模型架構分為三個部分 ，Preattention, Attention 和\n",
      "Prediction。輸入影像大小為608×608×3，Preattention 和 Attention 的設計\n",
      "模仿了人類視覺系統中從大的全局特徵開始，再逐步轉向局部細節的兩階段\n",
      "注意機制。 \n",
      "    在 Preattention 架構中，輸入的圖像會根據其中是否包含𝑠𝑖𝑧𝑒 > 32×32\n",
      "的物件分為 A 子資料集及 B 子資料集，並在之後的 Attention 架構中根據其\n",
      "所在的子資料集做不同的影像處理。 \n",
      "    Attention 架構主要參考了 YOLOv4 的 Backbone 及 Neck 架構來設計，\n",
      "A 子資料集及 B 子資料集在 Backbone 中的處理流程相同，都是利用一層\n",
      "CBM 進行卷積運算以及五層 CSPDarknet53 進行殘差及卷積運算來提取特\n",
      "徵同時防止梯度消失，由於YOLOv4 的 CBL 架構基於卷積運算，而卷積運\n",
      "算受限於 Kernel 大小，因此無法很好地提取全局特徵，所以 A 子資料集在\n",
      "Neck 中 SPP 架構輸出之後使用了 Transformer 中的 Multi-head Self-Attention\n",
      "架構取代了 CBL，稱為 SPP-MHSA，其中 Multi-head Self-Attention 使用了\n",
      "四個 head。Neck 的後半段與 YOLOv4 相似，使用了 FPN 做 Upsampling、\n",
      "PANet 做 downsampling 以提升多尺度目標檢測的能力。 \n",
      "    Prediction 架構用來對 PANet 輸出做多尺度目標檢測，損失函數使用了\n",
      "CIoU 以及 DIoU-NMS。模型準確度在 SSDD 資料集、近海及遠海場景上分\n",
      "別達到了 96.3%、91.78%以及 98.33%。 \n",
      " 在另一篇論文 A streamlined approach for intelligent ship object detection \n",
      "using EL -YOLO algorithm 中提出了 EL-YOLO 的架構[2]，用於提升目標檢\n",
      "測在具有波浪、反射等複雜海洋環境中對於小物體的檢測精度，其輕量化的\n",
      "網路架構在硬體運算資源有限的智慧船舶、無人船舶等領域也有良好的適應\n",
      "性。 \n",
      "EL-YOLO 的架構基於 YOLOv8 進行改進，輸入影像大小為640×640\n",
      "，包含了Backbone、Neck、Head 三個部分，Backbone 中與 YOLOv8 相同，\n",
      "使用了一層CBS 進行卷積運算和四層CBS 加C2f 進行殘差及卷積運算來提\n",
      "取特徵同時防止梯度消失。 \n",
      "在 Neck 部分，因為傳統的 FPN 和 PAN 架構在面對因反射或波浪等背\n",
      "景干擾因素導致特徵信息不足的目標時，容易在多層卷積過程中丟失信息，\n",
      "導致檢測精度下降，所以作者提出了 SMFN (short multi‑fuse neck )架構，在6 \n",
      " \n",
      "YOLOv8 的基礎上，額外加入了較大尺寸的兩個輸入 (320×320和160×\n",
      "160)、一個 Upsampling 層(160×160) 、一個 Fusion 加 C2f 層(160×160)\n",
      "、一個卷積層(80×80)及一個輸出(160×160)到 FPN 和 PAN 架構中，以\n",
      "捕捉更多的特徵信息，並提高對小型目標的檢測能力。 \n",
      "Head 架構因為 Neck 的 SMFN 架構而多了一個160×160的輸出，相較\n",
      "原本只有三個輸出的 YOLOv8 多了一個。在損失函數的部分，因為傳統的\n",
      "CIoU 在處理特徵信息不足的目標時 往往會過度懲罰， 因此作者提出了\n",
      "AWIoU(adequate wise IoU )，通過動態分配不同權重給不同特徵信息量的目\n",
      "標來調整懲罰，避免目標因受背景干擾而造成模型誤判。 \n",
      "在模型訓練完後，為了使其網路架構輕量化以應用於硬體運算資源有限\n",
      "的智慧船舶 、 無人船舶等領域，作者提出了GDFP(Greedy-driven filter pruning)\n",
      "，首先計算每一層中所有 filter 的 L1 範數以得到其重要性分數，並將分數最\n",
      "低的 filter 刪除，在刪除後對模型重新評估，並重複以上操作直到得到理想\n",
      "的模型，最後重新訓練該模型，以得到將模型輕量化的效果。 \n",
      "此模型在 SeaShips 資料集上的mAP0.5 為 0.988， mAP0.5:0.95 為 0.778\n",
      "，在 ABOships 資料集上的mAP0.5 為 0.672，mAP0.5:0.95 為 0.348。 \n",
      "另一篇論文  YOLOSeaShip: a lightweight model for real -time ship \n",
      "detection [3]中提出了 YOLOSeaShip 的架構，用於解決海洋環境中目標檢測\n",
      "的準確性與硬體資源需求之間的矛盾，特別是在實時性要求較高且硬體運算\n",
      "能力有限的應用場景如邊境監控、智慧海洋交通中。 \n",
      "    YOLOSeaShip 的架構基於 YOLOv7-tiny 進行改進，包含了 Input、\n",
      "Backbone 和 Head 三個主要部分。 \n",
      "Input 架構上採用了 Mosaic 數據增強技術，通過隨機裁剪並拼接多張影\n",
      "像，增加數據的多樣性與小目標樣本數。此外，使用自適應圖片縮放技術來\n",
      "處理不同尺度的目標，並結合K-means 分群方法優化錨框的尺寸設定，避免\n",
      "人工設計過程中的偏差。 \n",
      "Backbone 的部分，YOLOSeaShip 引入了 PConv（Partial Convolution ）\n",
      "架構替代了原本的卷積操作。該架構僅對部分通道進行計算，從而有效減少\n",
      "了參數量並提升計算效率。此外，每層池化操作後 還加入了 PfAAM（\n",
      "Parameter-Free Average Attention Module）。PfAAM 基於空間和通道的平均值\n",
      "計算注意力權重，不增加模型參數的情況下提升了模型對關鍵區域的定位能\n",
      "力。 \n",
      "Head 部分，模型加入了SPPCSPC_tiny 架構，通過多尺度（5×5、9×9 和\n",
      "13×13）最大池化層結合本地與全局特徵，增強對不同大小目標的檢測能力\n",
      "。模型的最終輸出包含三個不同大小的特徵圖，用於處理不同尺度的目標檢\n",
      "測。 \n",
      "在損失函數設計上，作者提出了 Focal EIOU（Focal and Efficient IOU）\n",
      "損失函數，結合了 EIOU 和 Focal Loss 的優點。EIOU 損失通過細化目標框7 \n",
      " \n",
      "的寬高比差異來提升回歸精度，而Focal Loss 則用於平衡正負樣本比例，讓\n",
      "模型更關注高質量的預測框。 \n",
      "為了評估模型性能，作者在 SeaShips(7000)資料集上進行實驗，訓練時\n",
      "採用 Adam 優化器，學習率為 0.001，訓練 300 個 epoch。結果顯示，\n",
      "YOLOSeaShip 的 mAP 達到 0.976，檢測速度達到119.84 FPS，相較YOLOv7-\n",
      "tiny 模型，參數量減少至 4.78M，同時大幅提升了檢測速度和資源效率。 \n",
      "在論文 An Improved YOLO v4 Algorithm-based Object Detection Method \n",
      "for Maritime Vessels[4]中提出了基於改進 YOLOv4 的船舶和泊位檢測方法，\n",
      "用於提升目標檢測在複雜海洋環境下的準確性，特別是對港口泊位的檢測效\n",
      "果進行了優化。該方法通過改良 錨框的生成方式和數據集構建，改善了\n",
      "YOLOv4 在海洋場景中的檢測性能，適用於智能船舶的安全輔助系統。 \n",
      "改進的 YOLOv4 架構包含了 Backbone、Neck 和 Head 三個部分。\n",
      "Backbone 部分採用了 CSPDarknet53 作為特徵提取模塊，通過 ResUnit 組件\n",
      "進行深度卷積操作，增強特徵提取能力。Neck 部分引入了 SPP 層和 PANet\n",
      "層，其中 SPP 層通過多尺度池化操作擴展感受野，而 PANet 則將底層的定\n",
      "位信息與高層的語義信息結合，提高多尺度目標的檢測能力。Head 部分則\n",
      "採用了 YOLOv3 的檢測頭，輸出不同尺度的檢測結果。 \n",
      "針對泊位檢測效果不足的問題，作者採用了 K-means 演算法重新生成\n",
      "錨框。在原始 YOLOv4 模型中，錨框基於 MS COCO 和 VOC 數據集生成，\n",
      "但這些框與船舶與泊位數據集中的物體尺寸不匹配，影響了檢測精度。改進\n",
      "後的 K-means 演算法針對數據集進行分群，生成了9 組適配的錨框，有效提\n",
      "升了檢測效率和準確性。 \n",
      "此外，作者構建了一個包含船舶和泊位的專用數據集，通過智能實驗船\n",
      "上的攝像頭在港口拍攝的實景影像生成，並結合公開數據集如MS COCO 和\n",
      "VOC 補充正樣本數量。最終數據集中包含6634 張標註影像，其中70%用於\n",
      "訓練，30%用於測試。標註信息包括物體類別及邊界框的坐標和尺寸。 \n",
      "實驗結果表明，改進的YOLOv4 模型在 mAP 和 F1-score 方面分別提升\n",
      "了 2.79%和 0.80%，相較於原始YOLOv4 達到了更高的檢測精度與穩定性。\n",
      "具體指標顯示，改進後的YOLOv4 模型在 mAP 上達到 83.98%，F1-score 達\n",
      "到 86.18%，而 YOLOv4_tiny 僅達到 54.45%的 mAP 和 54.82%的 F1-score，\n",
      "說明輕量化模型雖然具有更快的檢測速度，但在檢測準確性上仍有進步空間\n",
      "。8 \n",
      " \n",
      "三、 研究方法 \n",
      "1. 資料收集 \n",
      "    資料集使用 Singapore Maritime Dataset 的 Visible On-Shore 資料集[5, 6]加上\n",
      "ABOships-PLUS[7]以及手動標註公司提供的高雄資料集。 \n",
      "    Visible On-Shore 資料集為網路上的公開資料集，包含 38 部長度小於 33 秒\n",
      "的全彩影片，屬於中、遠港船隻影像資料集，其中含有 7 個船隻類別，此資料集\n",
      "特徵為船隻背景為海面、天空等較乾淨的畫面。 \n",
      " \n",
      "表一、Visible On-Shore 資料集類別 \n",
      "Lable Data   \n",
      "Ferry \n",
      " \n",
      "SailsBoat \n",
      " \n",
      "PatrolBoat \n",
      " \n",
      "MerchantShip \n",
      " \n",
      "FishingBoat \n",
      " \n",
      "Tugboat \n",
      " \n",
      "BargeShip9 \n",
      " \n",
      "    ABOships-PLUS 資料集為網路上的公開資料集，ABOships 資料集的改進版\n",
      "本，包含 9880 張影像，33227 個標註，屬於近港船隻影像資料集，其中含有 3 個\n",
      "船隻類別，此資料集特徵為船隻背景包含陸地建築物等容易誤判的畫面。 \n",
      " \n",
      "表二、ABOships-PLUS 資料集類別 \n",
      "Lable Data   \n",
      "powerboat \n",
      " \n",
      "sailboat \n",
      " \n",
      "ship \n",
      " \n",
      "  \n",
      " \n",
      "    高雄資料集為高雄實地拍攝的非公開資料集，包含 504 部長度小於 10 秒的\n",
      "影片，屬於近、中港船隻影像資料集，其中含有 4 個船隻類別，此資料集特徵為\n",
      "船隻背景包含陸地建築物等容易誤判的畫面。 \n",
      " \n",
      "表三、高雄資料集類別 \n",
      "Lable Data   \n",
      "PatrolBoat \n",
      " \n",
      "Yacht \n",
      " \n",
      "MerchantShip \n",
      " \n",
      "Tugboat10 \n",
      " \n",
      "2. 資料前處理 \n",
      "    \n",
      " \n",
      "圖一、資料前處理流程圖。 \n",
      "    如圖一所示，首先會將資料集處理成只包含 images 和 labels 資料夾的\n",
      "形式，images 和 labels 中的檔案是兩兩對應的，並且labels 內的標註檔格式\n",
      "為 yolo 格式。再來會刪除有問題的標註檔及圖片，例如標註檔為空、包含\n",
      "不存在類別、格式錯誤、圖片模糊或者有破圖情況等。第三步是合併資料集\n",
      "，這步是可選的，主要會將數個資料集合併，並記錄合併後的類別名稱。第\n",
      "四步是篩選類別，這步同樣為可選，主要會將需要的類別保留，不需要的剔\n",
      "除。接著因為同一圖片中可能包含數量不等的不同類別物件，因此在切分訓\n",
      "練集和驗證集時，容易造成不同類別的訓練驗證比例不同的情況，所以第五\n",
      "步會將包含 n 個物件的標註檔拆分成 n 份，每一份只包含1 個原始標註檔的\n",
      "物件，彼此不重複，且與其對應的圖片同樣複製 n 份，以確保每個類別都按\n",
      "照正確比例進行切分，最後一步為按照自訂比例切分訓練集及驗證集。 \n",
      "3. 船隻辨識模型 \n",
      "    我們使用了最新的YOLOv11[8]模型來建置船隻辨識模型 ，YOLOv11 基\n",
      "於 PyTorch 架構開發，可在一次前向傳播中同時定位及辨識物件，具有速度\n",
      "快、所需資源少、開發便利及多尺度檢測等優點。圖二為 YOLOv11 架構圖\n",
      "，首先輸入的圖片為 640x640x3 的 RGB 圖像，接著 YOLOv11 可以根據此\n",
      "架構分為三個部分，Backbone, Neck 以及 Head。11 \n",
      " \n",
      " \n",
      "圖二、YOLOv11 架構圖[9] \n",
      " \n",
      "Backbone 如圖二左側所示，主要目的是從輸入影像中提取有用的特徵\n",
      "資訊。在 YOLOv11 中，Backbone 採用了 C3K2 結構，為升級版的 C3，透\n",
      "過更小的卷積核與路徑切分技術，在保持模型表現的前提下大幅降低了計算\n",
      "成本。每個C3K2 中包含兩條路徑，一條直接進行卷積處理，另一條則經過\n",
      "多個 Bottleneck 區塊進行深度特徵學習，最後進行特徵融合。這種結構不僅\n",
      "有效防止梯度消失問題，也能提升網路的收斂速度與特徵提取效率。 \n",
      "Neck 部分如圖二中間所示，結合了 SPFF(Spatial Pyramid Pooling Fast)\n",
      "架構和多層 C2PSA 區塊。SPFF 架構是 SPP 的高速版本，透過不同尺度的\n",
      "最大池化操作將特徵圖進行多尺度融合，再透過 Concatenation 將資訊彙整\n",
      "，幫助模型更好地識別大小不一的船隻。此外，Neck 中的 C2PSA 架構引入\n",
      "空間注意力機制(Spatial Attention)，能讓模型聚焦在關鍵影像區域，特別是\n",
      "對小型或部分遮蔽的物件表現更佳。這部分的架構延續了FPN 與 PAN 的優\n",
      "點，強化了從深層到淺層、再回到深層的資訊傳遞，進一步提升辨識與定位\n",
      "的能力。 \n",
      "Head 如圖二右側所示，負責進行最後的物件偵測任務。YOLOv11 採用\n",
      "多尺度輸出策略，透過多層輸出特徵圖分別負責不同大小目標的偵測。\n",
      "YOLOv11 會利用不同尺寸與比例的錨框(Anchor Boxes)來涵蓋不同形狀的\n",
      "目標，並透過 Non-Maximum Suppression(NMS)過濾重疊的邊界框，保留最\n",
      "具代表性的偵測結果。12 \n",
      " \n",
      "四、 實驗結果 \n",
      "    我們使用 YOLOv11l 模型，訓練集使用 ABOships-PLUS，測試集使用\n",
      "高雄資料集，實驗環境為 64-bit Windows 11、Intel i5-13400F 2.5GHz CPU、\n",
      "32GB RAM 及 NVIDIA RTX 4070 GPU。除了測試模型在原先新加坡資料集\n",
      "的效果外，實驗還在高雄資料集上針對船隻速度、距離以及避碰能力做檢測\n",
      "，因實際場域在白天時使用的是彩色影像，黑夜時使用的是黑白影像當作模\n",
      "型輸入，所以實驗也同時測試了模型對彩色和黑白影像的辨識能力，檢測方\n",
      "式為當船隻出現的 3 秒內有辨識到至少 1 次則辨識成功，反之辨識失敗，同\n",
      "一部影片中辨識成功的數量與真實船隻的數量比值即為檢測率。實驗時我們\n",
      "同時比較了 1 秒內有辨識到船隻、2 秒內有辨識到船隻的檢測率以更精確地\n",
      "測量模型的辨識能力，以下為檢測效果。 \n",
      " \n",
      "表四、實驗結果檢測率 \n",
      "測試影片 1 秒內檢測率 2 秒內檢測率 3 秒內檢測率 \n",
      "彩色影片 output_005 1.0 1.0 1.0 \n",
      "彩色影片 output_041 1.0 1.0 1.0 \n",
      "彩色影片 output_080 1.0 1.0 1.0 \n",
      "彩色影片 output_097 1.0 1.0 1.0 \n",
      "黑白影片 output_199 0.67 1.0 1.0 \n",
      "黑白影片 output_202 0.67 1.0 1.0 \n",
      "黑白影片 output_276 1.0 1.0 1.0 \n",
      "黑白影片 output_290 0.75 0.75 1.0 \n",
      " \n",
      "    如上表所示，原要求的 3 秒內檢測率全部達標，都為 1.0，2 秒與 1 秒\n",
      "內的檢測率也大部分都是 1.0，其中判錯的情況都是在船隻彼此重疊時或影\n",
      "像較模糊時發生，一般的應用情況幾乎不會有問題。13 \n",
      " \n",
      " \n",
      "圖三、彩色影片 output_005 第一秒影像 \n",
      "    彩色影片 output_005 的第一秒影像如上圖所示，圖中模型成功辨識出所\n",
      "有船隻，1~3 秒內的檢測率都為 1.0。 \n",
      " \n",
      "圖四、彩色影片 output_041 第一秒影像 \n",
      "    彩色影片 output_041 的第一秒影像如上圖所示，圖中模型成功辨識出所\n",
      "有船隻，1~3 秒內的檢測率都為 1.0。14 \n",
      " \n",
      " \n",
      "圖五、彩色影片 output_080 第一秒影像 \n",
      "    彩色影片 output_080 的第一秒影像如上圖所示，圖中模型成功辨識出所\n",
      "有船隻，1~3 秒內的檢測率都為 1.0。 \n",
      " \n",
      "圖六、彩色影片 output_097 第一秒影像 \n",
      "    彩色影片 output_097 的第一秒影像如上圖所示，圖中模型成功辨識出所\n",
      "有船隻，1~3 秒內的檢測率都為 1.0。15 \n",
      " \n",
      " \n",
      "圖七、黑白影片 output_199 第二秒影像 \n",
      "    彩色影片 output_199 的第二秒影像如上圖所示，圖中模型成功辨識出所\n",
      "有船隻，2~3 秒內的檢測率都為 1.0。 \n",
      " \n",
      "圖八、黑白影片 output_202 第二秒影像 \n",
      "    彩色影片 output_202 的第二秒影像如上圖所示，圖中模型成功辨識出所\n",
      "有船隻，2~3 秒內的檢測率都為 1.0。16 \n",
      " \n",
      " \n",
      "圖九、黑白影片 output_276 第一秒影像 \n",
      "    彩色影片 output_276 的第一秒影像如上圖所示，圖中模型成功辨識出所\n",
      "有船隻，1~3 秒內的檢測率都為 1.0。 \n",
      " \n",
      "圖十、黑白影片 output_290 第三秒影像 \n",
      "    彩色影片 output_290 的第三秒影像如上圖所示，圖中模型成功辨識出所\n",
      "有船隻，3 秒內的檢測率都為 1.0。17 \n",
      " \n",
      "表五、KPI 完成表 \n",
      "項目 達成狀況 \n",
      "1.建立 AI 分析海事觀測演算法邏輯架構 已達成 \n",
      "2.完成演算法建立，並可在本島沿海 3 公里海域內環境進行 已達成 \n",
      "3.演算結果可達以下規格標準: \n",
      "通訊傳輸速率>250kbps 以上 已達成 \n",
      "影像解析度> 640x480 已達成 \n",
      "影像幀速率≧ 10FPS 已達成 \n",
      "船隻移動速度≧15 節(30km/hr) 已達成 \n",
      "船隻辨識數量≧ 10 已達成 \n",
      "船隻辨識大小> 15m 已達成 \n",
      "船隻辨識距離≧5km 已達成 \n",
      "船隻避碰距離≧3.7km 已達成 \n",
      "船隻辨識準確度≧90% 已達成 \n",
      " \n",
      "KPI 完成表如上所示，全部項目都已完成。18 \n",
      " \n",
      "五、 結論 \n",
      "本計畫目的為設計出可以有效辨識 3 公里遠的船隻，且一次可辨識長度 15\n",
      "公尺的船隻 10 艘以上的模型，根據目前的實驗結果，模型在船隻距離、速度、\n",
      "目標數量以及避碰能力上都有達到目標，並且模型在彩色及黑白影片上的表現也\n",
      "能夠符合實際應用場域需求。19 \n",
      " \n",
      "六、 參考文獻 \n",
      "[1] Sun, Bowen, et al. \"Automatic ship object detection model based on YOLOv4 \n",
      "with transformer mechanism in remote sensing images.\" Applied Sciences vol. \n",
      "13. No. 4, p. 2488, 2023. \n",
      "[2] Yang, Defu, et al. \"A streamlined approach for intelligent ship object detection \n",
      "using EL-YOLO algorithm.\" Scientific Reports, vol. 14. No.1, p.15254, 2024. \n",
      "[3] Jiang, X., Cai, J., & Wang, B. (2024). YOLOSeaShip: a lightweight model for \n",
      "real-time ship detection. European Journal of Remote Sensing, 57(1). \n",
      "https://doi.org/10.1080/22797254.2024.2307613 \n",
      "[4] He, Guowen & Wang, Wenlong & Shi, Bowen & Liu, Shijie & Xiang, Hui & \n",
      "Wang, Xiaoyuan. (2022). An Improved YOLO v4 Algorithm-based Object \n",
      "Detection Method for Maritime Vessels. International Journal of Science and \n",
      "Engineering Applications. 11. 50-55. 10.7753/IJSEA1104.1001. \n",
      "[5] D. K. Prasad, D. Rajan, L. Rachmawati, E. Rajabaly, and C. Quek, “Video \n",
      "Processing from Electro-optical Sensors for Object Detection and Tracking in \n",
      "Maritime Environment: A Survey,” IEEE Transactions on Intelligent \n",
      "Transportation Systems (IEEE), 18 (8), 1993 - 2016, 2017. \n",
      "[6] D. K. Prasad, “Singapore Maritime Dataset, Visible On-Shore dataset,” Available \n",
      "Online: https://sites.google.com/site/dilipprasad/home/singapore-maritime-\n",
      "dataset \n",
      "[7] Winsten Jesper, Iancu Bogdan, Soloviev Valentin, & Lilius Johan. (2024). \n",
      "ABOships-PLUS [Data set]. Zenodo. https://doi.org/10.5281/zenodo.10469672 \n",
      "[8] Glenn Jocher and Jing Qiu, “Ultralytics YOLO11,” Available Online: \n",
      "https://github.com/ultralytics/ultralytics \n",
      "[9] Medium, “YOLOv11 Architecture Explained: Next-Level Object Detection with \n",
      "Enhanced Speed and Accuracy,” Available Online: https://medium.com/@nikhil-\n",
      "rao-20/yolov11-explained-next-level-object-detection-with-enhanced-speed-and-\n",
      "accuracy-2dbe2d376f71\n",
      "===\n",
      "簡單整理目前的想像畫面：\n",
      "- 使用者是岸邊的監控中心操作人員，負責24小時不間斷監控約24海里（約44公里）範圍內海域的船隻動向。\n",
      "- 系統需要持續自動掃描，並能在船隻進入或快速靠近關鍵區域時，及時在螢幕上標示其位置並發出警示，協助管控及調度決策。\n",
      "- 在距離較近的地方，掃描頻率及更新速度要高，確保船隻動態能即時反映；而遠距離船隻則可以較低頻率掃描，平衡系統負載與效率。\n",
      "- 影像辨識必須涵蓋夜間及低光環境，對黑白影像或雨霧等惡劣天氣需有一定的精準度，避免錯過重要目標。\n",
      "\n",
      "基於這個使用情境，遠距離即時辨識的主要挑戰可能會包含：\n",
      "1. **影像品質與解析度**：遠距離的船隻在影像中尺寸會非常小，光線及水氣環境易降低辨識率。\n",
      "2. **傳輸與處理效率**：解析高解析度影像需要較大頻寬與計算資源，尤其是24海里範圍涵蓋面積廣。\n",
      "3. **環境干擾**：反射、波浪、霧氣等變數更顯著，會影響模型的判斷準確度。\n",
      "4. **多層次巡檢策略**：需針對不同距離船隻設定合理的掃描頻率及預警門檻，避免系統過載且保持監控效能。\n",
      "5. **低光源與夜間辨識**：必須提升模型對黑白或低光影像的準確率，可能需導入專門的影像增強或特殊感測器。\n",
      "\n",
      "---------- TextMessage (TechnicalAgent) ----------\n",
      "根據提供的計畫文件與使用情境描述，以下提出兩種可行的技術組合方案，針對遠距離即時海洋監控與AI影像辨識的需求：\n",
      "\n",
      "---\n",
      "\n",
      "## 方案一：多階段影像分級辨識系統（分層掃描+多模型融合）\n",
      "\n",
      "### 適用條件\n",
      "\n",
      "- 監控範圍廣（24海里約44公里），需兼顧即時性與系統負載平衡\n",
      "- 高頻率近距離掃描與低頻率遠距離掃描混合需求\n",
      "- 環境條件變化大（霧氣、光線波動、夜間低光）\n",
      "- 需要較強的擴展性以因應未來多來源資料融合（如雷達、AIS數據等）\n",
      "\n",
      "### 核心模組與系統層級流程\n",
      "\n",
      "1. **影像資料采集模組**\n",
      "    - 多組不同焦段與解析度的攝影機（如固定長焦鏡頭+廣角鏡頭）\n",
      "    - 可搭配紅外線或熱成像以補足夜間及惡劣天氣的影像品質不足\n",
      "\n",
      "2. **分層掃描排程模組**\n",
      "    - 根據距離分為近距離（<5公里）、中距離（5-15公里）、遠距離（>15公里）三層\n",
      "    - 近距離區域實施高頻率多角度掃描，遠距離區域則採用低頻率掃描策略，減少計算與頻寬負擔\n",
      "\n",
      "3. **多模型融合辨識模組**\n",
      "    - 近距離採用輕量化高速模型（例如方案文件中的 YOLOSeaShip 或 YOLOv11 Tiny 版本）進行快速辨識\n",
      "    - 遠距離及黑白影像使用經過訓練的深度學習模型（如改良版 YOLOv11 搭配多尺度檢測和空間注意力機制）\n",
      "    - 利用後端融合器（Ensemble Mechanism）整合不同模型輸出，提升整體識別準確率及穩定性\n",
      "\n",
      "4. **影像增強與預處理模組**\n",
      "    - 包含去霧、去反光、影像超分辨率重建等技術協助提升極端環境下的影像質量\n",
      "    - 夜間黑白影像利用專門的圖像強化演算法進行處理增加辨識效果\n",
      "\n",
      "5. **事件偵測與預警模組**\n",
      "    - 建立基於空間位置與速度的船隻動態追蹤系統（融合Kalman Filter或Deep SORT等演算法）\n",
      "    - 設定多重預警規則（如船隻進入特定區域、速度異常等），並透過即時視覺界面與告警系統通報操作人員\n",
      "\n",
      "6. **後端服務與數據管理**\n",
      "    - 高擴展性的雲端或邊緣計算平台部署\n",
      "    - 支援海量影像資料存取、模型線上更新與訓練數據管理\n",
      "\n",
      "### 擴展性與彈性\n",
      "\n",
      "- 支援新增其他影像感測器（紅外線、雷達）或融合AIS等多元數據源，提升系統穩定性和警示誤報率降低\n",
      "- 採取模組化架構便於後續替換或升級辨識模型\n",
      "- 動態調整掃描頻率與影像解析度，依運算能力及網路狀態彈性調整\n",
      "\n",
      "### 潛在風險與限制\n",
      "\n",
      "- 高頻率掃描及多模型計算帶來較大運算與網路負擔，須做好硬體資源規劃\n",
      "- 複雜模組間協調與同步難度高，尤其是在多模型結果融合與事件觸發邏輯設計\n",
      "- 黑白及惡劣天氣影像辨識仍面臨準確率下降問題，需持續優化影像增強及模型訓練\n",
      "- 資安面需嚴格管控影像資料傳輸與存取權限，防止敏感資料外洩\n",
      "\n",
      "---\n",
      "\n",
      "## 方案二：端側輕量化即時辨識+中央集中式智慧決策平台\n",
      "\n",
      "### 適用條件\n",
      "\n",
      "- 海域監控點分散，現場設置運算能力有限的裝置\n",
      "- 需降低即時影像傳輸量以節省通訊頻寬與延遲\n",
      "- 具備集中彙整多點資料進行高階分析與調度的需求\n",
      "\n",
      "### 核心模組與系統層級流程\n",
      "\n",
      "1. **前端端側辨識裝置**\n",
      "    - 在各岸邊或浮標配備輕量化GPU或AI加速模組（如NVIDIA Jetson系列）\n",
      "    - 部署輕量化、速度優先的模型（例如方案文件中提及的 YOLOSeaShip 或剪裁版 YOLOv11）\n",
      "    - 端側即時處理採集的影像，執行目標檢測與追蹤，先行過濾與標定船隻訊息（位置、速度、類別）\n",
      "\n",
      "2. **資料壓縮與傳輸模組**\n",
      "    - 僅將辨識後的船隻資料（坐標、速度、警示狀態）及關鍵影像片段上傳至中央平台，減少頻寬需求\n",
      "    - 傳輸使用安全加密通道，保護資料隱私與完整性\n",
      "\n",
      "3. **中央智慧決策平台**\n",
      "    - 負責整合多個端側裝置匯入的資訊，進行多點船隻動態整合與碰撞預測\n",
      "    - 利用更大型的深度學習模型或統計模型，執行複雜預警分析與資源調度建議\n",
      "    - 操作介面顯示整合後的海域監控地圖與警報通知\n",
      "\n",
      "4. **夜間及惡劣氣象補充機制**\n",
      "    - 中央平台協調前端感測器切換或補充（熱成像或雷達資料混合）\n",
      "    - 可在特殊情況下遠端調用更高階模型進行重檢驗或調整端側模型參數\n",
      "\n",
      "### 擴展性與彈性\n",
      "\n",
      "- 易於分布式擴充，多個端點可逐步增加部署維護\n",
      "- 中央平台可以加入AI模型持續更新，端側裝置亦可透過遠端下發模型更新\n",
      "- 結構適合有多廠商或多系統接入，利於系統整合及擴展\n",
      "\n",
      "### 潛在風險與限制\n",
      "\n",
      "- 端側裝置硬體性能受限，可能限制辨識模型的精度及複雜度\n",
      "- 中央與多端點間的網路連線穩定性影響系統整體運作與即時性\n",
      "- 端側影像品質提升受限（硬體感測器限制、影像增強能力較弱）\n",
      "- 系統整合複雜度高，需要嚴格設計通訊協議與容錯機制\n",
      "- 資安風險增加，需重視多點資料同步安全與權限控管措施\n",
      "\n",
      "---\n",
      "\n",
      "以上兩方案皆建立於計畫中深度學習模型及資料集基礎，並兼顧使用者需求與系統實際運作條件，具備不同策略側重點：\n",
      "\n",
      "- 方案一強調後端集中深度運算與多模態融合，適合硬體資源豐富與統一運維環境\n",
      "- 方案二強調端側計算分擔負載與中樞智慧整合，適合分散式部署及有限通訊帶寬環境\n",
      "\n",
      "---\n",
      "\n",
      "請依據您的實際系統架構喜好與部署環境，選擇適合方案，我將依此進行進一步的任務拆解與交付規劃。若有缺少關鍵資訊，也請補充說明，有助於方案細化。\n",
      "---------- TextMessage (ApplicationAgent) ----------\n",
      "感謝您提出的兩套技術組合方案，針對遠距離即時海洋監控及AI影像辨識需求，我針對業務使用情境補充以下分析建議：\n",
      "\n",
      "---\n",
      "\n",
      "### 從使用情境角度判斷方案適用性主軸\n",
      "\n",
      "1. **系統即時反應與持續監控需求**\n",
      "   - 業務描述需24小時不間斷監控約44公里海域，且需快速標示與警示靠近關鍵區域船隻。  \n",
      "   - 方案一以集中式多模型融合和多層掃描調度，能做細緻調整，同時兼顧頻率和精準度，但計算資源需求較高。  \n",
      "   - 方案二以端側輕量辨識減輕中心壓力，通訊頻寬受限有利，但可能影響即時性與精準覆蓋。\n",
      "\n",
      "2. **環境多變化下的辨識能力**\n",
      "   - 海況變化大（霧氣、反光、黑白影像）且需要辨識15公尺以上船隻10艘以上。  \n",
      "   - 方案一的影像增強模組及多模型融合明顯在惡劣環境下更具彈性與準確度提升空間  \n",
      "   - 方案二受限於端側硬體及影像處理能力，可能較難全面因應複雜環境情況，夜間辨識效果或較弱。\n",
      "\n",
      "3. **系統擴展性與彈性**\n",
      "   - 若未來需導入雷達、AIS等多元感測器輔助判斷，以提升誤報降低及更全方位監控，方案一的模組化集中架構較易整合與擴增。  \n",
      "   - 方案二則適合對分布式站點多、通訊頻寬有限且部署規模分散的場景，維運彈性較高。\n",
      "\n",
      "---\n",
      "\n",
      "### 綜合建議\n",
      "\n",
      "- 若部署環境具備較佳運算資源及帶寬，且追求最高判別精準度與整體監控完整性，**方案一為優先選擇**，可精細調控多層掃描與模型融合策略，兼顧精確度與即時反應，尤其對夜間與惡劣天候辨識更具優勢。  \n",
      "- 若現場硬體受限、海域監控點多且傳輸環境較差，需盡量降低傳輸負擔並分散即時處理壓力，且中心端可負擔較複雜決策演算，則可考慮**方案二**，尤其在可階段式擴展投入的情況下適用。\n",
      "\n",
      "---\n",
      "\n",
      "若有需聚焦的場域使用限制（如硬體配置、通訊環境、現場人力能力等），或業務對目標響應時間的更細節需求，請進一步提供，我將協助調整方案重點並優化架構建議。\n",
      "\n",
      "您希望我再以何種方向協助？  \n",
      "- 協助細化方案一或方案二應用場景流程？  \n",
      "- 或是針對兩方案結合的混合方案設計建議？  \n",
      "- 抑或是針對使用者操作介面與警示流程的細節想像進行引導？\n",
      "\n",
      "期待您的回覆。\n",
      "---------- TextMessage (TechnicalAgent) ----------\n",
      "感謝您詳盡的補充分析與評估建議。\n",
      "\n",
      "綜合考量貴方系統需「24小時不間斷高可靠即時監控」「遠近距船隻同時高精度識別」及「夜間與惡劣天氣條件辨識能力」，並且假設目前部署環境具備中高端運算資源與可接受一定頻寬成本（待補充實際硬體與通訊條件），\n",
      "\n",
      "我建議聚焦 **方案一：多階段影像分級辨識系統（分層掃描+多模型融合）** 進行後續任務拆解與交付規劃。\n",
      "\n",
      "原因如下：\n",
      "\n",
      "- 方案一在系統即時反應及多層掃描頻率調節上彈性更大，可兼顧監控廣域與多目標分辨需求。\n",
      "- 內建影像增強與注意力機制，提高環境多變化下模型辨識精度，且對夜間黑白影像辨識具備升級空間。\n",
      "- 替未來多感測源融合及演算法迭代提供良好擴展性與模組化管理便利。\n",
      "- 符合持續提升船隻避碰預警能力與異常事件警示的業務目標。\n",
      "- 中央集中運算便於統一維運並快速更新優化演算法。\n",
      "\n",
      "若您同意，我將根據方案一開始做系統任務拆解、交付內容建議、所需角色配置及風險管理方案，並依據方案細節協助規劃適用的驗收指標與里程碑控制。\n",
      "\n",
      "如有其他補充硬體資源、通訊頻寬、或實際部署場域限制，也請一併提供，便於細化規劃。\n",
      "\n",
      "期待您的決定指示。\n",
      "---------- TextMessage (ApplicationAgent) ----------\n",
      "感謝您詳細的補充與分析，針對您提出的情境與需求，我認為選擇方案一「多階段影像分級辨識系統（分層掃描+多模型融合）」是相當適當的策略。\n",
      "\n",
      "以下是我對此方案的應用情境進一步想像與彙整：\n",
      "\n",
      "- 使用者行為與工作流程：\n",
      "  岸邊監控中心操作人員透過綜合影像監控平台，全天候持續監視海上情況。系統根據船隻距離自動調整掃描頻率，近距離船隻獲得密集且高解析度的掃描與辨識，遠距離船隻則以低頻率監控保持警覺。當有船隻異常靠近或出現在特定區域時，系統即時傳送視覺與警示通知，協助操作人員快速判斷情況並啟動應對流程。\n",
      "\n",
      "- 使用時機與觸發條件：\n",
      "  主要是全天候實時監控，系統會依實際感測與辨識結果動態調整運算分配。觸發條件包括監測到船隻進入關鍵海域、接近避碰距離或速度異常等狀態。\n",
      "\n",
      "- 系統介入與回饋：\n",
      "  系統整合多焦段影像來源並進行即時影像增強，利用多層模型策略強化不同環境條件的識別能力。結合空間注意力與多尺度檢測技術，提升小尺寸與遠距目標的辨識精度。辨識結果不僅回饋可視化介面即時標示，也會觸發警示音與視覺提醒，推動作業員快速反應，並支援後續資料儲存與分析以優化未來預警條件。\n",
      "\n",
      "此方案適合貴方系統對精準度、即時度及環境多元挑戰的核心訴求，同時保障未來持續升級與擴展的彈性。\n",
      "\n",
      "若您同意，我們可往此方案方向推進系統任務拆解與驗收規劃，並同步收集部署現場的硬體與通訊條件細節，確保設計符合現場運營限制。\n",
      "\n",
      "請確認是否可依此進行，或有其他補充與調整方向，謝謝！\n",
      "\n",
      "TERMINATE\n",
      "---------- TextMessage (TechnicalAgent) ----------\n",
      "感謝您的確認與補充說明。\n",
      "\n",
      "針對方案一「多階段影像分級辨識系統（分層掃描+多模型融合）」，我將依下列方向進行後續任務拆解與交付規劃，並望貴方同步提供部署現場硬體與通訊環境具體資料，以利細節對齊：\n",
      "\n",
      "---\n",
      "\n",
      "## 一、任務拆解與依賴關係\n",
      "\n",
      "1. **需求細化與系統設計**\n",
      "   - 確認並細化多層掃描策略的距離分段與頻率規範\n",
      "   - 確定所需模型版本組合（輕量模型vs深度模型）的配置邏輯與切換條件\n",
      "   - 定義影像增強模組支援範圍（去霧、夜間強化等）與接口規範\n",
      "   - 設計事件觸發條件及警示流程（包含預警參數設置與操作人員UI互動）\n",
      "\n",
      "2. **前置環境建置**\n",
      "   - 建置高性能運算環境（GPU集群或雲端架構）\n",
      "   - 視訊採集設備整合（多焦距鏡頭、夜間感測強化設備）\n",
      "   - 通訊頻寬與資料存取規劃\n",
      "\n",
      "3. **模型開發與訓練**\n",
      "   - 深度模型及輕量模型基線版本建立與測試\n",
      "   - 影像增強前處理模組開發\n",
      "   - 模型融合及多尺度檢測算法集成\n",
      "   - 黑白影像、低光環境模型調優\n",
      "\n",
      "4. **系統整合開發**\n",
      "   - 多模型融合機制與動態調度模組實作\n",
      "   - 多源影像資料流及前後端連接\n",
      "   - 事件觸發系統整合與UI警示呈現開發\n",
      "\n",
      "5. **測試驗證與調優**\n",
      "   - 實場景多距離、多環境影像測試\n",
      "   - 整體系統負載與延遲測試\n",
      "   - 警示準確率與誤報率調整\n",
      "   - 性能瓶頸及安全性測試\n",
      "\n",
      "6. **部署與維運支援**\n",
      "   - 部署系統到目標環境\n",
      "   - 提供日常維運監控、模型更新及系統擴展流程\n",
      "\n",
      "---\n",
      "\n",
      "## 二、建議所需人力角色\n",
      "\n",
      "- **計畫經理／技術經理**：整合協調跨團隊進度\n",
      "- **系統架構師**：整體系統設計及技術評估\n",
      "- **深度學習工程師**：模型訓練、調參與優化\n",
      "- **影像處理工程師**：影像增強及前處理模組開發\n",
      "- **後端工程師**：系統整合、服務架構及API開發\n",
      "- **前端工程師**：即時視覺界面與警示呈現\n",
      "- **網絡工程師**：通訊架構及資安設計\n",
      "- **測試工程師**：軟硬體系統整合測試及驗收\n",
      "\n",
      "---\n",
      "\n",
      "## 三、潛在風險與備案建議\n",
      "\n",
      "- **運算及頻寬負載過高**  \n",
      "  備案：提升軟硬體資源，調整掃描頻率，增加端側初步過濾機制\n",
      "\n",
      "- **惡劣環境辨識率下降**  \n",
      "  備案：持續優化影像增強技術、增設多感測源（紅外、雷達）\n",
      "\n",
      "- **系統複雜度高導致維護困難**  \n",
      "  備案：模組化設計並導入自動化部署與監控\n",
      "\n",
      "- **資料安全與隱私問題**  \n",
      "  備案：加強通訊加密、身份驗證及存取權限管理\n",
      "\n",
      "---\n",
      "\n",
      "## 四、驗收標準與里程碑（建議範例）\n",
      "\n",
      "- **M1 設計確認與環境建置完成**（預計1-2個月）  \n",
      "  包含分層掃描策略設定、系統架構定案、環境搭建\n",
      "\n",
      "- **M2 模型基線開發與影像增強模組測試**（預計2-3個月）  \n",
      "  完成不同距離及夜間模型版本訓練與近似驗證\n",
      "\n",
      "- **M3 系統整合與初步場景測試**（預計1-2個月）  \n",
      "  多模融合、事件警示流程實測\n",
      "\n",
      "- **M4 全面性系統測試與優化**（預計1個月）  \n",
      "  包括性能、資安、穩定性測試與調校\n",
      "\n",
      "- **M5 部署與驗收上線**（預計1個月）  \n",
      "  正式啟動使用並進行後續維運準備\n",
      "\n",
      "---\n",
      "\n",
      "歡迎隨時提供部署硬體及通訊細節，我可協助進一步精準調整規劃細節。\n",
      "\n",
      "期待與您共同推動項目成功落地。\n",
      "\n",
      "TERMINATE\n"
     ]
    }
   ],
   "source": [
    "# Application to Technical interaction\n",
    "\n",
    "from autogen_agentchat.ui import Console\n",
    "\n",
    "task_description = f\"\"\"\n",
    "以下是提供你閱讀的計畫文件：\n",
    "{full_documents_content}\n",
    "簡單整理目前的想像畫面：\n",
    "- 使用者是岸邊的監控中心操作人員，負責24小時不間斷監控約24海里（約44公里）範圍內海域的船隻動向。\n",
    "- 系統需要持續自動掃描，並能在船隻進入或快速靠近關鍵區域時，及時在螢幕上標示其位置並發出警示，協助管控及調度決策。\n",
    "- 在距離較近的地方，掃描頻率及更新速度要高，確保船隻動態能即時反映；而遠距離船隻則可以較低頻率掃描，平衡系統負載與效率。\n",
    "- 影像辨識必須涵蓋夜間及低光環境，對黑白影像或雨霧等惡劣天氣需有一定的精準度，避免錯過重要目標。\n",
    "\n",
    "基於這個使用情境，遠距離即時辨識的主要挑戰可能會包含：\n",
    "1. **影像品質與解析度**：遠距離的船隻在影像中尺寸會非常小，光線及水氣環境易降低辨識率。\n",
    "2. **傳輸與處理效率**：解析高解析度影像需要較大頻寬與計算資源，尤其是24海里範圍涵蓋面積廣。\n",
    "3. **環境干擾**：反射、波浪、霧氣等變數更顯著，會影響模型的判斷準確度。\n",
    "4. **多層次巡檢策略**：需針對不同距離船隻設定合理的掃描頻率及預警門檻，避免系統過載且保持監控效能。\n",
    "5. **低光源與夜間辨識**：必須提升模型對黑白或低光影像的準確率，可能需導入專門的影像增強或特殊感測器。\n",
    "\"\"\"\n",
    "\n",
    "with capture_print_to_file(\"log/no_rag/application_to_technical_log.txt\"):\n",
    "    await Console(team2.run_stream(task=task_description))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_tpm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
