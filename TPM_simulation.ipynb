{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e77eec5f",
   "metadata": {},
   "source": [
    "# API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93efbf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf3564e",
   "metadata": {},
   "source": [
    "# Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a680ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "附件四、報告格式 \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "即時海洋觀測平台開發暨AI影像數據應用服\n",
      "務主題式研發計畫 \n",
      " \n",
      "期末報告\n",
      "{'producer': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creator': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creationdate': '2025-07-26T01:23:18+08:00',\n",
      " 'author': 'Annie',\n",
      " 'moddate': '2025-07-26T01:23:18+08:00',\n",
      " 'source': './docs/期末報告_0407.pdf',\n",
      " 'total_pages': 20,\n",
      " 'page': 0,\n",
      " 'page_label': '1'}\n",
      "1 \n",
      " \n",
      "即時海洋觀測平台開發暨 AI 影像數據應用服務主題式研發\n",
      "計畫 \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "期末報告 \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "計畫主持人：林家瑜 助理教授     \n",
      "研究機構  ：國立中央大\n",
      "{'producer': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creator': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creationdate': '2025-07-26T01:23:18+08:00',\n",
      " 'author': 'Annie',\n",
      " 'moddate': '2025-07-26T01:23:18+08:00',\n",
      " 'source': './docs/期末報告_0407.pdf',\n",
      " 'total_pages': 20,\n",
      " 'page': 1,\n",
      " 'page_label': '2'}\n",
      "2 \n",
      " \n",
      "計畫摘要 \n",
      "    本研究致力於開發即時海洋觀測平台，並應用 AI 影像數據分析來提升遠距離船\n",
      "隻辨識的準確性與效率。現行船舶識別技術主要依賴人眼辨識，然而在 3 公里以上距\n",
      "離，由於海面反\n",
      "{'producer': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creator': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creationdate': '2025-07-26T01:23:18+08:00',\n",
      " 'author': 'Annie',\n",
      " 'moddate': '2025-07-26T01:23:18+08:00',\n",
      " 'source': './docs/期末報告_0407.pdf',\n",
      " 'total_pages': 20,\n",
      " 'page': 2,\n",
      " 'page_label': '3'}\n",
      "3 \n",
      " \n",
      "目錄 \n",
      "計畫摘要 ......................................................................................\n",
      "{'producer': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creator': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creationdate': '2025-07-26T01:23:18+08:00',\n",
      " 'author': 'Annie',\n",
      " 'moddate': '2025-07-26T01:23:18+08:00',\n",
      " 'source': './docs/期末報告_0407.pdf',\n",
      " 'total_pages': 20,\n",
      " 'page': 3,\n",
      " 'page_label': '4'}\n",
      "4 \n",
      " \n",
      "一、 計畫動機與目的 \n",
      "1. 動機 \n",
      "在海洋環境中，對於船隻的及時且準確的辨識是保障航行安全和有效執\n",
      "行海上作業的關鍵。但目前大部分的船隻都是人工辨識，而人眼無法同時看\n",
      "超過 10 艘船隻進\n",
      "{'producer': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creator': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creationdate': '2025-07-26T01:23:18+08:00',\n",
      " 'author': 'Annie',\n",
      " 'moddate': '2025-07-26T01:23:18+08:00',\n",
      " 'source': './docs/期末報告_0407.pdf',\n",
      " 'total_pages': 20,\n",
      " 'page': 4,\n",
      " 'page_label': '5'}\n",
      "5 \n",
      " \n",
      "二、 文獻探討 \n",
      "現在有一些研究採用物件辨識模型進行船隻辨識，在 Automatic Ship \n",
      "Object Detection Model Based on YOLOv4 with Tr\n",
      "{'producer': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creator': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creationdate': '2025-07-26T01:23:18+08:00',\n",
      " 'author': 'Annie',\n",
      " 'moddate': '2025-07-26T01:23:18+08:00',\n",
      " 'source': './docs/期末報告_0407.pdf',\n",
      " 'total_pages': 20,\n",
      " 'page': 5,\n",
      " 'page_label': '6'}\n",
      "6 \n",
      " \n",
      "YOLOv8 的基礎上，額外加入了較大尺寸的兩個輸入 (320×320和160×\n",
      "160)、一個 Upsampling 層(160×160) 、一個 Fusion 加 C2f 層(160×1\n",
      "{'producer': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creator': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creationdate': '2025-07-26T01:23:18+08:00',\n",
      " 'author': 'Annie',\n",
      " 'moddate': '2025-07-26T01:23:18+08:00',\n",
      " 'source': './docs/期末報告_0407.pdf',\n",
      " 'total_pages': 20,\n",
      " 'page': 6,\n",
      " 'page_label': '7'}\n",
      "7 \n",
      " \n",
      "的寬高比差異來提升回歸精度，而Focal Loss 則用於平衡正負樣本比例，讓\n",
      "模型更關注高質量的預測框。 \n",
      "為了評估模型性能，作者在 SeaShips(7000)資料集上進行實驗，訓練時\n",
      "\n",
      "{'producer': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creator': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creationdate': '2025-07-26T01:23:18+08:00',\n",
      " 'author': 'Annie',\n",
      " 'moddate': '2025-07-26T01:23:18+08:00',\n",
      " 'source': './docs/期末報告_0407.pdf',\n",
      " 'total_pages': 20,\n",
      " 'page': 7,\n",
      " 'page_label': '8'}\n",
      "8 \n",
      " \n",
      "三、 研究方法 \n",
      "1. 資料收集 \n",
      "    資料集使用 Singapore Maritime Dataset 的 Visible On-Shore 資料集[5, 6]加上\n",
      "ABOships-\n",
      "{'producer': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creator': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creationdate': '2025-07-26T01:23:18+08:00',\n",
      " 'author': 'Annie',\n",
      " 'moddate': '2025-07-26T01:23:18+08:00',\n",
      " 'source': './docs/期末報告_0407.pdf',\n",
      " 'total_pages': 20,\n",
      " 'page': 8,\n",
      " 'page_label': '9'}\n",
      "9 \n",
      " \n",
      "    ABOships-PLUS 資料集為網路上的公開資料集，ABOships 資料集的改進版\n",
      "本，包含 9880 張影像，33227 個標註，屬於近港船隻影像資料集，其中含有 3 個\n",
      "船\n",
      "{'producer': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creator': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creationdate': '2025-07-26T01:23:18+08:00',\n",
      " 'author': 'Annie',\n",
      " 'moddate': '2025-07-26T01:23:18+08:00',\n",
      " 'source': './docs/期末報告_0407.pdf',\n",
      " 'total_pages': 20,\n",
      " 'page': 9,\n",
      " 'page_label': '10'}\n",
      "10 \n",
      " \n",
      "2. 資料前處理 \n",
      "    \n",
      " \n",
      "圖一、資料前處理流程圖。 \n",
      "    如圖一所示，首先會將資料集處理成只包含 images 和 labels 資料夾的\n",
      "形式，images 和 labels\n",
      "{'producer': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creator': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creationdate': '2025-07-26T01:23:18+08:00',\n",
      " 'author': 'Annie',\n",
      " 'moddate': '2025-07-26T01:23:18+08:00',\n",
      " 'source': './docs/期末報告_0407.pdf',\n",
      " 'total_pages': 20,\n",
      " 'page': 10,\n",
      " 'page_label': '11'}\n",
      "11 \n",
      " \n",
      " \n",
      "圖二、YOLOv11 架構圖[9] \n",
      " \n",
      "Backbone 如圖二左側所示，主要目的是從輸入影像中提取有用的特徵\n",
      "資訊。在 YOLOv11 中，Backbone 採用了 C3K2 結構\n",
      "{'producer': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creator': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creationdate': '2025-07-26T01:23:18+08:00',\n",
      " 'author': 'Annie',\n",
      " 'moddate': '2025-07-26T01:23:18+08:00',\n",
      " 'source': './docs/期末報告_0407.pdf',\n",
      " 'total_pages': 20,\n",
      " 'page': 11,\n",
      " 'page_label': '12'}\n",
      "12 \n",
      " \n",
      "四、 實驗結果 \n",
      "    我們使用 YOLOv11l 模型，訓練集使用 ABOships-PLUS，測試集使用\n",
      "高雄資料集，實驗環境為 64-bit Windows 11、Intel i5\n",
      "{'producer': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creator': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creationdate': '2025-07-26T01:23:18+08:00',\n",
      " 'author': 'Annie',\n",
      " 'moddate': '2025-07-26T01:23:18+08:00',\n",
      " 'source': './docs/期末報告_0407.pdf',\n",
      " 'total_pages': 20,\n",
      " 'page': 12,\n",
      " 'page_label': '13'}\n",
      "13 \n",
      " \n",
      " \n",
      "圖三、彩色影片 output_005 第一秒影像 \n",
      "    彩色影片 output_005 的第一秒影像如上圖所示，圖中模型成功辨識出所\n",
      "有船隻，1~3 秒內的檢測率都為 1.0。 \n",
      "\n",
      "{'producer': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creator': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creationdate': '2025-07-26T01:23:18+08:00',\n",
      " 'author': 'Annie',\n",
      " 'moddate': '2025-07-26T01:23:18+08:00',\n",
      " 'source': './docs/期末報告_0407.pdf',\n",
      " 'total_pages': 20,\n",
      " 'page': 13,\n",
      " 'page_label': '14'}\n",
      "14 \n",
      " \n",
      " \n",
      "圖五、彩色影片 output_080 第一秒影像 \n",
      "    彩色影片 output_080 的第一秒影像如上圖所示，圖中模型成功辨識出所\n",
      "有船隻，1~3 秒內的檢測率都為 1.0。 \n",
      "\n",
      "{'producer': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creator': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creationdate': '2025-07-26T01:23:18+08:00',\n",
      " 'author': 'Annie',\n",
      " 'moddate': '2025-07-26T01:23:18+08:00',\n",
      " 'source': './docs/期末報告_0407.pdf',\n",
      " 'total_pages': 20,\n",
      " 'page': 14,\n",
      " 'page_label': '15'}\n",
      "15 \n",
      " \n",
      " \n",
      "圖七、黑白影片 output_199 第二秒影像 \n",
      "    彩色影片 output_199 的第二秒影像如上圖所示，圖中模型成功辨識出所\n",
      "有船隻，2~3 秒內的檢測率都為 1.0。 \n",
      "\n",
      "{'producer': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creator': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creationdate': '2025-07-26T01:23:18+08:00',\n",
      " 'author': 'Annie',\n",
      " 'moddate': '2025-07-26T01:23:18+08:00',\n",
      " 'source': './docs/期末報告_0407.pdf',\n",
      " 'total_pages': 20,\n",
      " 'page': 15,\n",
      " 'page_label': '16'}\n",
      "16 \n",
      " \n",
      " \n",
      "圖九、黑白影片 output_276 第一秒影像 \n",
      "    彩色影片 output_276 的第一秒影像如上圖所示，圖中模型成功辨識出所\n",
      "有船隻，1~3 秒內的檢測率都為 1.0。 \n",
      "\n",
      "{'producer': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creator': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creationdate': '2025-07-26T01:23:18+08:00',\n",
      " 'author': 'Annie',\n",
      " 'moddate': '2025-07-26T01:23:18+08:00',\n",
      " 'source': './docs/期末報告_0407.pdf',\n",
      " 'total_pages': 20,\n",
      " 'page': 16,\n",
      " 'page_label': '17'}\n",
      "17 \n",
      " \n",
      "表五、KPI 完成表 \n",
      "項目 達成狀況 \n",
      "1.建立 AI 分析海事觀測演算法邏輯架構 已達成 \n",
      "2.完成演算法建立，並可在本島沿海 3 公里海域內環境進行 已達成 \n",
      "3.演算結果可達以下規\n",
      "{'producer': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creator': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creationdate': '2025-07-26T01:23:18+08:00',\n",
      " 'author': 'Annie',\n",
      " 'moddate': '2025-07-26T01:23:18+08:00',\n",
      " 'source': './docs/期末報告_0407.pdf',\n",
      " 'total_pages': 20,\n",
      " 'page': 17,\n",
      " 'page_label': '18'}\n",
      "18 \n",
      " \n",
      "五、 結論 \n",
      "本計畫目的為設計出可以有效辨識 3 公里遠的船隻，且一次可辨識長度 15\n",
      "公尺的船隻 10 艘以上的模型，根據目前的實驗結果，模型在船隻距離、速度、\n",
      "目標數量以及避碰能力上都\n",
      "{'producer': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creator': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creationdate': '2025-07-26T01:23:18+08:00',\n",
      " 'author': 'Annie',\n",
      " 'moddate': '2025-07-26T01:23:18+08:00',\n",
      " 'source': './docs/期末報告_0407.pdf',\n",
      " 'total_pages': 20,\n",
      " 'page': 18,\n",
      " 'page_label': '19'}\n",
      "19 \n",
      " \n",
      "六、 參考文獻 \n",
      "[1] Sun, Bowen, et al. \"Automatic ship object detection model based on YOLOv4 \n",
      "with t\n",
      "{'producer': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creator': '適用於 Microsoft 365 的 Microsoft® Word',\n",
      " 'creationdate': '2025-07-26T01:23:18+08:00',\n",
      " 'author': 'Annie',\n",
      " 'moddate': '2025-07-26T01:23:18+08:00',\n",
      " 'source': './docs/期末報告_0407.pdf',\n",
      " 'total_pages': 20,\n",
      " 'page': 19,\n",
      " 'page_label': '20'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "import pprint\n",
    "\n",
    "file_path = \"./docs/期末報告_0407.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "\n",
    "pages = []\n",
    "async for page in loader.alazy_load():\n",
    "    pages.append(page)\n",
    "\n",
    "for page in pages:\n",
    "    print(page.page_content[:100])  # Print the first 100 characters of each page content\n",
    "    pprint.pp(page.metadata)  # Print the metadata of each page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ae4a850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "附件四、報告格式 \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "即時海洋觀測平台開發暨AI影像數據應用服\n",
      "務主題式研發計畫 \n",
      " \n",
      "期末報告1 \n",
      " \n",
      "即時海洋觀測平台開發暨 AI 影像數據應用服務主題式研發\n",
      "計畫 \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "期末報告 \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "計畫主持人：林家瑜 助理教授     \n",
      "研究機構  ：國立中央大學資訊工程系 \n",
      "執行期間  ：113/05/01-114/04/30（請填寫合作研究計畫執行期間） \n",
      " \n",
      "(以上資料請務必以中文繕打清楚) \n",
      " \n",
      "中華民國 114 年 01 月31 日2 \n",
      " \n",
      "計畫摘要 \n",
      "    本研究致力於開發即時海洋觀測平台，並應用 AI 影像數據分析來提升遠距離船\n",
      "隻辨識的準確性與效率。現行船舶識別技術主要依賴人眼辨識，然而在 3 公里以上距\n",
      "離，由於海面反射、霧氣與光線變化等環境因素的影響，傳統方法的準確率明顯下\n",
      "降。本計畫旨在透過深度學習物件辨識技術，建立一套高效能的「即時遠距離多船隻\n",
      "辨識系統」，能夠在 3 公里外準確偵測船隻，並可同時識別 10 艘以上長度超過 15 公\n",
      "尺的船隻。 \n",
      "    本研究參考 YOLOv5s 與YOLOv8 物件辨識模型，針對海洋環境特性進行改良，\n",
      "並利用多種公開及自建數據集如 Singapore Maritime Dataset、ABOships-PLUS、高雄\n",
      "港實測數據進行模型訓練與驗證。透過影像增強、特徵提取優化與多尺度檢測技術，\n",
      "我們顯著提升了模型在複雜海洋場景中的識別能力。 \n",
      "    目前的實驗結果顯示，我們的系統在新加坡與高雄測試數據集中的部分影像皆展\n",
      "現超過 90%的識別準確度，並成功達成： \n",
      "⚫ 可偵測移動速度超過 15 節的船隻 \n",
      "⚫ 在 5 公里範圍內實現高效識別 \n",
      "⚫ 可即時處理 640×480 解析度影像，幀率≥10FPS \n",
      "⚫ 具備船隻避碰預警功能 \n",
      "    未來將進一步提升船隻辨識與船隻避碰預測的準確度，並擴充模型至夜間與黑白\n",
      "影像辨識，以提升即時監測與應用能力。此技術的發展對於海洋交通安全監控、智慧\n",
      "港口管理與海上救援應用將具備重要價值。 \n",
      " \n",
      "關鍵字：即時海洋觀測、AI 影像辨識、深度學習、YOLOv5、YOLOv8、多尺度檢\n",
      "測、船隻辨識、避碰預警、智慧港口、遠距離監測3 \n",
      " \n",
      "目錄 \n",
      "計畫摘要 ................................\n"
     ]
    }
   ],
   "source": [
    "documents_content = []\n",
    "\n",
    "full_content = \"\".join([page.page_content for page in pages])\n",
    "print(full_content[:1000])  # Print the first 1000 characters of the full\n",
    "\n",
    "documents_content.append(full_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd98cd2c",
   "metadata": {},
   "source": [
    "# Model Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bf3f9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "\n",
    "model_client = OpenAIChatCompletionClient(\n",
    "    model=\"gpt-4.1-mini\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7173b999",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fb8160b",
   "metadata": {},
   "outputs": [],
   "source": [
    "business_agent_system_prompt = f\"\"\"\n",
    "你是一位業務代表，負責將客戶的想法與需求轉交給技術團隊。你不具備工程背景，也不了解具體技術實作方式，但你擅長觀察客戶反應、理解業務場景，並嘗試將需求表達出來。\n",
    "\n",
    "你現在的任務如下：\n",
    "\n",
    "---\n",
    "\n",
    "### 模擬任務：\n",
    "\n",
    "你即將閱讀一份「過去執行過的計畫成果文件」，這份文件描述了一個已成功交付的系統或解決方案。\n",
    "\n",
    "請你依據該文件內容，模擬以下情境：\n",
    "\n",
    "1. **扮演業務角色，想像你剛從客戶那聽到一些可能的需求或回饋**（例如：「客戶聽說有這樣的案例，也想看看能不能導入」）\n",
    "2. **根據你對文件的理解與客戶方向，向 TPM 提出初步問題或轉述需求**\n",
    "3. 問題可以是模糊的、不完全的，例如：「我們有個類似的客戶，希望加上...不知道這樣會不會太複雜？」\n",
    "\n",
    "---\n",
    "\n",
    "### 回應 TPM 追問的行為規則：\n",
    "- 當 TPM Agent 提出釐清性的問題時，請主動代入一個你想像中的客戶角色與場景，根據其可能的需求、限制或業務情境，提供合理的模擬性回答\n",
    "- 回答不需絕對正確，但應具備商業情境感與邏輯一致性，像是真實客戶會提出的要求或回應\n",
    "- 你可以自行設定客戶的產業背景、痛點或場域條件，並據此做出回應\n",
    "\n",
    "---\n",
    "\n",
    "### 對話風格建議：\n",
    "\n",
    "- 使用自然語言，像你在跟 TPM 開會，轉述客戶說法或發想\n",
    "- 初始輸出可以提出 1~3 個問題或需求，不需一次講完所有細節\n",
    "- 在 TPM 釐清階段，適度補充模擬性的客戶需求說明或限制條件，但避免討論具體技術或架構方式\n",
    "\n",
    "---\n",
    "\n",
    "### 禁忌與限制：\n",
    "\n",
    "- 請避免使用技術術語、系統架構、API、模型、演算法等名詞\n",
    "- 不要主動設計系統功能與實作流程（那是 TPM 的任務）\n",
    "- 你的角色是**需求轉述者**與**客戶意圖的模擬提供者**\n",
    "\n",
    "---\n",
    "\n",
    "請根據下方提供的文件內容，開始進行你的業務對話任務。\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "tpm_agent_system_prompt = f\"\"\"\n",
    "你是一位專業的 TPM(Technical Program Manager)，擅長在技術與業務之間溝通協調。你的任務是根據業務方或客戶提供的資訊，逐步完成以下三個階段的任務，以協助團隊成功落地專案。\n",
    "\n",
    "請注意：以下三個階段並不需要在每次回覆中一次完成。請根據當前對話的上下文，判斷應執行哪個階段的任務，再進行對應的輸出。\n",
    "\n",
    "---\n",
    "\n",
    "### 第一階段：釐清需求與反問（通常是對話初期）\n",
    "- 仔細閱讀業務或客戶提供的需求說明，專注於理解其真實意圖、使用情境與痛點。\n",
    "- 分析是否存在模糊、不一致、尚未確認或潛在矛盾的地方，特別是目標與商業需求層面的模糊。\n",
    "- 優先提出與「需求本質」、「使用者情境」、「業務期望」、「成果標準」有關的釐清問題，而非技術實作細節。\n",
    "\n",
    "---\n",
    "\n",
    "### 第二階段：提出可行技術組合與解法建議（在需求較清楚時進行）\n",
    "\n",
    "- 根據已釐清的需求內容，簡述 **兩種以上可行的技術組合或解法方向**，並指出其適用條件、可能的服務規模或限制。\n",
    "- 若需求尚未完整，可先提供預估性的選項，並標註「待確認」部分。\n",
    "- 目標是提供決策依據，讓 PM 或技術團隊進一步展開可行性評估。\n",
    "\n",
    "---\n",
    "\n",
    "### 第三階段：彙整任務拆解與交付建議（作為最後彙總）\n",
    "\n",
    "- 根據目前已確認的需求與解法方向，進行 **初步任務拆解**，列出主要步驟與依賴項。\n",
    "- 評估潛在風險，並提出應對建議。\n",
    "- 將以上內容整理成一份 **可交付給 PM 的落地建議草案**。\n",
    "\n",
    "---\n",
    "\n",
    "### 使用注意事項：\n",
    "\n",
    "- 不需每次回應都涵蓋全部階段，請根據上下文做出合適回應。\n",
    "- 你是 TPM，需關注全局、釐清邏輯與風險，但不需進行實作細節設計。\n",
    "\n",
    "請依據每次輸入的對話內容，自主判斷目前應進行的任務階段，並啟動相對應的 TPM 任務。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19cb2043",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "\n",
    "business_agent = AssistantAgent(\n",
    "    name=\"Business\",\n",
    "    model_client=model_client,\n",
    "    system_message=business_agent_system_prompt,\n",
    ")\n",
    "\n",
    "tpm_agent = AssistantAgent(\n",
    "    name=\"TPM\",\n",
    "    model_client=model_client,\n",
    "    system_message=tpm_agent_system_prompt,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72b3ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_documents_content = \"\\n\".join(f\"===\\n{doc}\\n===\" for doc in documents_content)\n",
    "\n",
    "# business_agent_task = f\"\"\"\n",
    "# 以下是提供你閱讀的計畫文件：\n",
    "# {full_documents_content}\n",
    "# 請根據以上文件內容，模擬一位業務代表會向 TPM 詢問的10個問題或轉述的需求。\n",
    "# \"\"\"\n",
    "\n",
    "business_agent_task = f\"\"\"\n",
    "以下是提供你閱讀的計畫文件：\n",
    "{full_documents_content}\n",
    "請根據以上文件內容，模擬一位業務代表會向 TPM 詢問有關 即時辨識 24 海里內船隻平台 的1個問題或轉述的需求。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a61a176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi TPM，剛跟我們一個港口管理客戶聊，他們聽說你們之前做過這個「即時海洋觀測平台」的案子，對於能在3公里以外精準辨識多艘船隻的能力很感興趣。不過他們現在希望平台能擴展到24海里（約44公里）範圍內即時辨識船隻，不知道這樣的距離辨識延伸會不會太複雜？特別是考慮到遠距離能見度和環境干擾等問題，他們還希望平台除了辨識還能結合避碰預警的功能，請問技術面上有沒有潛力或挑戰要先評估？感覺這會是他們未來想試水溫的方向，想初步了解可行性。\n"
     ]
    }
   ],
   "source": [
    "result = await business_agent.run(task=business_agent_task)\n",
    "print(result.messages[-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050af699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "感謝分享需求資訊！針對這位港口管理客戶希望將「即時海洋觀測平台」的辨識範圍從約3公里擴展到24海里（約44公里）並加入避碰預警功能，為了更準確掌握需求並評估技術可行性，我這邊想先釐清幾個重點：\n",
      "\n",
      "1. **使用場景與目標船隻類型**\n",
      "   - 客戶主要關注的是哪種船隻？（如大小船舶、漁船、商港貨櫃船，還是全部類型）\n",
      "   - 辨識重點是單純的定位及識別船隻數量，還是還需辨識船隻類別或其他狀態？\n",
      "\n",
      "2. **即時性與更新頻率**\n",
      "   - 客戶希望系統多即時？更新頻率與延遲容忍度大概是多少？\n",
      "   - 避碰預警功能預期多久更新一次決策，是否有對即時性有嚴格要求？\n",
      "\n",
      "3. **環境條件與部署限制**\n",
      "   - 辨識的海域環境條件如何？是否存在天候惡劣、海況複雜等問題？\n",
      "   - 現有基建情況如何？是否允許安裝額外硬體（如雷達、攝像頭或其他感測器）來支援距離擴展？\n",
      "\n",
      "4. **預算與規模預期**\n",
      "   - 客戶是否已有初步預算概念或期望的投資規模？\n",
      "   - 整體系統是否預期覆蓋更大範圍、或後續持續追加多功能？\n",
      "\n",
      "5. **避碰預警具體需求**\n",
      "   - 預期避碰預警的觸發邏輯與介面是什麼？需要提供多大範圍的預警？是否包含航跡預測與風險評估等功能？\n",
      "   - 是否需要與現有的船舶導航系統或港口管理系統對接？\n",
      "\n",
      "這些訊息可以幫助我們從技術角度更有效地評估距離擴展的可行性與潛在挑戰，也能更準確地規劃解決方案。您是否能幫我確認或補充以上資訊？謝謝！\n"
     ]
    }
   ],
   "source": [
    "result = await tpm_agent.run(task=\"Hi TPM，剛跟我們一個港口管理客戶聊，他們聽說你們之前做過這個「即時海洋觀測平台」的案子，對於能在3公里以外精準辨識多艘船隻的能力很感興趣。不過他們現在希望平台能擴展到24海里（約44公里）範圍內即時辨識船隻，不知道這樣的距離辨識延伸會不會太複雜？特別是考慮到遠距離能見度和環境干擾等問題，他們還希望平台除了辨識還能結合避碰預警的功能，請問技術面上有沒有潛力或挑戰要先評估？感覺這會是他們未來想試水溫的方向，想初步了解可行性。\")\n",
    "print(result.messages[-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599ee9f7",
   "metadata": {},
   "source": [
    "# Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffbf15cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.conditions import MaxMessageTermination\n",
    "\n",
    "termination = MaxMessageTermination(max_messages=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0b5441",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "\n",
    "team = RoundRobinGroupChat(\n",
    "    participants=[business_agent, tpm_agent],\n",
    "    # termination_condition=termination,\n",
    "    max_turns=6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28fcf950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "\n",
      "以下是提供你閱讀的計畫文件：\n",
      "===\n",
      "附件四、報告格式 \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "即時海洋觀測平台開發暨AI影像數據應用服\n",
      "務主題式研發計畫 \n",
      " \n",
      "期末報告1 \n",
      " \n",
      "即時海洋觀測平台開發暨 AI 影像數據應用服務主題式研發\n",
      "計畫 \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "期末報告 \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "計畫主持人：林家瑜 助理教授     \n",
      "研究機構  ：國立中央大學資訊工程系 \n",
      "執行期間  ：113/05/01-114/04/30（請填寫合作研究計畫執行期間） \n",
      " \n",
      "(以上資料請務必以中文繕打清楚) \n",
      " \n",
      "中華民國 114 年 01 月31 日2 \n",
      " \n",
      "計畫摘要 \n",
      "    本研究致力於開發即時海洋觀測平台，並應用 AI 影像數據分析來提升遠距離船\n",
      "隻辨識的準確性與效率。現行船舶識別技術主要依賴人眼辨識，然而在 3 公里以上距\n",
      "離，由於海面反射、霧氣與光線變化等環境因素的影響，傳統方法的準確率明顯下\n",
      "降。本計畫旨在透過深度學習物件辨識技術，建立一套高效能的「即時遠距離多船隻\n",
      "辨識系統」，能夠在 3 公里外準確偵測船隻，並可同時識別 10 艘以上長度超過 15 公\n",
      "尺的船隻。 \n",
      "    本研究參考 YOLOv5s 與YOLOv8 物件辨識模型，針對海洋環境特性進行改良，\n",
      "並利用多種公開及自建數據集如 Singapore Maritime Dataset、ABOships-PLUS、高雄\n",
      "港實測數據進行模型訓練與驗證。透過影像增強、特徵提取優化與多尺度檢測技術，\n",
      "我們顯著提升了模型在複雜海洋場景中的識別能力。 \n",
      "    目前的實驗結果顯示，我們的系統在新加坡與高雄測試數據集中的部分影像皆展\n",
      "現超過 90%的識別準確度，並成功達成： \n",
      "⚫ 可偵測移動速度超過 15 節的船隻 \n",
      "⚫ 在 5 公里範圍內實現高效識別 \n",
      "⚫ 可即時處理 640×480 解析度影像，幀率≥10FPS \n",
      "⚫ 具備船隻避碰預警功能 \n",
      "    未來將進一步提升船隻辨識與船隻避碰預測的準確度，並擴充模型至夜間與黑白\n",
      "影像辨識，以提升即時監測與應用能力。此技術的發展對於海洋交通安全監控、智慧\n",
      "港口管理與海上救援應用將具備重要價值。 \n",
      " \n",
      "關鍵字：即時海洋觀測、AI 影像辨識、深度學習、YOLOv5、YOLOv8、多尺度檢\n",
      "測、船隻辨識、避碰預警、智慧港口、遠距離監測3 \n",
      " \n",
      "目錄 \n",
      "計畫摘要 ....................................................................................................................... 2 \n",
      "一、計畫動機與目的 ................................................................................................... 4 \n",
      "1. 動機 ..................................................................................................................... 4 \n",
      "2. 目的 ..................................................................................................................... 4 \n",
      "二、文獻探討 ............................................................................................................... 5 \n",
      "三、研究方法 ............................................................................................................... 8 \n",
      "1. 資料收集 ............................................................................................................. 8 \n",
      "2. 資料前處理 ....................................................................................................... 10 \n",
      "3. 船隻辨識模型 ................................................................................................... 10 \n",
      "四、實驗結果 ............................................................................................................. 12 \n",
      "五、結論 ..................................................................................................................... 18 \n",
      "六、參考文獻 ............................................................................................................. 194 \n",
      " \n",
      "一、 計畫動機與目的 \n",
      "1. 動機 \n",
      "在海洋環境中，對於船隻的及時且準確的辨識是保障航行安全和有效執\n",
      "行海上作業的關鍵。但目前大部分的船隻都是人工辨識，而人眼無法同時看\n",
      "超過 10 艘船隻進行辨識，因此需要 AI 輔助。現有的 AI 對距離近且較大的\n",
      "船或是俯視角的衛星雷達成像的船有不錯的辨識能力，但若是在第一人稱且\n",
      "距離超過 3 公里的情況下，可能會受到環境條件如海面反射、霧氣、光線變\n",
      "化等的影響，導致偵測的準確度降低，且現有開放資料集大多是較大的船隻\n",
      "，3 公里以上的船隻資料集較少，不利於訓練模型。 \n",
      "2. 目的 \n",
      "基於上述的問題，本計畫欲設計一套「即時遠距離多船隻辨識系統」 ，\n",
      "此系統可以有效辨識 3 公里遠的船隻，且一次可辨識長度15 公尺的船隻 10\n",
      "艘以上。5 \n",
      " \n",
      "二、 文獻探討 \n",
      "現在有一些研究採用物件辨識模型進行船隻辨識，在 Automatic Ship \n",
      "Object Detection Model Based on YOLOv4 with Transformer Mechanism in \n",
      "Remote Sensing Images 論文中提出了名為 Auto-T-YOLO 的架構[1]，用於解\n",
      "決現有物件偵測模型從輸入中提取特徵未能充分考慮全局特徵，且無法根據\n",
      "輸入的特徵自動調整，導致偵測準確度下降的問題。 \n",
      "    Auto-T-YOLO 的模型架構分為三個部分 ，Preattention, Attention 和\n",
      "Prediction。輸入影像大小為608×608×3，Preattention 和 Attention 的設計\n",
      "模仿了人類視覺系統中從大的全局特徵開始，再逐步轉向局部細節的兩階段\n",
      "注意機制。 \n",
      "    在 Preattention 架構中，輸入的圖像會根據其中是否包含𝑠𝑖𝑧𝑒 > 32×32\n",
      "的物件分為 A 子資料集及 B 子資料集，並在之後的 Attention 架構中根據其\n",
      "所在的子資料集做不同的影像處理。 \n",
      "    Attention 架構主要參考了 YOLOv4 的 Backbone 及 Neck 架構來設計，\n",
      "A 子資料集及 B 子資料集在 Backbone 中的處理流程相同，都是利用一層\n",
      "CBM 進行卷積運算以及五層 CSPDarknet53 進行殘差及卷積運算來提取特\n",
      "徵同時防止梯度消失，由於YOLOv4 的 CBL 架構基於卷積運算，而卷積運\n",
      "算受限於 Kernel 大小，因此無法很好地提取全局特徵，所以 A 子資料集在\n",
      "Neck 中 SPP 架構輸出之後使用了 Transformer 中的 Multi-head Self-Attention\n",
      "架構取代了 CBL，稱為 SPP-MHSA，其中 Multi-head Self-Attention 使用了\n",
      "四個 head。Neck 的後半段與 YOLOv4 相似，使用了 FPN 做 Upsampling、\n",
      "PANet 做 downsampling 以提升多尺度目標檢測的能力。 \n",
      "    Prediction 架構用來對 PANet 輸出做多尺度目標檢測，損失函數使用了\n",
      "CIoU 以及 DIoU-NMS。模型準確度在 SSDD 資料集、近海及遠海場景上分\n",
      "別達到了 96.3%、91.78%以及 98.33%。 \n",
      " 在另一篇論文 A streamlined approach for intelligent ship object detection \n",
      "using EL -YOLO algorithm 中提出了 EL-YOLO 的架構[2]，用於提升目標檢\n",
      "測在具有波浪、反射等複雜海洋環境中對於小物體的檢測精度，其輕量化的\n",
      "網路架構在硬體運算資源有限的智慧船舶、無人船舶等領域也有良好的適應\n",
      "性。 \n",
      "EL-YOLO 的架構基於 YOLOv8 進行改進，輸入影像大小為640×640\n",
      "，包含了Backbone、Neck、Head 三個部分，Backbone 中與 YOLOv8 相同，\n",
      "使用了一層CBS 進行卷積運算和四層CBS 加C2f 進行殘差及卷積運算來提\n",
      "取特徵同時防止梯度消失。 \n",
      "在 Neck 部分，因為傳統的 FPN 和 PAN 架構在面對因反射或波浪等背\n",
      "景干擾因素導致特徵信息不足的目標時，容易在多層卷積過程中丟失信息，\n",
      "導致檢測精度下降，所以作者提出了 SMFN (short multi‑fuse neck )架構，在6 \n",
      " \n",
      "YOLOv8 的基礎上，額外加入了較大尺寸的兩個輸入 (320×320和160×\n",
      "160)、一個 Upsampling 層(160×160) 、一個 Fusion 加 C2f 層(160×160)\n",
      "、一個卷積層(80×80)及一個輸出(160×160)到 FPN 和 PAN 架構中，以\n",
      "捕捉更多的特徵信息，並提高對小型目標的檢測能力。 \n",
      "Head 架構因為 Neck 的 SMFN 架構而多了一個160×160的輸出，相較\n",
      "原本只有三個輸出的 YOLOv8 多了一個。在損失函數的部分，因為傳統的\n",
      "CIoU 在處理特徵信息不足的目標時 往往會過度懲罰， 因此作者提出了\n",
      "AWIoU(adequate wise IoU )，通過動態分配不同權重給不同特徵信息量的目\n",
      "標來調整懲罰，避免目標因受背景干擾而造成模型誤判。 \n",
      "在模型訓練完後，為了使其網路架構輕量化以應用於硬體運算資源有限\n",
      "的智慧船舶 、 無人船舶等領域，作者提出了GDFP(Greedy-driven filter pruning)\n",
      "，首先計算每一層中所有 filter 的 L1 範數以得到其重要性分數，並將分數最\n",
      "低的 filter 刪除，在刪除後對模型重新評估，並重複以上操作直到得到理想\n",
      "的模型，最後重新訓練該模型，以得到將模型輕量化的效果。 \n",
      "此模型在 SeaShips 資料集上的mAP0.5 為 0.988， mAP0.5:0.95 為 0.778\n",
      "，在 ABOships 資料集上的mAP0.5 為 0.672，mAP0.5:0.95 為 0.348。 \n",
      "另一篇論文  YOLOSeaShip: a lightweight model for real -time ship \n",
      "detection [3]中提出了 YOLOSeaShip 的架構，用於解決海洋環境中目標檢測\n",
      "的準確性與硬體資源需求之間的矛盾，特別是在實時性要求較高且硬體運算\n",
      "能力有限的應用場景如邊境監控、智慧海洋交通中。 \n",
      "    YOLOSeaShip 的架構基於 YOLOv7-tiny 進行改進，包含了 Input、\n",
      "Backbone 和 Head 三個主要部分。 \n",
      "Input 架構上採用了 Mosaic 數據增強技術，通過隨機裁剪並拼接多張影\n",
      "像，增加數據的多樣性與小目標樣本數。此外，使用自適應圖片縮放技術來\n",
      "處理不同尺度的目標，並結合K-means 分群方法優化錨框的尺寸設定，避免\n",
      "人工設計過程中的偏差。 \n",
      "Backbone 的部分，YOLOSeaShip 引入了 PConv（Partial Convolution ）\n",
      "架構替代了原本的卷積操作。該架構僅對部分通道進行計算，從而有效減少\n",
      "了參數量並提升計算效率。此外，每層池化操作後 還加入了 PfAAM（\n",
      "Parameter-Free Average Attention Module）。PfAAM 基於空間和通道的平均值\n",
      "計算注意力權重，不增加模型參數的情況下提升了模型對關鍵區域的定位能\n",
      "力。 \n",
      "Head 部分，模型加入了SPPCSPC_tiny 架構，通過多尺度（5×5、9×9 和\n",
      "13×13）最大池化層結合本地與全局特徵，增強對不同大小目標的檢測能力\n",
      "。模型的最終輸出包含三個不同大小的特徵圖，用於處理不同尺度的目標檢\n",
      "測。 \n",
      "在損失函數設計上，作者提出了 Focal EIOU（Focal and Efficient IOU）\n",
      "損失函數，結合了 EIOU 和 Focal Loss 的優點。EIOU 損失通過細化目標框7 \n",
      " \n",
      "的寬高比差異來提升回歸精度，而Focal Loss 則用於平衡正負樣本比例，讓\n",
      "模型更關注高質量的預測框。 \n",
      "為了評估模型性能，作者在 SeaShips(7000)資料集上進行實驗，訓練時\n",
      "採用 Adam 優化器，學習率為 0.001，訓練 300 個 epoch。結果顯示，\n",
      "YOLOSeaShip 的 mAP 達到 0.976，檢測速度達到119.84 FPS，相較YOLOv7-\n",
      "tiny 模型，參數量減少至 4.78M，同時大幅提升了檢測速度和資源效率。 \n",
      "在論文 An Improved YOLO v4 Algorithm-based Object Detection Method \n",
      "for Maritime Vessels[4]中提出了基於改進 YOLOv4 的船舶和泊位檢測方法，\n",
      "用於提升目標檢測在複雜海洋環境下的準確性，特別是對港口泊位的檢測效\n",
      "果進行了優化。該方法通過改良 錨框的生成方式和數據集構建，改善了\n",
      "YOLOv4 在海洋場景中的檢測性能，適用於智能船舶的安全輔助系統。 \n",
      "改進的 YOLOv4 架構包含了 Backbone、Neck 和 Head 三個部分。\n",
      "Backbone 部分採用了 CSPDarknet53 作為特徵提取模塊，通過 ResUnit 組件\n",
      "進行深度卷積操作，增強特徵提取能力。Neck 部分引入了 SPP 層和 PANet\n",
      "層，其中 SPP 層通過多尺度池化操作擴展感受野，而 PANet 則將底層的定\n",
      "位信息與高層的語義信息結合，提高多尺度目標的檢測能力。Head 部分則\n",
      "採用了 YOLOv3 的檢測頭，輸出不同尺度的檢測結果。 \n",
      "針對泊位檢測效果不足的問題，作者採用了 K-means 演算法重新生成\n",
      "錨框。在原始 YOLOv4 模型中，錨框基於 MS COCO 和 VOC 數據集生成，\n",
      "但這些框與船舶與泊位數據集中的物體尺寸不匹配，影響了檢測精度。改進\n",
      "後的 K-means 演算法針對數據集進行分群，生成了9 組適配的錨框，有效提\n",
      "升了檢測效率和準確性。 \n",
      "此外，作者構建了一個包含船舶和泊位的專用數據集，通過智能實驗船\n",
      "上的攝像頭在港口拍攝的實景影像生成，並結合公開數據集如MS COCO 和\n",
      "VOC 補充正樣本數量。最終數據集中包含6634 張標註影像，其中70%用於\n",
      "訓練，30%用於測試。標註信息包括物體類別及邊界框的坐標和尺寸。 \n",
      "實驗結果表明，改進的YOLOv4 模型在 mAP 和 F1-score 方面分別提升\n",
      "了 2.79%和 0.80%，相較於原始YOLOv4 達到了更高的檢測精度與穩定性。\n",
      "具體指標顯示，改進後的YOLOv4 模型在 mAP 上達到 83.98%，F1-score 達\n",
      "到 86.18%，而 YOLOv4_tiny 僅達到 54.45%的 mAP 和 54.82%的 F1-score，\n",
      "說明輕量化模型雖然具有更快的檢測速度，但在檢測準確性上仍有進步空間\n",
      "。8 \n",
      " \n",
      "三、 研究方法 \n",
      "1. 資料收集 \n",
      "    資料集使用 Singapore Maritime Dataset 的 Visible On-Shore 資料集[5, 6]加上\n",
      "ABOships-PLUS[7]以及手動標註公司提供的高雄資料集。 \n",
      "    Visible On-Shore 資料集為網路上的公開資料集，包含 38 部長度小於 33 秒\n",
      "的全彩影片，屬於中、遠港船隻影像資料集，其中含有 7 個船隻類別，此資料集\n",
      "特徵為船隻背景為海面、天空等較乾淨的畫面。 \n",
      " \n",
      "表一、Visible On-Shore 資料集類別 \n",
      "Lable Data   \n",
      "Ferry \n",
      " \n",
      "SailsBoat \n",
      " \n",
      "PatrolBoat \n",
      " \n",
      "MerchantShip \n",
      " \n",
      "FishingBoat \n",
      " \n",
      "Tugboat \n",
      " \n",
      "BargeShip9 \n",
      " \n",
      "    ABOships-PLUS 資料集為網路上的公開資料集，ABOships 資料集的改進版\n",
      "本，包含 9880 張影像，33227 個標註，屬於近港船隻影像資料集，其中含有 3 個\n",
      "船隻類別，此資料集特徵為船隻背景包含陸地建築物等容易誤判的畫面。 \n",
      " \n",
      "表二、ABOships-PLUS 資料集類別 \n",
      "Lable Data   \n",
      "powerboat \n",
      " \n",
      "sailboat \n",
      " \n",
      "ship \n",
      " \n",
      "  \n",
      " \n",
      "    高雄資料集為高雄實地拍攝的非公開資料集，包含 504 部長度小於 10 秒的\n",
      "影片，屬於近、中港船隻影像資料集，其中含有 4 個船隻類別，此資料集特徵為\n",
      "船隻背景包含陸地建築物等容易誤判的畫面。 \n",
      " \n",
      "表三、高雄資料集類別 \n",
      "Lable Data   \n",
      "PatrolBoat \n",
      " \n",
      "Yacht \n",
      " \n",
      "MerchantShip \n",
      " \n",
      "Tugboat10 \n",
      " \n",
      "2. 資料前處理 \n",
      "    \n",
      " \n",
      "圖一、資料前處理流程圖。 \n",
      "    如圖一所示，首先會將資料集處理成只包含 images 和 labels 資料夾的\n",
      "形式，images 和 labels 中的檔案是兩兩對應的，並且labels 內的標註檔格式\n",
      "為 yolo 格式。再來會刪除有問題的標註檔及圖片，例如標註檔為空、包含\n",
      "不存在類別、格式錯誤、圖片模糊或者有破圖情況等。第三步是合併資料集\n",
      "，這步是可選的，主要會將數個資料集合併，並記錄合併後的類別名稱。第\n",
      "四步是篩選類別，這步同樣為可選，主要會將需要的類別保留，不需要的剔\n",
      "除。接著因為同一圖片中可能包含數量不等的不同類別物件，因此在切分訓\n",
      "練集和驗證集時，容易造成不同類別的訓練驗證比例不同的情況，所以第五\n",
      "步會將包含 n 個物件的標註檔拆分成 n 份，每一份只包含1 個原始標註檔的\n",
      "物件，彼此不重複，且與其對應的圖片同樣複製 n 份，以確保每個類別都按\n",
      "照正確比例進行切分，最後一步為按照自訂比例切分訓練集及驗證集。 \n",
      "3. 船隻辨識模型 \n",
      "    我們使用了最新的YOLOv11[8]模型來建置船隻辨識模型 ，YOLOv11 基\n",
      "於 PyTorch 架構開發，可在一次前向傳播中同時定位及辨識物件，具有速度\n",
      "快、所需資源少、開發便利及多尺度檢測等優點。圖二為 YOLOv11 架構圖\n",
      "，首先輸入的圖片為 640x640x3 的 RGB 圖像，接著 YOLOv11 可以根據此\n",
      "架構分為三個部分，Backbone, Neck 以及 Head。11 \n",
      " \n",
      " \n",
      "圖二、YOLOv11 架構圖[9] \n",
      " \n",
      "Backbone 如圖二左側所示，主要目的是從輸入影像中提取有用的特徵\n",
      "資訊。在 YOLOv11 中，Backbone 採用了 C3K2 結構，為升級版的 C3，透\n",
      "過更小的卷積核與路徑切分技術，在保持模型表現的前提下大幅降低了計算\n",
      "成本。每個C3K2 中包含兩條路徑，一條直接進行卷積處理，另一條則經過\n",
      "多個 Bottleneck 區塊進行深度特徵學習，最後進行特徵融合。這種結構不僅\n",
      "有效防止梯度消失問題，也能提升網路的收斂速度與特徵提取效率。 \n",
      "Neck 部分如圖二中間所示，結合了 SPFF(Spatial Pyramid Pooling Fast)\n",
      "架構和多層 C2PSA 區塊。SPFF 架構是 SPP 的高速版本，透過不同尺度的\n",
      "最大池化操作將特徵圖進行多尺度融合，再透過 Concatenation 將資訊彙整\n",
      "，幫助模型更好地識別大小不一的船隻。此外，Neck 中的 C2PSA 架構引入\n",
      "空間注意力機制(Spatial Attention)，能讓模型聚焦在關鍵影像區域，特別是\n",
      "對小型或部分遮蔽的物件表現更佳。這部分的架構延續了FPN 與 PAN 的優\n",
      "點，強化了從深層到淺層、再回到深層的資訊傳遞，進一步提升辨識與定位\n",
      "的能力。 \n",
      "Head 如圖二右側所示，負責進行最後的物件偵測任務。YOLOv11 採用\n",
      "多尺度輸出策略，透過多層輸出特徵圖分別負責不同大小目標的偵測。\n",
      "YOLOv11 會利用不同尺寸與比例的錨框(Anchor Boxes)來涵蓋不同形狀的\n",
      "目標，並透過 Non-Maximum Suppression(NMS)過濾重疊的邊界框，保留最\n",
      "具代表性的偵測結果。12 \n",
      " \n",
      "四、 實驗結果 \n",
      "    我們使用 YOLOv11l 模型，訓練集使用 ABOships-PLUS，測試集使用\n",
      "高雄資料集，實驗環境為 64-bit Windows 11、Intel i5-13400F 2.5GHz CPU、\n",
      "32GB RAM 及 NVIDIA RTX 4070 GPU。除了測試模型在原先新加坡資料集\n",
      "的效果外，實驗還在高雄資料集上針對船隻速度、距離以及避碰能力做檢測\n",
      "，因實際場域在白天時使用的是彩色影像，黑夜時使用的是黑白影像當作模\n",
      "型輸入，所以實驗也同時測試了模型對彩色和黑白影像的辨識能力，檢測方\n",
      "式為當船隻出現的 3 秒內有辨識到至少 1 次則辨識成功，反之辨識失敗，同\n",
      "一部影片中辨識成功的數量與真實船隻的數量比值即為檢測率。實驗時我們\n",
      "同時比較了 1 秒內有辨識到船隻、2 秒內有辨識到船隻的檢測率以更精確地\n",
      "測量模型的辨識能力，以下為檢測效果。 \n",
      " \n",
      "表四、實驗結果檢測率 \n",
      "測試影片 1 秒內檢測率 2 秒內檢測率 3 秒內檢測率 \n",
      "彩色影片 output_005 1.0 1.0 1.0 \n",
      "彩色影片 output_041 1.0 1.0 1.0 \n",
      "彩色影片 output_080 1.0 1.0 1.0 \n",
      "彩色影片 output_097 1.0 1.0 1.0 \n",
      "黑白影片 output_199 0.67 1.0 1.0 \n",
      "黑白影片 output_202 0.67 1.0 1.0 \n",
      "黑白影片 output_276 1.0 1.0 1.0 \n",
      "黑白影片 output_290 0.75 0.75 1.0 \n",
      " \n",
      "    如上表所示，原要求的 3 秒內檢測率全部達標，都為 1.0，2 秒與 1 秒\n",
      "內的檢測率也大部分都是 1.0，其中判錯的情況都是在船隻彼此重疊時或影\n",
      "像較模糊時發生，一般的應用情況幾乎不會有問題。13 \n",
      " \n",
      " \n",
      "圖三、彩色影片 output_005 第一秒影像 \n",
      "    彩色影片 output_005 的第一秒影像如上圖所示，圖中模型成功辨識出所\n",
      "有船隻，1~3 秒內的檢測率都為 1.0。 \n",
      " \n",
      "圖四、彩色影片 output_041 第一秒影像 \n",
      "    彩色影片 output_041 的第一秒影像如上圖所示，圖中模型成功辨識出所\n",
      "有船隻，1~3 秒內的檢測率都為 1.0。14 \n",
      " \n",
      " \n",
      "圖五、彩色影片 output_080 第一秒影像 \n",
      "    彩色影片 output_080 的第一秒影像如上圖所示，圖中模型成功辨識出所\n",
      "有船隻，1~3 秒內的檢測率都為 1.0。 \n",
      " \n",
      "圖六、彩色影片 output_097 第一秒影像 \n",
      "    彩色影片 output_097 的第一秒影像如上圖所示，圖中模型成功辨識出所\n",
      "有船隻，1~3 秒內的檢測率都為 1.0。15 \n",
      " \n",
      " \n",
      "圖七、黑白影片 output_199 第二秒影像 \n",
      "    彩色影片 output_199 的第二秒影像如上圖所示，圖中模型成功辨識出所\n",
      "有船隻，2~3 秒內的檢測率都為 1.0。 \n",
      " \n",
      "圖八、黑白影片 output_202 第二秒影像 \n",
      "    彩色影片 output_202 的第二秒影像如上圖所示，圖中模型成功辨識出所\n",
      "有船隻，2~3 秒內的檢測率都為 1.0。16 \n",
      " \n",
      " \n",
      "圖九、黑白影片 output_276 第一秒影像 \n",
      "    彩色影片 output_276 的第一秒影像如上圖所示，圖中模型成功辨識出所\n",
      "有船隻，1~3 秒內的檢測率都為 1.0。 \n",
      " \n",
      "圖十、黑白影片 output_290 第三秒影像 \n",
      "    彩色影片 output_290 的第三秒影像如上圖所示，圖中模型成功辨識出所\n",
      "有船隻，3 秒內的檢測率都為 1.0。17 \n",
      " \n",
      "表五、KPI 完成表 \n",
      "項目 達成狀況 \n",
      "1.建立 AI 分析海事觀測演算法邏輯架構 已達成 \n",
      "2.完成演算法建立，並可在本島沿海 3 公里海域內環境進行 已達成 \n",
      "3.演算結果可達以下規格標準: \n",
      "通訊傳輸速率>250kbps 以上 已達成 \n",
      "影像解析度> 640x480 已達成 \n",
      "影像幀速率≧ 10FPS 已達成 \n",
      "船隻移動速度≧15 節(30km/hr) 已達成 \n",
      "船隻辨識數量≧ 10 已達成 \n",
      "船隻辨識大小> 15m 已達成 \n",
      "船隻辨識距離≧5km 已達成 \n",
      "船隻避碰距離≧3.7km 已達成 \n",
      "船隻辨識準確度≧90% 已達成 \n",
      " \n",
      "KPI 完成表如上所示，全部項目都已完成。18 \n",
      " \n",
      "五、 結論 \n",
      "本計畫目的為設計出可以有效辨識 3 公里遠的船隻，且一次可辨識長度 15\n",
      "公尺的船隻 10 艘以上的模型，根據目前的實驗結果，模型在船隻距離、速度、\n",
      "目標數量以及避碰能力上都有達到目標，並且模型在彩色及黑白影片上的表現也\n",
      "能夠符合實際應用場域需求。19 \n",
      " \n",
      "六、 參考文獻 \n",
      "[1] Sun, Bowen, et al. \"Automatic ship object detection model based on YOLOv4 \n",
      "with transformer mechanism in remote sensing images.\" Applied Sciences vol. \n",
      "13. No. 4, p. 2488, 2023. \n",
      "[2] Yang, Defu, et al. \"A streamlined approach for intelligent ship object detection \n",
      "using EL-YOLO algorithm.\" Scientific Reports, vol. 14. No.1, p.15254, 2024. \n",
      "[3] Jiang, X., Cai, J., & Wang, B. (2024). YOLOSeaShip: a lightweight model for \n",
      "real-time ship detection. European Journal of Remote Sensing, 57(1). \n",
      "https://doi.org/10.1080/22797254.2024.2307613 \n",
      "[4] He, Guowen & Wang, Wenlong & Shi, Bowen & Liu, Shijie & Xiang, Hui & \n",
      "Wang, Xiaoyuan. (2022). An Improved YOLO v4 Algorithm-based Object \n",
      "Detection Method for Maritime Vessels. International Journal of Science and \n",
      "Engineering Applications. 11. 50-55. 10.7753/IJSEA1104.1001. \n",
      "[5] D. K. Prasad, D. Rajan, L. Rachmawati, E. Rajabaly, and C. Quek, “Video \n",
      "Processing from Electro-optical Sensors for Object Detection and Tracking in \n",
      "Maritime Environment: A Survey,” IEEE Transactions on Intelligent \n",
      "Transportation Systems (IEEE), 18 (8), 1993 - 2016, 2017. \n",
      "[6] D. K. Prasad, “Singapore Maritime Dataset, Visible On-Shore dataset,” Available \n",
      "Online: https://sites.google.com/site/dilipprasad/home/singapore-maritime-\n",
      "dataset \n",
      "[7] Winsten Jesper, Iancu Bogdan, Soloviev Valentin, & Lilius Johan. (2024). \n",
      "ABOships-PLUS [Data set]. Zenodo. https://doi.org/10.5281/zenodo.10469672 \n",
      "[8] Glenn Jocher and Jing Qiu, “Ultralytics YOLO11,” Available Online: \n",
      "https://github.com/ultralytics/ultralytics \n",
      "[9] Medium, “YOLOv11 Architecture Explained: Next-Level Object Detection with \n",
      "Enhanced Speed and Accuracy,” Available Online: https://medium.com/@nikhil-\n",
      "rao-20/yolov11-explained-next-level-object-detection-with-enhanced-speed-and-\n",
      "accuracy-2dbe2d376f71\n",
      "===\n",
      "請根據以上文件內容，模擬一位業務代表會向 TPM 詢問有關 即時辨識 24 海里內船隻平台 的1個問題或轉述的需求。\n",
      "\n",
      "---------- TextMessage (Business) ----------\n",
      "Hi TPM，剛剛跟一家航運管理公司的客戶聊到，他們提到目前的即時海洋觀測系統偵測距離是5公里左右（約3海里），他們想了解可不可以擴充成能夠即時辨識24海里內的船隻？因為他們需要更廣的海域監控，預防遠距離船隻靠近港口的安全風險。不過他們也擔心距離拉遠會不會讓辨識的準確度大幅下降，或者系統負擔會不會變太重？不知道這樣的需求技術上有什麼做法或限制？我們有沒有案例或想法可以先跟客戶回應？\n",
      "---------- TextMessage (TPM) ----------\n",
      "感謝你的說明，針對客戶想將即時海洋觀測系統的偵測距離從目前約3海里 (5公里) 擴充到24海里 (約44公里) 這個需求，我目前有以下幾個需要釐清的問題，幫助我們更準確理解其期望與使用情境：\n",
      "\n",
      "1. **使用情境與目標**  \n",
      "   - 客戶希望24海里範圍內即時偵測船隻，是持續且連續監控，還是只需要定時或事件觸發偵測？  \n",
      "   - 他們對「即時」的幀率或延遲容忍度有無具體要求（例如每秒幾幀、可接受的識別延遲時間）？  \n",
      "   - 是否需要同時辨識10艘以上的船隻目標？過去系統表現有此需求嗎？\n",
      "\n",
      "2. **硬體與環境限制**  \n",
      "   - 目前平台所使用的攝影設備（鏡頭規格、感光度、安裝高度等）是否可以在更遠距離保持有效影像品質？  \n",
      "   - 客戶是否有計畫或預算升級攝影硬體？或希望純粹用現有設備做軟體優化？\n",
      "\n",
      "3. **辨識準確度與安全風險容忍度**  \n",
      "   - 目前系統在5公里內約達90%的準確率，若在24海里距離辨識準確度下降（例如降到60%、70%），是否仍符合他們的安全風險需求？  \n",
      "   - 需要辨識的船隻大小、速度等細節是否與現有設定一致？還是有更嚴格或更多樣化的目標？\n",
      "\n",
      "4. **系統負載與運算資源**  \n",
      "   - 他們期望平台是在現有架構下升級，還是可以接受新增硬體（如更強GPU、邊緣運算節點）？  \n",
      "   - 是否能接受辨識精度與運算速度的trade-off（例如降低幀率以維持遠距離辨識）？\n",
      "\n",
      "有了這些細節後，我能協助評估從技術面是否有可行的解法，以及不同方案的優劣與風險，接著再彙整給您或直接回覆客戶。\n",
      "\n",
      "目前從已有計畫和文獻來看，遠距離辨識在影像品質下降、目標物訊號弱化時會面臨挑戰，可能需要搭配更高解析度攝影機、更強大的AI模型（或模型調校）、以及更高的計算資源；同時也可考慮結合雷達、AIS等多感測資料融合，提升長距辨識的效果與可靠性。\n",
      "\n",
      "請問上述的釐清方向是否符合？還是客戶有其他重點需求需要我們特別注意？\n",
      "---------- TextMessage (Business) ----------\n",
      "謝謝你的詳盡回覆！我先以模擬客戶的角度來補充回應：\n",
      "\n",
      "1. 使用情境與目標：客戶是希望能有連續且接近即時的監控，尤其在繁忙海域要持續掌握遠距離船隻動態，幀率希望至少能維持5FPS以上，延遲不可超過2秒。他們仍希望能同時偵測超過10艘船隻，因為海域常有多船活動。\n",
      "\n",
      "2. 硬體與環境限制：客戶目前使用的監控鏡頭大多是中階型號，感光度及變焦能力有限，拍攝角度多為岸邊或碼頭高點安裝。短期內沒有大幅升級硬體的預算，但有意願評估少量升級（例如更換更高解析度鏡頭）。他們較希望先測試看軟體優化可達的效果。\n",
      "\n",
      "3. 辨識準確度與安全風險容忍度：客戶能接受辨識準確度在遠距離有所降低，但希望不要低於70%。船隻大小及速度條件跟現有類似，以大型商船與漁船為主。\n",
      "\n",
      "4. 系統負載與運算資源：客戶希望盡可能利用現有系統架構，除非必要，不願意頻繁增購硬體。但若確定可以透過硬體升級大幅提升性能，也願意評估。\n",
      "\n",
      "整體來看，客戶期待是一個平衡方案，希望能先藉由我們過去已有的AI模型與資料優化，推動軟體端的效能提升，並且評估逐步的小規模硬體升級可能，分階段達到他們24海里即時辨識的目標。\n",
      "\n",
      "我這邊先把這些需求整理出來，方便您做初步評估後，我再回報給客戶，謝謝！\n",
      "---------- TextMessage (TPM) ----------\n",
      "感謝你補充客戶的詳細需求，這樣資訊非常有助於我們進行技術評估。根據目前掌握的情況，我將進入【第二階段：提出可行技術組合與解法建議】，先提出兩個可行方向供參考，針對客戶希望在既有系統基礎上，分階段達到24海里內即時辨識的平衡方案：\n",
      "\n",
      "---\n",
      "\n",
      "### 技術組合與解法建議\n",
      "\n",
      "#### 方案一：軟體優化＋現有硬體的極限調整\n",
      "- **核心想法**  \n",
      "  利用已有的YOLOv11模型架構，針對遠距離特徵弱化問題，做進一步模型微調與強化（如改良影像增強演算法，加強遠距特徵提取的注意力機制），並結合多尺度、多角度資料重新訓練，提升模型對遠距離薄弱訊號的辨識力。\n",
      "- **硬體條件**  \n",
      "  盡量用現有中階鏡頭，並在軟體端做影像前處理（去霧、增亮等）及拼接多時序影像來增加辨識機會。不優先更換硬體，符合客戶短期無大升級預算。\n",
      "- **效能預期**  \n",
      "  可望延伸有效偵測距離到10-15公里（約6-8海里），辨識準確率可在70%-80%之間，幀率在5FPS上下，延遲控制在2秒內可望達成，但難以完全覆蓋24海里。\n",
      "- **限制與風險**  \n",
      "  遠距影像訊號受環境影響大，準確率提升有限，且偵測範圍增大會造成有效像素下降，辨識器需要更敏感的特徵提取，運算負荷可能增加，需實驗驗證。\n",
      "\n",
      "#### 方案二：軟體優化＋部分硬體升級（高解析鏡頭＋邊緣運算）\n",
      "- **核心想法**  \n",
      "  在方案一基礎上，採用更高解析度的攝影鏡頭（例如4K解析度），利用解析度提升來拉長有效偵測距離及精細辨識遠距目標；此外，在岸邊安裝邊緣運算裝置，搭載優化的AI辨識模型，緩解中央系統負載並減低通訊延遲。\n",
      "- **硬體條件**  \n",
      "  客戶可先小規模升級部分關鍵點鏡頭（如重要港口或監控要點），邊緣計算設備可採用既有系統兼容的GPU或AI加速卡，避免大規模換新。\n",
      "- **效能預期**  \n",
      "  預估可達到15-20公里範圍，辨識準確率可穩定在75%-85%，維持5FPS以上及2秒延遲內；可同時精準監控超過10艘船隻且減輕中央系統負載。\n",
      "- **限制與風險**  \n",
      "  硬體升級但非全面，需評估場域佈局是否有效支持遠距離偵測；邊緣運算設備規格與維護成本需提前規劃；此外系統整合複雜度提高。\n",
      "\n",
      "---\n",
      "\n",
      "### 備註與待確認事項\n",
      "- 需確認目前現有鏡頭實際影像品質現況，如解析度、視野角度及光學變焦能力，才能細化優化方向及升級預算評估。  \n",
      "- 目前24海里的偵測距離在光學影像系統上屬於極限挑戰，軟體調整必須配合硬體支持，且環境因素（天氣、海況）影響更大。  \n",
      "- 可評估與雷達或AIS系統融合，作為遠距離初步篩選，提高整體監控可靠度。\n",
      "\n",
      "---\n",
      "\n",
      "我建議先以方案一做小規模PoC（Proof of Concept）測試，驗證軟體優化後的偵測與辨識能力提升幅度，再根據結果評估是否推動方案二階段性硬體升級。\n",
      "\n",
      "接下來我可協助拆解必要的評估任務與資源規劃，您覺得這樣的技術回應方向是否符合您與客戶期待？還是需要更聚焦某個面向？\n",
      "---------- TextMessage (Business) ----------\n",
      "感謝你的詳細分析與建議！我覺得你提出的兩個方案相當符合客戶目前期望的分階段策略，尤其是先從軟體提升做PoC再考慮硬體升級，能夠降低他們的初期風險，也較符合他們希望優先利用現有設備的意向。\n",
      "\n",
      "我這邊先回報給客戶，強調方案一可先行推動，看看軟體端優化效果能推多遠，再依結果討論是否投入方案二，含硬體升級與邊緣運算的可能性。\n",
      "\n",
      "另外，客戶很關注現有鏡頭規格和畫質是否適合遠距辨識，能否協助我們做個簡單的現場鏡頭影像品質評估？這樣也方便我們更精準地做PoC設計。\n",
      "\n",
      "最後，我想先確認下個階段如果要做PoC，是需要我們配合試驗數據提供，還是你方有建議的實驗環境？或者需要客戶提供現場錄影素材？\n",
      "\n",
      "謝謝！\n",
      "---------- TextMessage (TPM) ----------\n",
      "感謝你的回饋，了解客戶的想法與後續需求後，我針對接下來的PoC準備與執行，提出以下建議與規劃方向，供你與客戶參考：\n",
      "\n",
      "---\n",
      "\n",
      "### 1. 現場鏡頭影像品質評估  \n",
      "- **建議方式**：  \n",
      "  可派遣技術團隊以現場鏡頭實際拍攝一段包含各種典型海況（晴天、陰天、霧天、夜間）的影片，或由客戶提供若干現有錄影素材，以多角度、多距離測試當前影像品質。  \n",
      "- **評估重點**：  \n",
      "  - 解析度與視野角度是否足以涵蓋目標偵測範圍。  \n",
      "  - 影像清晰度、噪點、反光與霧氣對圖像品質的影響程度。  \n",
      "  - 中距到遠距目標在畫面中的像素大小範圍。  \n",
      "- **交付物**：提供現場錄影樣本與技術評估報告，協助做後續PoC的模型調整依據。  \n",
      "\n",
      "---\n",
      "\n",
      "### 2. PoC階段實驗環境與數據需求  \n",
      "- **數據提供**：  \n",
      "  - 從客戶側收集現有的監控錄影（推薦含多條視角與時間段，彩色與黑白均可）作為訓練及測試資料。  \n",
      "  - 若無足夠資料，則可結合公開資料集與自建資料集進行混合訓練，並用客戶錄影做測試驗證。  \n",
      "- **實驗架構**：  \n",
      "  - 模型部署可先在本地測試環境執行，利用已有設備的錄影素材以模擬實時影像輸入。  \n",
      "  - 可視情況與客戶協調，安排短期現場測試（例如選擇代表性監控點進行實地錄像與即時辨識演示）。  \n",
      "- **技術支持**：  \n",
      "  - 提供軟體調整及模型訓練方案。  \n",
      "  - 針對影像前處理、動態場景適應做優化測試。  \n",
      "  - 幀率與延遲測試以符合客戶5FPS以上、延遲低於2秒的要求。  \n",
      "\n",
      "---\n",
      "\n",
      "### 3. 預期交付成果與後續規劃  \n",
      "- PoC結束後，將提供性能評估報告，包含：  \n",
      "  - 不同距離與條件下的辨識準確率、幀率和延遲數據。  \n",
      "  - 可接受的最長即時偵測距離及瓶頸分析。  \n",
      "- 根據PoC結果，與客戶討論是否及如何執行小規模硬體升級（方案二），包括鏡頭及邊緣運算設備。  \n",
      "\n",
      "---\n",
      "\n",
      "### 4. 風險與注意事項  \n",
      "- 請確保現場錄影涵蓋多樣環境情境，避免PoC過於理想化。  \n",
      "- 可能需要一些時間進行資料整理與標註，以確保模型訓練質量。  \n",
      "- 若客戶錄像品質過低，遠距辨識效果可能受限，需提前溝通期望值。  \n",
      "\n",
      "---\n",
      "\n",
      "請問以上規劃是否符合你與客戶的期待？我可以準備一份簡短的PoC技術方案及時間表，方便你回報與溝通；並可協助安排技術支持團隊與客戶對接完成影像資料收集。若有其他需求或想更聚焦某階段，請隨時告知。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(id='895b1b31-554c-44ea-b771-cee83e804185', source='user', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 7, 27, 12, 58, 9, 656718, tzinfo=datetime.timezone.utc), content='\\n以下是提供你閱讀的計畫文件：\\n===\\n附件四、報告格式 \\n \\n \\n \\n \\n \\n \\n即時海洋觀測平台開發暨AI影像數據應用服\\n務主題式研發計畫 \\n \\n期末報告1 \\n \\n即時海洋觀測平台開發暨 AI 影像數據應用服務主題式研發\\n計畫 \\n \\n \\n \\n \\n期末報告 \\n \\n \\n \\n \\n \\n \\n \\n \\n計畫主持人：林家瑜 助理教授     \\n研究機構  ：國立中央大學資訊工程系 \\n執行期間  ：113/05/01-114/04/30（請填寫合作研究計畫執行期間） \\n \\n(以上資料請務必以中文繕打清楚) \\n \\n中華民國 114 年 01 月31 日2 \\n \\n計畫摘要 \\n    本研究致力於開發即時海洋觀測平台，並應用 AI 影像數據分析來提升遠距離船\\n隻辨識的準確性與效率。現行船舶識別技術主要依賴人眼辨識，然而在 3 公里以上距\\n離，由於海面反射、霧氣與光線變化等環境因素的影響，傳統方法的準確率明顯下\\n降。本計畫旨在透過深度學習物件辨識技術，建立一套高效能的「即時遠距離多船隻\\n辨識系統」，能夠在 3 公里外準確偵測船隻，並可同時識別 10 艘以上長度超過 15 公\\n尺的船隻。 \\n    本研究參考 YOLOv5s 與YOLOv8 物件辨識模型，針對海洋環境特性進行改良，\\n並利用多種公開及自建數據集如 Singapore Maritime Dataset、ABOships-PLUS、高雄\\n港實測數據進行模型訓練與驗證。透過影像增強、特徵提取優化與多尺度檢測技術，\\n我們顯著提升了模型在複雜海洋場景中的識別能力。 \\n    目前的實驗結果顯示，我們的系統在新加坡與高雄測試數據集中的部分影像皆展\\n現超過 90%的識別準確度，並成功達成： \\n⚫ 可偵測移動速度超過 15 節的船隻 \\n⚫ 在 5 公里範圍內實現高效識別 \\n⚫ 可即時處理 640×480 解析度影像，幀率≥10FPS \\n⚫ 具備船隻避碰預警功能 \\n    未來將進一步提升船隻辨識與船隻避碰預測的準確度，並擴充模型至夜間與黑白\\n影像辨識，以提升即時監測與應用能力。此技術的發展對於海洋交通安全監控、智慧\\n港口管理與海上救援應用將具備重要價值。 \\n \\n關鍵字：即時海洋觀測、AI 影像辨識、深度學習、YOLOv5、YOLOv8、多尺度檢\\n測、船隻辨識、避碰預警、智慧港口、遠距離監測3 \\n \\n目錄 \\n計畫摘要 ....................................................................................................................... 2 \\n一、計畫動機與目的 ................................................................................................... 4 \\n1. 動機 ..................................................................................................................... 4 \\n2. 目的 ..................................................................................................................... 4 \\n二、文獻探討 ............................................................................................................... 5 \\n三、研究方法 ............................................................................................................... 8 \\n1. 資料收集 ............................................................................................................. 8 \\n2. 資料前處理 ....................................................................................................... 10 \\n3. 船隻辨識模型 ................................................................................................... 10 \\n四、實驗結果 ............................................................................................................. 12 \\n五、結論 ..................................................................................................................... 18 \\n六、參考文獻 ............................................................................................................. 194 \\n \\n一、 計畫動機與目的 \\n1. 動機 \\n在海洋環境中，對於船隻的及時且準確的辨識是保障航行安全和有效執\\n行海上作業的關鍵。但目前大部分的船隻都是人工辨識，而人眼無法同時看\\n超過 10 艘船隻進行辨識，因此需要 AI 輔助。現有的 AI 對距離近且較大的\\n船或是俯視角的衛星雷達成像的船有不錯的辨識能力，但若是在第一人稱且\\n距離超過 3 公里的情況下，可能會受到環境條件如海面反射、霧氣、光線變\\n化等的影響，導致偵測的準確度降低，且現有開放資料集大多是較大的船隻\\n，3 公里以上的船隻資料集較少，不利於訓練模型。 \\n2. 目的 \\n基於上述的問題，本計畫欲設計一套「即時遠距離多船隻辨識系統」 ，\\n此系統可以有效辨識 3 公里遠的船隻，且一次可辨識長度15 公尺的船隻 10\\n艘以上。5 \\n \\n二、 文獻探討 \\n現在有一些研究採用物件辨識模型進行船隻辨識，在 Automatic Ship \\nObject Detection Model Based on YOLOv4 with Transformer Mechanism in \\nRemote Sensing Images 論文中提出了名為 Auto-T-YOLO 的架構[1]，用於解\\n決現有物件偵測模型從輸入中提取特徵未能充分考慮全局特徵，且無法根據\\n輸入的特徵自動調整，導致偵測準確度下降的問題。 \\n    Auto-T-YOLO 的模型架構分為三個部分 ，Preattention, Attention 和\\nPrediction。輸入影像大小為608×608×3，Preattention 和 Attention 的設計\\n模仿了人類視覺系統中從大的全局特徵開始，再逐步轉向局部細節的兩階段\\n注意機制。 \\n    在 Preattention 架構中，輸入的圖像會根據其中是否包含𝑠𝑖𝑧𝑒 > 32×32\\n的物件分為 A 子資料集及 B 子資料集，並在之後的 Attention 架構中根據其\\n所在的子資料集做不同的影像處理。 \\n    Attention 架構主要參考了 YOLOv4 的 Backbone 及 Neck 架構來設計，\\nA 子資料集及 B 子資料集在 Backbone 中的處理流程相同，都是利用一層\\nCBM 進行卷積運算以及五層 CSPDarknet53 進行殘差及卷積運算來提取特\\n徵同時防止梯度消失，由於YOLOv4 的 CBL 架構基於卷積運算，而卷積運\\n算受限於 Kernel 大小，因此無法很好地提取全局特徵，所以 A 子資料集在\\nNeck 中 SPP 架構輸出之後使用了 Transformer 中的 Multi-head Self-Attention\\n架構取代了 CBL，稱為 SPP-MHSA，其中 Multi-head Self-Attention 使用了\\n四個 head。Neck 的後半段與 YOLOv4 相似，使用了 FPN 做 Upsampling、\\nPANet 做 downsampling 以提升多尺度目標檢測的能力。 \\n    Prediction 架構用來對 PANet 輸出做多尺度目標檢測，損失函數使用了\\nCIoU 以及 DIoU-NMS。模型準確度在 SSDD 資料集、近海及遠海場景上分\\n別達到了 96.3%、91.78%以及 98.33%。 \\n 在另一篇論文 A streamlined approach for intelligent ship object detection \\nusing EL -YOLO algorithm 中提出了 EL-YOLO 的架構[2]，用於提升目標檢\\n測在具有波浪、反射等複雜海洋環境中對於小物體的檢測精度，其輕量化的\\n網路架構在硬體運算資源有限的智慧船舶、無人船舶等領域也有良好的適應\\n性。 \\nEL-YOLO 的架構基於 YOLOv8 進行改進，輸入影像大小為640×640\\n，包含了Backbone、Neck、Head 三個部分，Backbone 中與 YOLOv8 相同，\\n使用了一層CBS 進行卷積運算和四層CBS 加C2f 進行殘差及卷積運算來提\\n取特徵同時防止梯度消失。 \\n在 Neck 部分，因為傳統的 FPN 和 PAN 架構在面對因反射或波浪等背\\n景干擾因素導致特徵信息不足的目標時，容易在多層卷積過程中丟失信息，\\n導致檢測精度下降，所以作者提出了 SMFN (short multi‑fuse neck )架構，在6 \\n \\nYOLOv8 的基礎上，額外加入了較大尺寸的兩個輸入 (320×320和160×\\n160)、一個 Upsampling 層(160×160) 、一個 Fusion 加 C2f 層(160×160)\\n、一個卷積層(80×80)及一個輸出(160×160)到 FPN 和 PAN 架構中，以\\n捕捉更多的特徵信息，並提高對小型目標的檢測能力。 \\nHead 架構因為 Neck 的 SMFN 架構而多了一個160×160的輸出，相較\\n原本只有三個輸出的 YOLOv8 多了一個。在損失函數的部分，因為傳統的\\nCIoU 在處理特徵信息不足的目標時 往往會過度懲罰， 因此作者提出了\\nAWIoU(adequate wise IoU )，通過動態分配不同權重給不同特徵信息量的目\\n標來調整懲罰，避免目標因受背景干擾而造成模型誤判。 \\n在模型訓練完後，為了使其網路架構輕量化以應用於硬體運算資源有限\\n的智慧船舶 、 無人船舶等領域，作者提出了GDFP(Greedy-driven filter pruning)\\n，首先計算每一層中所有 filter 的 L1 範數以得到其重要性分數，並將分數最\\n低的 filter 刪除，在刪除後對模型重新評估，並重複以上操作直到得到理想\\n的模型，最後重新訓練該模型，以得到將模型輕量化的效果。 \\n此模型在 SeaShips 資料集上的mAP0.5 為 0.988， mAP0.5:0.95 為 0.778\\n，在 ABOships 資料集上的mAP0.5 為 0.672，mAP0.5:0.95 為 0.348。 \\n另一篇論文  YOLOSeaShip: a lightweight model for real -time ship \\ndetection [3]中提出了 YOLOSeaShip 的架構，用於解決海洋環境中目標檢測\\n的準確性與硬體資源需求之間的矛盾，特別是在實時性要求較高且硬體運算\\n能力有限的應用場景如邊境監控、智慧海洋交通中。 \\n    YOLOSeaShip 的架構基於 YOLOv7-tiny 進行改進，包含了 Input、\\nBackbone 和 Head 三個主要部分。 \\nInput 架構上採用了 Mosaic 數據增強技術，通過隨機裁剪並拼接多張影\\n像，增加數據的多樣性與小目標樣本數。此外，使用自適應圖片縮放技術來\\n處理不同尺度的目標，並結合K-means 分群方法優化錨框的尺寸設定，避免\\n人工設計過程中的偏差。 \\nBackbone 的部分，YOLOSeaShip 引入了 PConv（Partial Convolution ）\\n架構替代了原本的卷積操作。該架構僅對部分通道進行計算，從而有效減少\\n了參數量並提升計算效率。此外，每層池化操作後 還加入了 PfAAM（\\nParameter-Free Average Attention Module）。PfAAM 基於空間和通道的平均值\\n計算注意力權重，不增加模型參數的情況下提升了模型對關鍵區域的定位能\\n力。 \\nHead 部分，模型加入了SPPCSPC_tiny 架構，通過多尺度（5×5、9×9 和\\n13×13）最大池化層結合本地與全局特徵，增強對不同大小目標的檢測能力\\n。模型的最終輸出包含三個不同大小的特徵圖，用於處理不同尺度的目標檢\\n測。 \\n在損失函數設計上，作者提出了 Focal EIOU（Focal and Efficient IOU）\\n損失函數，結合了 EIOU 和 Focal Loss 的優點。EIOU 損失通過細化目標框7 \\n \\n的寬高比差異來提升回歸精度，而Focal Loss 則用於平衡正負樣本比例，讓\\n模型更關注高質量的預測框。 \\n為了評估模型性能，作者在 SeaShips(7000)資料集上進行實驗，訓練時\\n採用 Adam 優化器，學習率為 0.001，訓練 300 個 epoch。結果顯示，\\nYOLOSeaShip 的 mAP 達到 0.976，檢測速度達到119.84 FPS，相較YOLOv7-\\ntiny 模型，參數量減少至 4.78M，同時大幅提升了檢測速度和資源效率。 \\n在論文 An Improved YOLO v4 Algorithm-based Object Detection Method \\nfor Maritime Vessels[4]中提出了基於改進 YOLOv4 的船舶和泊位檢測方法，\\n用於提升目標檢測在複雜海洋環境下的準確性，特別是對港口泊位的檢測效\\n果進行了優化。該方法通過改良 錨框的生成方式和數據集構建，改善了\\nYOLOv4 在海洋場景中的檢測性能，適用於智能船舶的安全輔助系統。 \\n改進的 YOLOv4 架構包含了 Backbone、Neck 和 Head 三個部分。\\nBackbone 部分採用了 CSPDarknet53 作為特徵提取模塊，通過 ResUnit 組件\\n進行深度卷積操作，增強特徵提取能力。Neck 部分引入了 SPP 層和 PANet\\n層，其中 SPP 層通過多尺度池化操作擴展感受野，而 PANet 則將底層的定\\n位信息與高層的語義信息結合，提高多尺度目標的檢測能力。Head 部分則\\n採用了 YOLOv3 的檢測頭，輸出不同尺度的檢測結果。 \\n針對泊位檢測效果不足的問題，作者採用了 K-means 演算法重新生成\\n錨框。在原始 YOLOv4 模型中，錨框基於 MS COCO 和 VOC 數據集生成，\\n但這些框與船舶與泊位數據集中的物體尺寸不匹配，影響了檢測精度。改進\\n後的 K-means 演算法針對數據集進行分群，生成了9 組適配的錨框，有效提\\n升了檢測效率和準確性。 \\n此外，作者構建了一個包含船舶和泊位的專用數據集，通過智能實驗船\\n上的攝像頭在港口拍攝的實景影像生成，並結合公開數據集如MS COCO 和\\nVOC 補充正樣本數量。最終數據集中包含6634 張標註影像，其中70%用於\\n訓練，30%用於測試。標註信息包括物體類別及邊界框的坐標和尺寸。 \\n實驗結果表明，改進的YOLOv4 模型在 mAP 和 F1-score 方面分別提升\\n了 2.79%和 0.80%，相較於原始YOLOv4 達到了更高的檢測精度與穩定性。\\n具體指標顯示，改進後的YOLOv4 模型在 mAP 上達到 83.98%，F1-score 達\\n到 86.18%，而 YOLOv4_tiny 僅達到 54.45%的 mAP 和 54.82%的 F1-score，\\n說明輕量化模型雖然具有更快的檢測速度，但在檢測準確性上仍有進步空間\\n。8 \\n \\n三、 研究方法 \\n1. 資料收集 \\n    資料集使用 Singapore Maritime Dataset 的 Visible On-Shore 資料集[5, 6]加上\\nABOships-PLUS[7]以及手動標註公司提供的高雄資料集。 \\n    Visible On-Shore 資料集為網路上的公開資料集，包含 38 部長度小於 33 秒\\n的全彩影片，屬於中、遠港船隻影像資料集，其中含有 7 個船隻類別，此資料集\\n特徵為船隻背景為海面、天空等較乾淨的畫面。 \\n \\n表一、Visible On-Shore 資料集類別 \\nLable Data   \\nFerry \\n \\nSailsBoat \\n \\nPatrolBoat \\n \\nMerchantShip \\n \\nFishingBoat \\n \\nTugboat \\n \\nBargeShip9 \\n \\n    ABOships-PLUS 資料集為網路上的公開資料集，ABOships 資料集的改進版\\n本，包含 9880 張影像，33227 個標註，屬於近港船隻影像資料集，其中含有 3 個\\n船隻類別，此資料集特徵為船隻背景包含陸地建築物等容易誤判的畫面。 \\n \\n表二、ABOships-PLUS 資料集類別 \\nLable Data   \\npowerboat \\n \\nsailboat \\n \\nship \\n \\n  \\n \\n    高雄資料集為高雄實地拍攝的非公開資料集，包含 504 部長度小於 10 秒的\\n影片，屬於近、中港船隻影像資料集，其中含有 4 個船隻類別，此資料集特徵為\\n船隻背景包含陸地建築物等容易誤判的畫面。 \\n \\n表三、高雄資料集類別 \\nLable Data   \\nPatrolBoat \\n \\nYacht \\n \\nMerchantShip \\n \\nTugboat10 \\n \\n2. 資料前處理 \\n    \\n \\n圖一、資料前處理流程圖。 \\n    如圖一所示，首先會將資料集處理成只包含 images 和 labels 資料夾的\\n形式，images 和 labels 中的檔案是兩兩對應的，並且labels 內的標註檔格式\\n為 yolo 格式。再來會刪除有問題的標註檔及圖片，例如標註檔為空、包含\\n不存在類別、格式錯誤、圖片模糊或者有破圖情況等。第三步是合併資料集\\n，這步是可選的，主要會將數個資料集合併，並記錄合併後的類別名稱。第\\n四步是篩選類別，這步同樣為可選，主要會將需要的類別保留，不需要的剔\\n除。接著因為同一圖片中可能包含數量不等的不同類別物件，因此在切分訓\\n練集和驗證集時，容易造成不同類別的訓練驗證比例不同的情況，所以第五\\n步會將包含 n 個物件的標註檔拆分成 n 份，每一份只包含1 個原始標註檔的\\n物件，彼此不重複，且與其對應的圖片同樣複製 n 份，以確保每個類別都按\\n照正確比例進行切分，最後一步為按照自訂比例切分訓練集及驗證集。 \\n3. 船隻辨識模型 \\n    我們使用了最新的YOLOv11[8]模型來建置船隻辨識模型 ，YOLOv11 基\\n於 PyTorch 架構開發，可在一次前向傳播中同時定位及辨識物件，具有速度\\n快、所需資源少、開發便利及多尺度檢測等優點。圖二為 YOLOv11 架構圖\\n，首先輸入的圖片為 640x640x3 的 RGB 圖像，接著 YOLOv11 可以根據此\\n架構分為三個部分，Backbone, Neck 以及 Head。11 \\n \\n \\n圖二、YOLOv11 架構圖[9] \\n \\nBackbone 如圖二左側所示，主要目的是從輸入影像中提取有用的特徵\\n資訊。在 YOLOv11 中，Backbone 採用了 C3K2 結構，為升級版的 C3，透\\n過更小的卷積核與路徑切分技術，在保持模型表現的前提下大幅降低了計算\\n成本。每個C3K2 中包含兩條路徑，一條直接進行卷積處理，另一條則經過\\n多個 Bottleneck 區塊進行深度特徵學習，最後進行特徵融合。這種結構不僅\\n有效防止梯度消失問題，也能提升網路的收斂速度與特徵提取效率。 \\nNeck 部分如圖二中間所示，結合了 SPFF(Spatial Pyramid Pooling Fast)\\n架構和多層 C2PSA 區塊。SPFF 架構是 SPP 的高速版本，透過不同尺度的\\n最大池化操作將特徵圖進行多尺度融合，再透過 Concatenation 將資訊彙整\\n，幫助模型更好地識別大小不一的船隻。此外，Neck 中的 C2PSA 架構引入\\n空間注意力機制(Spatial Attention)，能讓模型聚焦在關鍵影像區域，特別是\\n對小型或部分遮蔽的物件表現更佳。這部分的架構延續了FPN 與 PAN 的優\\n點，強化了從深層到淺層、再回到深層的資訊傳遞，進一步提升辨識與定位\\n的能力。 \\nHead 如圖二右側所示，負責進行最後的物件偵測任務。YOLOv11 採用\\n多尺度輸出策略，透過多層輸出特徵圖分別負責不同大小目標的偵測。\\nYOLOv11 會利用不同尺寸與比例的錨框(Anchor Boxes)來涵蓋不同形狀的\\n目標，並透過 Non-Maximum Suppression(NMS)過濾重疊的邊界框，保留最\\n具代表性的偵測結果。12 \\n \\n四、 實驗結果 \\n    我們使用 YOLOv11l 模型，訓練集使用 ABOships-PLUS，測試集使用\\n高雄資料集，實驗環境為 64-bit Windows 11、Intel i5-13400F 2.5GHz CPU、\\n32GB RAM 及 NVIDIA RTX 4070 GPU。除了測試模型在原先新加坡資料集\\n的效果外，實驗還在高雄資料集上針對船隻速度、距離以及避碰能力做檢測\\n，因實際場域在白天時使用的是彩色影像，黑夜時使用的是黑白影像當作模\\n型輸入，所以實驗也同時測試了模型對彩色和黑白影像的辨識能力，檢測方\\n式為當船隻出現的 3 秒內有辨識到至少 1 次則辨識成功，反之辨識失敗，同\\n一部影片中辨識成功的數量與真實船隻的數量比值即為檢測率。實驗時我們\\n同時比較了 1 秒內有辨識到船隻、2 秒內有辨識到船隻的檢測率以更精確地\\n測量模型的辨識能力，以下為檢測效果。 \\n \\n表四、實驗結果檢測率 \\n測試影片 1 秒內檢測率 2 秒內檢測率 3 秒內檢測率 \\n彩色影片 output_005 1.0 1.0 1.0 \\n彩色影片 output_041 1.0 1.0 1.0 \\n彩色影片 output_080 1.0 1.0 1.0 \\n彩色影片 output_097 1.0 1.0 1.0 \\n黑白影片 output_199 0.67 1.0 1.0 \\n黑白影片 output_202 0.67 1.0 1.0 \\n黑白影片 output_276 1.0 1.0 1.0 \\n黑白影片 output_290 0.75 0.75 1.0 \\n \\n    如上表所示，原要求的 3 秒內檢測率全部達標，都為 1.0，2 秒與 1 秒\\n內的檢測率也大部分都是 1.0，其中判錯的情況都是在船隻彼此重疊時或影\\n像較模糊時發生，一般的應用情況幾乎不會有問題。13 \\n \\n \\n圖三、彩色影片 output_005 第一秒影像 \\n    彩色影片 output_005 的第一秒影像如上圖所示，圖中模型成功辨識出所\\n有船隻，1~3 秒內的檢測率都為 1.0。 \\n \\n圖四、彩色影片 output_041 第一秒影像 \\n    彩色影片 output_041 的第一秒影像如上圖所示，圖中模型成功辨識出所\\n有船隻，1~3 秒內的檢測率都為 1.0。14 \\n \\n \\n圖五、彩色影片 output_080 第一秒影像 \\n    彩色影片 output_080 的第一秒影像如上圖所示，圖中模型成功辨識出所\\n有船隻，1~3 秒內的檢測率都為 1.0。 \\n \\n圖六、彩色影片 output_097 第一秒影像 \\n    彩色影片 output_097 的第一秒影像如上圖所示，圖中模型成功辨識出所\\n有船隻，1~3 秒內的檢測率都為 1.0。15 \\n \\n \\n圖七、黑白影片 output_199 第二秒影像 \\n    彩色影片 output_199 的第二秒影像如上圖所示，圖中模型成功辨識出所\\n有船隻，2~3 秒內的檢測率都為 1.0。 \\n \\n圖八、黑白影片 output_202 第二秒影像 \\n    彩色影片 output_202 的第二秒影像如上圖所示，圖中模型成功辨識出所\\n有船隻，2~3 秒內的檢測率都為 1.0。16 \\n \\n \\n圖九、黑白影片 output_276 第一秒影像 \\n    彩色影片 output_276 的第一秒影像如上圖所示，圖中模型成功辨識出所\\n有船隻，1~3 秒內的檢測率都為 1.0。 \\n \\n圖十、黑白影片 output_290 第三秒影像 \\n    彩色影片 output_290 的第三秒影像如上圖所示，圖中模型成功辨識出所\\n有船隻，3 秒內的檢測率都為 1.0。17 \\n \\n表五、KPI 完成表 \\n項目 達成狀況 \\n1.建立 AI 分析海事觀測演算法邏輯架構 已達成 \\n2.完成演算法建立，並可在本島沿海 3 公里海域內環境進行 已達成 \\n3.演算結果可達以下規格標準: \\n通訊傳輸速率>250kbps 以上 已達成 \\n影像解析度> 640x480 已達成 \\n影像幀速率≧ 10FPS 已達成 \\n船隻移動速度≧15 節(30km/hr) 已達成 \\n船隻辨識數量≧ 10 已達成 \\n船隻辨識大小> 15m 已達成 \\n船隻辨識距離≧5km 已達成 \\n船隻避碰距離≧3.7km 已達成 \\n船隻辨識準確度≧90% 已達成 \\n \\nKPI 完成表如上所示，全部項目都已完成。18 \\n \\n五、 結論 \\n本計畫目的為設計出可以有效辨識 3 公里遠的船隻，且一次可辨識長度 15\\n公尺的船隻 10 艘以上的模型，根據目前的實驗結果，模型在船隻距離、速度、\\n目標數量以及避碰能力上都有達到目標，並且模型在彩色及黑白影片上的表現也\\n能夠符合實際應用場域需求。19 \\n \\n六、 參考文獻 \\n[1] Sun, Bowen, et al. \"Automatic ship object detection model based on YOLOv4 \\nwith transformer mechanism in remote sensing images.\" Applied Sciences vol. \\n13. No. 4, p. 2488, 2023. \\n[2] Yang, Defu, et al. \"A streamlined approach for intelligent ship object detection \\nusing EL-YOLO algorithm.\" Scientific Reports, vol. 14. No.1, p.15254, 2024. \\n[3] Jiang, X., Cai, J., & Wang, B. (2024). YOLOSeaShip: a lightweight model for \\nreal-time ship detection. European Journal of Remote Sensing, 57(1). \\nhttps://doi.org/10.1080/22797254.2024.2307613 \\n[4] He, Guowen & Wang, Wenlong & Shi, Bowen & Liu, Shijie & Xiang, Hui & \\nWang, Xiaoyuan. (2022). An Improved YOLO v4 Algorithm-based Object \\nDetection Method for Maritime Vessels. International Journal of Science and \\nEngineering Applications. 11. 50-55. 10.7753/IJSEA1104.1001. \\n[5] D. K. Prasad, D. Rajan, L. Rachmawati, E. Rajabaly, and C. Quek, “Video \\nProcessing from Electro-optical Sensors for Object Detection and Tracking in \\nMaritime Environment: A Survey,” IEEE Transactions on Intelligent \\nTransportation Systems (IEEE), 18 (8), 1993 - 2016, 2017. \\n[6] D. K. Prasad, “Singapore Maritime Dataset, Visible On-Shore dataset,” Available \\nOnline: https://sites.google.com/site/dilipprasad/home/singapore-maritime-\\ndataset \\n[7] Winsten Jesper, Iancu Bogdan, Soloviev Valentin, & Lilius Johan. (2024). \\nABOships-PLUS [Data set]. Zenodo. https://doi.org/10.5281/zenodo.10469672 \\n[8] Glenn Jocher and Jing Qiu, “Ultralytics YOLO11,” Available Online: \\nhttps://github.com/ultralytics/ultralytics \\n[9] Medium, “YOLOv11 Architecture Explained: Next-Level Object Detection with \\nEnhanced Speed and Accuracy,” Available Online: https://medium.com/@nikhil-\\nrao-20/yolov11-explained-next-level-object-detection-with-enhanced-speed-and-\\naccuracy-2dbe2d376f71\\n===\\n請根據以上文件內容，模擬一位業務代表會向 TPM 詢問有關 即時辨識 24 海里內船隻平台 的1個問題或轉述的需求。\\n', type='TextMessage'), TextMessage(id='a762fa79-edca-4fcb-afb8-ebeb3fd24a7c', source='Business', models_usage=RequestUsage(prompt_tokens=8237, completion_tokens=173), metadata={}, created_at=datetime.datetime(2025, 7, 27, 12, 58, 12, 104356, tzinfo=datetime.timezone.utc), content='Hi TPM，剛剛跟一家航運管理公司的客戶聊到，他們提到目前的即時海洋觀測系統偵測距離是5公里左右（約3海里），他們想了解可不可以擴充成能夠即時辨識24海里內的船隻？因為他們需要更廣的海域監控，預防遠距離船隻靠近港口的安全風險。不過他們也擔心距離拉遠會不會讓辨識的準確度大幅下降，或者系統負擔會不會變太重？不知道這樣的需求技術上有什麼做法或限制？我們有沒有案例或想法可以先跟客戶回應？', type='TextMessage'), TextMessage(id='5eaf1f5f-c13e-44ad-a816-17a3d4ff60b3', source='TPM', models_usage=RequestUsage(prompt_tokens=8413, completion_tokens=674), metadata={}, created_at=datetime.datetime(2025, 7, 27, 12, 58, 21, 885094, tzinfo=datetime.timezone.utc), content='感謝你的說明，針對客戶想將即時海洋觀測系統的偵測距離從目前約3海里 (5公里) 擴充到24海里 (約44公里) 這個需求，我目前有以下幾個需要釐清的問題，幫助我們更準確理解其期望與使用情境：\\n\\n1. **使用情境與目標**  \\n   - 客戶希望24海里範圍內即時偵測船隻，是持續且連續監控，還是只需要定時或事件觸發偵測？  \\n   - 他們對「即時」的幀率或延遲容忍度有無具體要求（例如每秒幾幀、可接受的識別延遲時間）？  \\n   - 是否需要同時辨識10艘以上的船隻目標？過去系統表現有此需求嗎？\\n\\n2. **硬體與環境限制**  \\n   - 目前平台所使用的攝影設備（鏡頭規格、感光度、安裝高度等）是否可以在更遠距離保持有效影像品質？  \\n   - 客戶是否有計畫或預算升級攝影硬體？或希望純粹用現有設備做軟體優化？\\n\\n3. **辨識準確度與安全風險容忍度**  \\n   - 目前系統在5公里內約達90%的準確率，若在24海里距離辨識準確度下降（例如降到60%、70%），是否仍符合他們的安全風險需求？  \\n   - 需要辨識的船隻大小、速度等細節是否與現有設定一致？還是有更嚴格或更多樣化的目標？\\n\\n4. **系統負載與運算資源**  \\n   - 他們期望平台是在現有架構下升級，還是可以接受新增硬體（如更強GPU、邊緣運算節點）？  \\n   - 是否能接受辨識精度與運算速度的trade-off（例如降低幀率以維持遠距離辨識）？\\n\\n有了這些細節後，我能協助評估從技術面是否有可行的解法，以及不同方案的優劣與風險，接著再彙整給您或直接回覆客戶。\\n\\n目前從已有計畫和文獻來看，遠距離辨識在影像品質下降、目標物訊號弱化時會面臨挑戰，可能需要搭配更高解析度攝影機、更強大的AI模型（或模型調校）、以及更高的計算資源；同時也可考慮結合雷達、AIS等多感測資料融合，提升長距辨識的效果與可靠性。\\n\\n請問上述的釐清方向是否符合？還是客戶有其他重點需求需要我們特別注意？', type='TextMessage'), TextMessage(id='1b346acb-4097-4c92-810a-0849f9d1ebbb', source='Business', models_usage=RequestUsage(prompt_tokens=9095, completion_tokens=458), metadata={}, created_at=datetime.datetime(2025, 7, 27, 12, 58, 25, 601997, tzinfo=datetime.timezone.utc), content='謝謝你的詳盡回覆！我先以模擬客戶的角度來補充回應：\\n\\n1. 使用情境與目標：客戶是希望能有連續且接近即時的監控，尤其在繁忙海域要持續掌握遠距離船隻動態，幀率希望至少能維持5FPS以上，延遲不可超過2秒。他們仍希望能同時偵測超過10艘船隻，因為海域常有多船活動。\\n\\n2. 硬體與環境限制：客戶目前使用的監控鏡頭大多是中階型號，感光度及變焦能力有限，拍攝角度多為岸邊或碼頭高點安裝。短期內沒有大幅升級硬體的預算，但有意願評估少量升級（例如更換更高解析度鏡頭）。他們較希望先測試看軟體優化可達的效果。\\n\\n3. 辨識準確度與安全風險容忍度：客戶能接受辨識準確度在遠距離有所降低，但希望不要低於70%。船隻大小及速度條件跟現有類似，以大型商船與漁船為主。\\n\\n4. 系統負載與運算資源：客戶希望盡可能利用現有系統架構，除非必要，不願意頻繁增購硬體。但若確定可以透過硬體升級大幅提升性能，也願意評估。\\n\\n整體來看，客戶期待是一個平衡方案，希望能先藉由我們過去已有的AI模型與資料優化，推動軟體端的效能提升，並且評估逐步的小規模硬體升級可能，分階段達到他們24海里即時辨識的目標。\\n\\n我這邊先把這些需求整理出來，方便您做初步評估後，我再回報給客戶，謝謝！', type='TextMessage'), TextMessage(id='52f53ca3-e392-4ddd-a54e-9ed980919874', source='TPM', models_usage=RequestUsage(prompt_tokens=9555, completion_tokens=1061), metadata={}, created_at=datetime.datetime(2025, 7, 27, 12, 58, 44, 584537, tzinfo=datetime.timezone.utc), content='感謝你補充客戶的詳細需求，這樣資訊非常有助於我們進行技術評估。根據目前掌握的情況，我將進入【第二階段：提出可行技術組合與解法建議】，先提出兩個可行方向供參考，針對客戶希望在既有系統基礎上，分階段達到24海里內即時辨識的平衡方案：\\n\\n---\\n\\n### 技術組合與解法建議\\n\\n#### 方案一：軟體優化＋現有硬體的極限調整\\n- **核心想法**  \\n  利用已有的YOLOv11模型架構，針對遠距離特徵弱化問題，做進一步模型微調與強化（如改良影像增強演算法，加強遠距特徵提取的注意力機制），並結合多尺度、多角度資料重新訓練，提升模型對遠距離薄弱訊號的辨識力。\\n- **硬體條件**  \\n  盡量用現有中階鏡頭，並在軟體端做影像前處理（去霧、增亮等）及拼接多時序影像來增加辨識機會。不優先更換硬體，符合客戶短期無大升級預算。\\n- **效能預期**  \\n  可望延伸有效偵測距離到10-15公里（約6-8海里），辨識準確率可在70%-80%之間，幀率在5FPS上下，延遲控制在2秒內可望達成，但難以完全覆蓋24海里。\\n- **限制與風險**  \\n  遠距影像訊號受環境影響大，準確率提升有限，且偵測範圍增大會造成有效像素下降，辨識器需要更敏感的特徵提取，運算負荷可能增加，需實驗驗證。\\n\\n#### 方案二：軟體優化＋部分硬體升級（高解析鏡頭＋邊緣運算）\\n- **核心想法**  \\n  在方案一基礎上，採用更高解析度的攝影鏡頭（例如4K解析度），利用解析度提升來拉長有效偵測距離及精細辨識遠距目標；此外，在岸邊安裝邊緣運算裝置，搭載優化的AI辨識模型，緩解中央系統負載並減低通訊延遲。\\n- **硬體條件**  \\n  客戶可先小規模升級部分關鍵點鏡頭（如重要港口或監控要點），邊緣計算設備可採用既有系統兼容的GPU或AI加速卡，避免大規模換新。\\n- **效能預期**  \\n  預估可達到15-20公里範圍，辨識準確率可穩定在75%-85%，維持5FPS以上及2秒延遲內；可同時精準監控超過10艘船隻且減輕中央系統負載。\\n- **限制與風險**  \\n  硬體升級但非全面，需評估場域佈局是否有效支持遠距離偵測；邊緣運算設備規格與維護成本需提前規劃；此外系統整合複雜度提高。\\n\\n---\\n\\n### 備註與待確認事項\\n- 需確認目前現有鏡頭實際影像品質現況，如解析度、視野角度及光學變焦能力，才能細化優化方向及升級預算評估。  \\n- 目前24海里的偵測距離在光學影像系統上屬於極限挑戰，軟體調整必須配合硬體支持，且環境因素（天氣、海況）影響更大。  \\n- 可評估與雷達或AIS系統融合，作為遠距離初步篩選，提高整體監控可靠度。\\n\\n---\\n\\n我建議先以方案一做小規模PoC（Proof of Concept）測試，驗證軟體優化後的偵測與辨識能力提升幅度，再根據結果評估是否推動方案二階段性硬體升級。\\n\\n接下來我可協助拆解必要的評估任務與資源規劃，您覺得這樣的技術回應方向是否符合您與客戶期待？還是需要更聚焦某個面向？', type='TextMessage'), TextMessage(id='316bbf5e-4664-4296-a076-1e31c5906deb', source='Business', models_usage=RequestUsage(prompt_tokens=10625, completion_tokens=253), metadata={}, created_at=datetime.datetime(2025, 7, 27, 12, 58, 47, 168758, tzinfo=datetime.timezone.utc), content='感謝你的詳細分析與建議！我覺得你提出的兩個方案相當符合客戶目前期望的分階段策略，尤其是先從軟體提升做PoC再考慮硬體升級，能夠降低他們的初期風險，也較符合他們希望優先利用現有設備的意向。\\n\\n我這邊先回報給客戶，強調方案一可先行推動，看看軟體端優化效果能推多遠，再依結果討論是否投入方案二，含硬體升級與邊緣運算的可能性。\\n\\n另外，客戶很關注現有鏡頭規格和畫質是否適合遠距辨識，能否協助我們做個簡單的現場鏡頭影像品質評估？這樣也方便我們更精準地做PoC設計。\\n\\n最後，我想先確認下個階段如果要做PoC，是需要我們配合試驗數據提供，還是你方有建議的實驗環境？或者需要客戶提供現場錄影素材？\\n\\n謝謝！', type='TextMessage'), TextMessage(id='e165c905-b2dd-462b-a88c-41aeb607b7a8', source='TPM', models_usage=RequestUsage(prompt_tokens=10879, completion_tokens=871), metadata={}, created_at=datetime.datetime(2025, 7, 27, 12, 59, 3, 140581, tzinfo=datetime.timezone.utc), content='感謝你的回饋，了解客戶的想法與後續需求後，我針對接下來的PoC準備與執行，提出以下建議與規劃方向，供你與客戶參考：\\n\\n---\\n\\n### 1. 現場鏡頭影像品質評估  \\n- **建議方式**：  \\n  可派遣技術團隊以現場鏡頭實際拍攝一段包含各種典型海況（晴天、陰天、霧天、夜間）的影片，或由客戶提供若干現有錄影素材，以多角度、多距離測試當前影像品質。  \\n- **評估重點**：  \\n  - 解析度與視野角度是否足以涵蓋目標偵測範圍。  \\n  - 影像清晰度、噪點、反光與霧氣對圖像品質的影響程度。  \\n  - 中距到遠距目標在畫面中的像素大小範圍。  \\n- **交付物**：提供現場錄影樣本與技術評估報告，協助做後續PoC的模型調整依據。  \\n\\n---\\n\\n### 2. PoC階段實驗環境與數據需求  \\n- **數據提供**：  \\n  - 從客戶側收集現有的監控錄影（推薦含多條視角與時間段，彩色與黑白均可）作為訓練及測試資料。  \\n  - 若無足夠資料，則可結合公開資料集與自建資料集進行混合訓練，並用客戶錄影做測試驗證。  \\n- **實驗架構**：  \\n  - 模型部署可先在本地測試環境執行，利用已有設備的錄影素材以模擬實時影像輸入。  \\n  - 可視情況與客戶協調，安排短期現場測試（例如選擇代表性監控點進行實地錄像與即時辨識演示）。  \\n- **技術支持**：  \\n  - 提供軟體調整及模型訓練方案。  \\n  - 針對影像前處理、動態場景適應做優化測試。  \\n  - 幀率與延遲測試以符合客戶5FPS以上、延遲低於2秒的要求。  \\n\\n---\\n\\n### 3. 預期交付成果與後續規劃  \\n- PoC結束後，將提供性能評估報告，包含：  \\n  - 不同距離與條件下的辨識準確率、幀率和延遲數據。  \\n  - 可接受的最長即時偵測距離及瓶頸分析。  \\n- 根據PoC結果，與客戶討論是否及如何執行小規模硬體升級（方案二），包括鏡頭及邊緣運算設備。  \\n\\n---\\n\\n### 4. 風險與注意事項  \\n- 請確保現場錄影涵蓋多樣環境情境，避免PoC過於理想化。  \\n- 可能需要一些時間進行資料整理與標註，以確保模型訓練質量。  \\n- 若客戶錄像品質過低，遠距辨識效果可能受限，需提前溝通期望值。  \\n\\n---\\n\\n請問以上規劃是否符合你與客戶的期待？我可以準備一份簡短的PoC技術方案及時間表，方便你回報與溝通；並可協助安排技術支持團隊與客戶對接完成影像資料收集。若有其他需求或想更聚焦某階段，請隨時告知。', type='TextMessage')], stop_reason='Maximum number of turns 6 reached.')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogen_agentchat.ui import Console\n",
    "\n",
    "await Console(team.run_stream(task=business_agent_task))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_tpm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
